[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Whether its making a simple site map or running deep learning analyses on satellite data, students and researchers are often called upon to conduct geospatial analysis. ðŸ—º\nFortunately, there a wealth of freely available tools can help to complete these tasks: think R, Python and QGIS.ðŸ”¨\nUnfortunately, a steep learning curve is often required to apply these tools, particularly when we donâ€™t all have a strong background in coding, GIS or remote sensing.\nThe UQ Geospatial Analysis Community of Practice (sometimes UQGAC, sometimes UQGEO) tries to make this process a bit less painful, by sharing our experiences, skills and tricks in a friendly and inclusive environment.\nðŸ‘©â€ðŸ’» We run monthly skill sharing tutorial sessions where a member of the community teaches us something they have learned along the way.\nThis usually occurs on the last Thursday of each month.\nSee upcoming events for the next session.\nAnd check out our blog for previous sessions.\nIf you want to get involved, just email us at uqgeo.community @ gmail dot com"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Brisbane Geospatial Community of Practice",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nCalculating areas with vector and raster data in R\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 5, 2023\n\n\nChristina Buelow\n\n\n\n\n\n\n  \n\n\n\n\nNewsletter | Happy New Year! | February meet-up | R Training\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJan 22, 2023\n\n\nChristina Buelow\n\n\n\n\n\n\n  \n\n\n\n\nBuild a blog with Quarto, Git, and RStudio\n\n\n\n\n\n\n\nwebsite\n\n\n\n\n\n\n\n\n\n\n\nNov 3, 2022\n\n\nCatherine Kim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNewsletter | Climate data blog post + problem solving session + conference in Fiji + more\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSep 9, 2022\n\n\n\n\n\n\n  \n\n\n\n\nAnalysing Climate data with R\n\n\n\n\n\n\n\nR\n\n\nclimate\n\n\nraster\n\n\n\n\n\n\n\n\n\n\n\nSep 1, 2022\n\n\nRalph Trancoso\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNewsletter | Analysing climate data with R + Interactive Maps + AEO Forum + more.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAug 16, 2022\n\n\n\n\n\n\n  \n\n\n\n\nInteractive mapping with RShiny\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJul 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNewsletter | Mapping interactively + R for ecologists + Data wrangling + more.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJul 14, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProblem Solving Session II\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJul 7, 2022\n\n\n\n\n\n\n  \n\n\n\n\nProblem Solving Session I\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMay 26, 2022\n\n\n\n\n\n\n  \n\n\n\n\nCloud computing with Open Data Cube and Python\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nApr 25, 2022\n\n\nTim Devereux\n\n\n\n\n\n\n  \n\n\n\n\nHow to contribute a post\n\n\n\n\n\n\n\nwebsite\n\n\n\n\n\n\n\n\n\n\n\nNov 23, 2021\n\n\nCatherine Kim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreating a geospatial blog with blogdown\n\n\n\n\n\n\n\nspatial\n\n\nvisualisation\n\n\n\n\n\n\n\n\n\n\n\nOct 28, 2021\n\n\nUQGSAC\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/build-blog-w-quarto/index.html",
    "href": "posts/build-blog-w-quarto/index.html",
    "title": "Build a blog with Quarto, Git, and RStudio",
    "section": "",
    "text": "We will be covering some basics of multiple programming skills (Git/GitHub, R, Markdown, etcâ€¦) with the aim of empowering people to contribute to quarto websites such as this one - the Brisbane Spatial Share Community of Practice. The idea is to encourage community members to contribute material directly instead of funneling everything through a website administrator.\nBackground of the Community of Practice with founder, Mitchel Rudge. See the About page for more info.\nSo the group already has a websiteâ€¦ why another blog? Essentially, we found blogdown to be buggier than we wanted. Also, the folder structure was not very intutitive and are unique to each hugo theme. Finally, for the needs of our Spatial Share group the multi-lingual aspects of quarto were an important draw."
  },
  {
    "objectID": "posts/build-blog-w-quarto/index.html#creating-a-blog-with-quarto",
    "href": "posts/build-blog-w-quarto/index.html#creating-a-blog-with-quarto",
    "title": "Build a blog with Quarto, Git, and RStudio",
    "section": "Creating a blog with quarto",
    "text": "Creating a blog with quarto\n\nWhat is quarto?\nQuarto is a â€œmulti-language, next-generation version of R markdown from RStudio.â€ It is designed to be programming language (compatible with R, python, Julia, and moreâ€¦?) and tool agnostic (RStudio, VSCode, jupyter, Observable). In this tutorial, we are focusing on Quarto and RStudio.\nThe basic model of Quarto publishing is taking a source document and rendering it to a variety of outputs like html, pdfs, and Word. The backend process is illustrated below. The key difference from R Markdown is that it uses pandoc. For those interested in the details, I would recommend the Welcome to Quarto! 2 hr workshop on Youtube led by Tom Mock at RStudio.\n\nFAQ for R Markdown users.\n\n\nMake a quarto blog in RStudio\nRStudio has quarto built-in with recent versions after 2022.07. Go to File > New Project or the R in a blue cube under â€˜Editâ€™ and you will see Quarto options right there!\n\nLetâ€™s click on the Quarto Blog option. In the next window, name you project (e.g., myblog), select where to save the project with the Browse button, and ensure â€˜Create a git repositoryâ€™ is checked. More on git later.\n\nThe default project is populated with some example files and folders. The open index.qmd file is the â€˜home pageâ€™ of the blog that will list all the posts. The .qmd is the file extension for a Quarto file just like .Rmd for R Markdown. Go ahead and change the first title field in the YAML. For instance, change â€˜my blogâ€™ to â€˜My Blogâ€™.\n\n\n\n\n\n\nNote\n\n\n\nYAML stands for â€˜Yet Another Markup Languageâ€™ and is delineated by a triple dash (â€”) at the beginning and end of the YAML section. This is where you define settings for you quarto document/post.\n\n\nNow, letâ€™s look at one of the template posts. In the Files pane click on posts > welcome > index.qmd. Here we can see a template for a â€˜Welcomeâ€™ post.\nA recent addition to RStudio is that you can view the â€˜Sourceâ€™ (top left pane) as either the Source code or Visual editor. These views can be swapped by toggling the buttons at the top right of the pane. The Source code (blue box below) displays all the source code for your quarto file such are your R code (in chunks - none in this example) and Markdown narrative text.\n\n\n\n\n\n\nNote\n\n\n\nA code chunck is delineated by three backticks (button to the left of 1) and {} with the language for the code chunk (R, python etc.). Click the green C+ button to the left of run to add a new R chunck. Or keyboard shortcut Ctrl/Cmd + Alt + I.\n\n\n\nThe Visual editor displays a rendered version of your quarto file - more like what it will look like when the site is published. This is more similar to writing in a text editor like Word. You can also see there some extra formatting buttons in the Visual Editor like bold/italics and super/subscripts. The â€˜Tableâ€™ function is also a welcome edition as formatting tables in Markdown is very finicky and tedious.\nTry inserting a table or super/subscript (Format > Text > Strikethrough/Superscript/Subscript/Smallcaps) in the Visual editor and then toggle to the Source code. Now you can see the associated Markdown code for whatever you just did! Super handy.\nNow, open the _quarto.yml file. Here we can see the project type (a website), some website formatting (the navigation bar), and some other customization fields. Update the title field to match the title we edited earlier. In my case, it was â€˜My Blogâ€™. Feel free to edit other fields such as your GitHub, Twitter, LinkedIn profile links etc. You can also change the theme to one of many built-in themes.\n\n\nDonâ€™t forget to save your files when you make changes. If the file name in the tab is red - that means you have unsaved changes.\n\n\n\n\n\n\n\nNote\n\n\n\nDonâ€™t forget to save your files when you make changes. If the file name in the tab is red - that means you have unsaved changes.\n\n\nThe Visual editor is pretty cool, but itâ€™s not exactly the same as previewing your website before publishing. Click on the Render button at the top and see what happens.\nA preview of your blog should have popped-up in a web browser. You can navigate like you would a website to see all the features. Go to the about page - we can see it is the default page with the Quarto blog project. If youâ€™d like, open the about.qmd page in the project directory and make a change. Add some text, delete a link (like LinkedIn) and then save your changes.\nCongrats - youâ€™ve made a blog!\n\n\n\nCelebrate! Credit: http://www.reactiongifs.com/cheering-minions/\n\n\nIn the top right view pane of RStudio, you can see Render and Background Jobs tabs. If youâ€™d like to get an idea of what is happening in the background, check out these tabs. In the Backgroun Jobs tab, there is a red stop sign in the top right corner to stop previewing your site.\nBut how do I share it with the world?? First, we will need to version control our project with git and store it in a remote repository."
  },
  {
    "objectID": "posts/build-blog-w-quarto/index.html#creating-a-post-on-the-uqgac-website",
    "href": "posts/build-blog-w-quarto/index.html#creating-a-post-on-the-uqgac-website",
    "title": "Build a blog with git, R, and quarto",
    "section": "Creating a post on the UQGAC website",
    "text": "Creating a post on the UQGAC website\nCatherine Kim, PhD\nPostdoctoral Associate, School of Biological Sciences\nTechnology Trainer, UQ Library\nTwitter: @fishiintheC\nWhat we will cover:\n\nblogdown basics\nGit and GitHub basics\nHow to create a post on the UQGSAC blogdown website\nR Markdown basics\n\nI have pieced this together using many other resources on the above which are mentioned throughout. Thank you to Mitch and StÃ©phane for their help with this tutorial and workshop!\nWhat you will need:\n\nInstallations - R, RStudio, Git\nA GitHub account (free) with your login and personal access token (PAT) details handy"
  },
  {
    "objectID": "posts/build-blog-w-quarto/index.html#blogdown-basics",
    "href": "posts/build-blog-w-quarto/index.html#blogdown-basics",
    "title": "Build a blog with git, R, and quarto",
    "section": "blogdown basics",
    "text": "blogdown basics\nblogdown is an R package that allows the creation of websites using R Markdown and Hugo, a static site generator. blogdown websites in R have been all the rage the last few years and you have probably seen many â€˜Hugo-Academic themeâ€™ personal websites - all built in R!\n\n\n\nblogdown hex sticker Credit: Creating Website with R Markdown\n\n\n\nThere is a short online book on blogdown written by the developer, Yihui and others.\nA recent article by Allison Hill on starting your own blogdown website from scratch.\nSee Mitch and StÃ©phaneâ€™s tutorial for UQGSAC on creating a blogdown website.\n\nThis session focuses on how to go about contributing a post to an existing website.\nThe UQGSAC website is built using the anatole theme. There are many themes to choose from and if you know html/CSS you can even build your own theme.\nSo, how do we go about contributing to a blogdown website?\n\n\n\nProgrammer GIF Credit: Capgemini India on GIPHY\n\n\nA good place to start is making sure you have installed the blogdown package:\n\ninstall.packages(\"blogdown\")\n\nArticle about setting global options in blogdown if you need to set the Hugo version in your .Rprofile (blogdown::config_Rprofile()).\nTo allow multiple people to contribute to the same website, the website is hosted on GitHub and Netlify.\nAs the website is already set-up, we will be dealing with Git + GitHub and R + RStudio + R Markdown."
  },
  {
    "objectID": "posts/build-blog-w-quarto/index.html#git---what-is-it",
    "href": "posts/build-blog-w-quarto/index.html#git---what-is-it",
    "title": "Build a blog with Quarto, Git, and RStudio",
    "section": "Git - what is it?",
    "text": "Git - what is it?\nA version control software (think track changes) useful for collaborating on and sharing code.\nGit is the software itself that records changes to a set of files locally. There are several hosting platforms that are like online repositories (think Dropbox, Google Drive, etc.) that work with Git: Bitbucket, GitLab, and GitHub to name a few.\nThese platforms not only allow for version control but also to collaborate, organize, and back up projects.\n\nIn this case, we will be using GitHub to access the website files, make some changes (i.e., add a post), and then incorporate those changes back to the website repository on GitHub which will automatically update the website itself. ðŸ™Œ\nThere are lots of fabulous and free resources online that go more into depth on Git:\n\nIf you need to be convinced to use Git for version control see this article and Happy Git and GitHub for the useR to git started both by Git/R guru Jenny Bryan.\nSee Caitie Kuempelâ€™s R Ladies Brisbane presentation on getting started with GitHub in RStudio.\n\n\nGit Terminology\nRepository/repo - where a project is stored in GitHub. Think of it like a folder holding all the relevant documents that you can version control, view history, and add collaborators. The repository or repo holds all the relevant files for the website - most of which we will not touch.\nCommit - is one or more changes to a file or set of files that you are asking GitHub to keep track of.\nPush - sending your committed changes to a remote repository on GitHub. Local changes updated on the GitHub website where other people can access.\nPull - incorporating and merging changes. An edit on the remote repository on GitHub can be pulled to a local repository.\nDiff - difference, or changes made that are visible as insertions/deletions for a commit.\nMain - the default branch you are on. Master has recently updated to main, but they are the same thing. You are more likely to come across master on older resources. Jenny Bryan strongly urges you to create a new branch to work off of which requires using command line. For the purpose of contributing to a quarto website, I will forgo covering this as it is unlikely more than one person will be contributing at the same time.\nOrigin - the remote repo online from which you have cloned your local copy from.\n\n\n\nHow committing goesâ€¦ Credit: xkcd comics\n\n\n\n\nUsethis on our blog project\n\n\n\n\n\n\nHappy Git and GitHub for the useR is the online bible of using git with R by legendary Jenny Bryan. This book covers all the basics in details and provides workflows and troubleshooting Jenny Bryan has a whole chapters on what is covered below. Ch 7 Configure Git, Ch 9 PATs, and Ch 17.3 Create and connect a GitHub repo. Itâ€™s an excellent resource that I would highly encourage you to check out.\n\n\n\nUsethis is a workflow package designed to automate repetitive tasks for package development and project setup. Here, weâ€™ll be using it for the latter.\n\n\n\n\n\n\nNote\n\n\n\nYou might need to install usethis. Check by search in the Packages window in the bottom right pane in RStudio.\ninstall.packages(\"usethis\")\nlibrary(usethis)\nOr you can install the development version: install.packages(\"devtools\") if you donâ€™t have devtools. devtools::install_github(â€œr-lib/usethisâ€)\n\n\n\nConfigure Git\nIf you have never used Git before you will need to configure your account. We can do this in R with usethis using your GitHub username and email. These must be the details associated with your GitHub account. You will only need to do this once.\nusethis::use_git_config(user.name = \"Jane Doe\", user.email = \"jane@example.org\")\nIf you are not sure if you have configured Git, you can check with running usethis::edit_git_config() in the console. This will open your .gitconfig file and you can check the [user] details. If these are not right you can go ahead and change theme in the file and save.\n\n\n\nCreate a personal access token\nWe must also configure a personal access token or PAT with usethis. Type usethis::create_github_token() in the console. You will either need to log into GitHub or confirm your password. usethis will automatically select some scopes - which ones are selected? We can use these defaults - click the big, green Generate token button at the bottom.\nLeave this page open or copy this and keep it a text file/password manager. We will use it again later. You can even use gitcreds::gitcreds_set() to store your PAT now.\n\n\n\n\n\n\nWe can also save our PAT in RStudio with: gitcreds::gitcreds_set()\nThis should result in the following message. Enter password or token: ghp_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\nAdding new credentialsâ€¦\nRemoving credentials from cacheâ€¦\nDone.\n\n\n\n\n\nSetup the remote GitHub repository\nNow letâ€™s setup a remote repo on GitHub using usethis::use_github. This section is straight out of 17.3 Happy git with R - create and connect a github repo with usethis.\nHow did that go? Did you get an error?\nDonâ€™t worry. Weâ€™ve forgotten to do an initial commit a common mistake. Click on the Commit button in the Git pane, select all (Ctrl/Cmd + Shift + A) and click Stage. We are going to stage all the files to push to our remote GitHub repo. This might be a bit slow since it is multiple files so be patient. Then, make a commit message in the top right of the window. Click Commit. This creates a record (or anchor in line with the climbing analogy below) in our project that we can view and go back to if we ever need to.\n\nOnce thatâ€™s complete, letâ€™s usethis::use_github() in the Console again. How did it go this time?\nHopefully, you see something like this: \nNotice that part of what use_github() does is push the master or main branch to GitHub. (Master is legacy, but you may still see it around.)\nNow go to the link there use_github() set the remote too (in the third line with a âœ”ï¸). You will see everything that youâ€™ve commited is now in the online, remote repo! Have a look around. You can navigate, add a README.md file, and even edit files in GitHub.\nLetâ€™s go ahead and edit a file. Go to the â€˜Welcomeâ€™ post, click on the pencil âœï¸ to edit, and make a change. At the bottom you can add a commit message then commit your change.\nCool, but how do we get these changes we made on our remote repo into our local repo on our computer? This is where pull comes in. Back in the RStudio Git pane, you should see a blue down arrow labelled Pull. Click this button. This will update your local repo on your computer with the edit we made in GitHub. Look at your files and see if you can find the change we just made online. Pulling is especially important if you are working on a collaborative project. In general, you want to pull first before pushing to ensure you are working with the most up-to-date version of the project. Even if you are not in a collaborative project, it is a good habit to get into.\nThose are the Git basics! In general, you want to use the following workflow when using git.\n\nMake a change in your files and save. The changes will not show up in the Git pane unless you save the changes.\nStage the files you would like to commit. Can stage multiple files at a time.\nWrite a concise, informative commit message and press the Commit button. If you donâ€™t get any glaringly obvious Error messages, itâ€™s probably all good.\nPull pressing the blue down arrow before pushing with the green up arrow.\nRepeat!"
  },
  {
    "objectID": "posts/build-blog-w-quarto/index.html#how-to-create-a-post-in-blogdown",
    "href": "posts/build-blog-w-quarto/index.html#how-to-create-a-post-in-blogdown",
    "title": "Build a blog with git, R, and quarto",
    "section": "How to create a post in blogdown",
    "text": "How to create a post in blogdown\nStarting with Git and GitHub:\n\n1. Fork the repo\n\nSign in with your GitHub account\nGo to the geocommunity/website repo\nPress the â€˜Forkâ€™ button at the top right. \nA forked copy of the repo should now be visible in your GitHub account. YOU/blog_website is the origin for your local copy of the repo in RStudio and geocommunity/blog_website is the upstream repo.\n\n\n\n\nScreenshot of a forked repo on GitHub.\n\n\n\n\n2. Clone the repo in a new RStudio project\n\nYou will need your GitHub credentials handy.\nYou can also set up RStudio so you do not need to input your GitHub credentials every time.\n\nFrom your forked repo, click on the green â€˜Codeâ€™ button and copy the link in the pop-up window.\n\n\n\nScreenshot of finding the url to clone.\n\n\nNext, in RStudio, go to File > New Project. In the pop-up window, click the last option â€˜Version Controlâ€™ and then â€˜Gitâ€™. In the following window, paste the url you copied from your forked GitHub repo in the first box which will automatically input the name of the project.\n\n\n\nPop-up windows of cloning a GitHub repo in RStudio\n\n\nConceptually, what we have done is:\n\n\n\nConceptual diagram of forking and cloning in GitHub Credit: Happy Git for the useR\n\n\nNow that we have cloned the repository, letâ€™s explore the file structure a little in the â€˜Filesâ€™ tab in RStudio. It is NOT a very intuitively set-up even for intermediate users of R. For the purposes of creating a new post to add to the blog, we are mostly concerned with the content/english/ directory that contains the post/ sub-directory.\nThe rest of the files are the â€˜backendâ€™ of the site using html, CSS, js, etc. to build the website. Have a look if you are curious but make changes at the risk of being â€˜that personâ€™ to break the site! But donâ€™t worry, since we are using Git version control all changes are tracked and reversible.\nNow that we are somewhat familiar with the project structure, letâ€™s create a new post.\n\n\n3. Create a new post\nIn our new RStudio project housing our forked and cloned GitHub repo of the website:\nUse blogdown::new_post(\"New post name\", ext = \".Rmd\") in the console to create a new post with a .Rmd extension. Alternatively, you can go to the Addins button under the menu and choose â€˜New Postâ€™ under the BLOGDOWN section and fill in the information in the pop-up window.\n\n\n\nA new blogdown post in RStudio.\n\n\n\nThis will create a new page/post bundle folder or sub-directory within post/ with the date and the name given in new_post() function. e.g., post/2021-11-18-New-post-name.\nAn index.Rmd file has been opened and only contains a YAML header (enclosed by ---). More on that later. Do not change the name of the .Rmd file.\nEach post gets its own bundle which is where your static post-specific files like images or data (.csv files etc.) used in your post should go.\nNote that the â€œNew post nameâ€ will not only be the incorporated into the sub-directory name, but also the url to the post. Read: choose wisely and concise > long descriptive name.\nThis â€œNew post nameâ€ will automatically be filled as the â€˜Title:â€™ in the .Rmd YAML heading. If you want a longer, descriptive title - change it in the YAML heading.\nIt is recommend you use either blogdown::new_post() or the Addin to create a new post instead of manually creating a new file (File > New File > R Markdown script)\n\nHere, we will stick with the .Rmd extension, but know there are a few file types:\n.md - markdown, cannot run code chunks\n.Rmd - R markdown -> rendered to .html using Pandoc\n.Rmarkdown - also R markdown -> compiled to .markdown documents\nIf you want more of this detailed stuff see: https://bookdown.org/yihui/blogdown/output-format.html.\n\n\n4. Commit the changes i.e., the new post\nLetâ€™s commit our new post. You can add something like a line of text, or not.\n\nIf you cloned the repo properly there should be a Git tab in the upper right hand window in RStudio where the Environment is. In the Git repo, there should be some files listed (i.e., post/2021-11-23-New-post-name) with different colored boxed under the â€˜Statusâ€™ column - hover with the cursor to see what they mean.\nCheck the â€˜Stagedâ€™ box for the files you want to include in this commit.\nClick the Commit button and a window will pop-up. In the bottom section, you will see the changes made to the file as additions (green) and deletions (red) - this is known as the diff in GitHub speak. For a new file, the whole thing will be green because it is all new.\nIn the â€˜Commit messageâ€™ box, add a concise but descriptive message of the changes like â€˜Added a new post bundle.â€™ Once you are happy with everything (file staged, commit messages, etc.) click the â€˜Commitâ€™ button.\n\n\n\n\nScreenshot of a forked repo on GitHub.\n\n\nSome stuff will happen and as long as you do not see any obvious errors then it has probably all gone well and youâ€™ve made your first commit!\n\n\n\nCelebrate! Credit: http://www.reactiongifs.com/cheering-minions/\n\n\nKnowing when and how often to commit is a bit of an art that comes with experience. In general, you want to commit changes that are related to a single problem and a good commit message. There is also a History button on the top left corner that will list all the commits with messages you have made and you can view the diff by clicking on a commit. All commits have a unique code which you can use to return to a previous commit etc.\nImportant notes:\n\nOnce you have served the site (see Step 6) it will create additional files within your post bundle directory. Be sure to commit all files in the post bundle created when knitting (/index.html, /index_files, etc.) not just the index.Rmd file as they will be necessary to build the site from GitHub. - You can stage them all together as one commit.\nYou will not be able to see diffs in the commit window until they have been saved.\n\nSee more on committing and best practices from the R packages book.\n\n\n\nHow committing goesâ€¦ Credit: xkcd comics\n\n\n\n\n5. Push the changes to GitHub\nThe changes and commits we have made are local, but we need to get them onto the GitHub repo and then the website. This is where we need to push.\nIn the Git window, you will see a blue down arrow for pulling and a green up arrow for pushing. You will also see a message along the lines of Your branch is ahead of 'origin/main' by X commits under those buttons.\nFor the purposes of contributing a post to a blogdown website, we will not worry about pulls and fetching upstream. This basically means keeping your origin/master repo synced with the original upstream repo that you forked.\nIf you stick to creating a new post bundle and only modifying files within the post bundles it should be okay without fetching upstream. BUT know that if you are using GitHub to work collaboratively, staying current with the original repo is important and in general it is a good practice to always pull before you push. Recommend Happy Git and GitHub for the useR as a trusty guide.\nIf you want to try fetching upstream it is easiest to do via GitHub. Followed by a pull in RStudio.\n\nLog into your GitHub account online, and navigate to your YOU/blog_website repo.\nUnder the green Code button, there should be a Fetch upstream button that will sync your forked repo with the original upstream repo.\nThere is information about the status of your branch compared to the original upstream repo e.g., â€˜up to dateâ€™ or â€˜X commits ahead/behindâ€™ to give you an idea if you need to fetch or not.\nNow in RStudio, you should be good to pull.\nRevisiting this diagram, the fetch upstream is updating your forked repo from the original yellow repo and then the pull is updating your local repo from your forked repo.\n\n\n\n\nDiagram of fetching upstream and pulling Credit: modified from Happy Git for the useR\n\n\nNow we will push our commits from or local repo to our remote origin/master repo on GitHub.\nIf this is your first time using Git with RStudio, you will have to set-up a personal access token or PAT in GitHub. For detailed directions, go to the GitHub page.\n\nGo to your GitHub account online and click on your profile photo in the upper-right and go to Settings.\nIn the left sidebar, click on Developer settings then Personal Access Tokens.\nClick the Generate a new token button and give a descriptive name and expiration.\nSelect scopes or privacy settings (defaults are generally fine) and the generate the token.\nCopy your PAT and put it in the password field for any pop-ups asking for your GitHub credentials when you push.\n\nIf you see HEAD -> main then all good.\n\n\n\nScreenshot of push window in RStudio.\n\n\nNow if you go back to your GitHub account and forked repo online, you should see the changes you made locally are now in the remote online repo and your commit message.\n\n\n\nScreenshot of pushed changes on forked GitHub repo.\n\n\nIn general, you should commit often and then push.\n\n\n6. Serve the site\nIn the console, run blogdown::serve_site(). Alternatively, can click on RStudio â€˜Addinsâ€™ and select â€˜Serve Siteâ€™. Be patient, but what happens?\n\n\n\nScreenshot of served site in RStudio.\n\n\nSome important information on what is going on from blogdown: Creating Websites with R Markdown:\n\nServing the site did the following: 1. Started a local Hugo server to help you preview your website, and 2. Knitted a sample .Rmd post to an .html page. You can see this from the progress message that printed to your console: Rendering content/english/post/2021-11-23-creating-a-post/index.Rmd... Done\n\nYou can also view the locally served website in a browser by clicking on the â€œShow in new windowâ€ button at the top left of the RStudio Viewer pane to the right of the broom.\nServing the site is using something called LiveReload:\n\nLetâ€™s introduce an important and helpful technology that you just used: LiveReload. Serving your site uses LiveReload, which means your website will be automatically rebuilt and reloaded in your web browser when you modify any source file of your website and save it. Basically, once you launch the website in a web browser, you do not need to rebuild it explicitly anymore. All you need to do is edit the source files, such as R Markdown documents, and save them. There is no need to click any buttons or run any commands. LiveReload is implemented via blogdown::serve_site() and Hugo, and you will only need to use it once per work session.\n\nRemember, every time you save your .Rmd file will activate the LiveReload. To stop serving the site locally run blogdown::stop_server() in the console.\n\n\n7. Create your content\nOnce the website is set-up, forked, and clonedâ€¦ you can get on with creating a new post with minimal coding. The main thing you will need to use is:\n\nR Markdown\nThis is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML documents that we can incorporate into the website. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nWhen you click the Knit button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. For a website post, knitting is not as important because we can serve our site locally which automatically knits anything new and view the changes as we just learned ðŸ‘†.\nNow letâ€™s add some information about R Markdown:\n\nYAML header\nThe YAML, or Yet Another Markdown Language, header at the top of the .Rmd is set between --- tags. Here is where information like the Title, Date, Author of the document go and will appear in the post.\nHave a look at previous posts and add any relevant tags or categories as you like.\nThe default .Rmd has some redundant settings (tags vs Tags) so if you use them stick with the lower case settings.\n\n\nFormatting\nCan bold and italicize text.\nHeadings:\nCan specify headings using # marks. The number of has symbols corresponds to the level of the header (2 hashs = level 2 header)\nThis will also create a structure outline of your document you can navigate either by using the â€˜Formattingâ€™ button at the bottom of the .Rmd or the right most button in the top right of the .Rmd.\n\n\n\nScreenshot of buttons to view document outline\n\n\nMake lists:\n\none\ntwo\nthree\n\nfull indent for sub-bullet\n\n\nOrdered lists:\n\nlists\nneed spaces\nbefore and after\n\nFor a return to start a new line, leave two spaces at the end of the line.\nLike this.\n\n\nIncluding code\nYou can embed an R code chunk like this:\n\nsummary(cars)\n\n     speed           dist       \n Min.   : 4.0   Min.   :  2.00  \n 1st Qu.:12.0   1st Qu.: 26.00  \n Median :15.0   Median : 36.00  \n Mean   :15.4   Mean   : 42.98  \n 3rd Qu.:19.0   3rd Qu.: 56.00  \n Max.   :25.0   Max.   :120.00  \n\n\nThere is also inline code: The mean of speed in the cars data set is 15.4.\n\n\nInclude mathematical notation\nMathematical notation can be enabled using third party JavaScript libraries like KaTeX. See resource of supported TeX functions. For these to render correctly you must add math: true to the YAML header at the top of the .Rmd.\nTo enter equations like a code chunk or block math, use two $ on separate lines surrounding your equations.\nPut two \\ after a line for a full return.\n\\[\ny = mx + \\beta\\\\\nE = mc^2\n\\]\n\\[ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } \\]\nYou can also use inline math notation by sandwiching it between $ without spaces. Like so \\(\\mu = 0.2566\\).\nAnother inline way: (= = 1.6180339887â€¦)\n\n\nIncluding Plots\nYou can also embed plots, for example:\n\n\n\n\n\n\n\nChunk options\nChunks are the gray areas in the .Rmd file where you can add code that will be run. These are defined by three back ticks (not a single quote, the key to the left of the 1). You can insert R code chunks but also in other languages! See the green â€˜Insertâ€™ code chunk button to see different options. An R code chunk will have the an {r  } after the opening back ticks.\nThe keyboard short cut to add an R code chunk is Ctrl + Alt + I\nYou can also set options in the {} of a chunk like hide the code chunk (echo = FALSE), suppress warnings (warnings = FALSE), and cache the chunk (cache = TRUE) if you have something that takes a while to run.\nLetâ€™s set echo = FALSE for our plot chunk above. We are only interested in seeing the plot, not the code that produces the plot.\nYou can add a code chunk at the beginning of the .Rmd file and set global options that will apply to the whole document.\n\nknitr::opts_chunk$set(echo = TRUE)\n\nSee more at:\n\nRStudio - https://rmarkdown.rstudio.com/lesson-3.html\nR Markdown Cookbook - https://bookdown.org/yihui/rmarkdown-cookbook/\n\nIt is also a good idea to name your chunks as chunks are included in the document outline. Chunks cannot have the same name - you will get an error.\n\n\nInsert objects\nYou can add pictures, weblinks, and GIFs in R Markdown. They all follow the similar hyperlink formats.\nFor a hyperlink to a website you put the word you want to hyperlink in square brackets [] followed immediately (no spaces or characters) by round parentheses (). E.g. [GitHub](www.github.com)\nTo insert an image or gif from a website you add a ! before the square brackets like so: ![description](https://media.giphy.com/media/sJWNLTclcvVmw/giphy.gif). The description in the [] will appear as a caption and the link must end in the appropriate file extension (.gif, .jpg, .png, etc) to work.\n\n\n\nFunny Yawn Credit: https://www.reddit.com/r/gifs/comments/54q75s/goodnight_tongue/\n\n\nYou can also insert pictures using the RStudio â€˜Addinsâ€™ > â€˜Insert Imageâ€™ and uploading an image saved on your computer with a few other options like alt text. This will result in the same hyperlink code as inserting an image, but with a relative path instead of the url.\nExample use Addin to insert image\nYou can also save files (like images, html presentations) in your post bundle to link using relative paths on your own.\n\n\n\n\n7. Pull Request\nOkay, so as you were creating the content of your post you should have been committing regularly and then pushing, right?\nLetâ€™s say we are finished with our beautiful post and read to incorporate it into the original upstream repo geocommunity/blog_website that we forked from. Remember, when we push we are pushing the commits we made locally on our computer to our YOU/blog_website repo that we forked from the original repo.\nBecause we are not owner/developers of the upstream geocommunity/blog_website repo we need to submit a pull request to submit our new blog post for approval into the upstream repo.\n\nOn your YOU/blog_website repo in your GitHub account, click on Pull requests.\nOn the right of the screen, there should be a green New pull request button. This will take to you a â€˜Comparing changesâ€™ window outlining the files and changes you have made. This will alert you to any merge conflicts with the original upstream repo. Again, sticking to creating a new post bundle/content should avoid any merge conflicts.\nClick the green Create pull request button on the right. This will take you to a â€˜Open a pull requestâ€™ window that will have your last commit and space to add a larger message with your pull request or PR.\nOnce you are happy, click the green button at the end and wait for approval. You can have a bit of a conversation to hash out any issues as well over the approval process.\n\n\n\n\nScreenshot of GitHub open a pull request.\n\n\nCongratulations - now you have submitted your blog post to a blogdown site!\n\n\n\nCheers Credit: Sony"
  },
  {
    "objectID": "posts/build-blog-w-quarto/index.html#troubleshooting",
    "href": "posts/build-blog-w-quarto/index.html#troubleshooting",
    "title": "Build a blog with Quarto, git, RStudio",
    "section": "Troubleshootingâ€¦",
    "text": "Troubleshootingâ€¦\nLetâ€™s face it, the likelihood of something going awry following this tutorial is not 0â€¦ Few things that might help along the way:\n\nSometimes it is difficult to tell when the â€˜LiveReloadâ€™ has finished or if you are used to saving regularly every few minutes that constant updating of â€˜LiveReloadâ€™ can freeze RStudio.\n\nSolution: The good â€™ole Restart R (Session > Restart R) or close and re-open.\n\nFormatting wise, itâ€™s a good idea to put full line returns before/after formatting bits like lists and inserting images. Something to check if your content is not formatting as you expect.\nOTHERS??"
  },
  {
    "objectID": "posts/build-blog-w-quarto/index.html#resources-mentioned",
    "href": "posts/build-blog-w-quarto/index.html#resources-mentioned",
    "title": "Build a blog with Quarto, git, RStudio",
    "section": "Resources mentioned:",
    "text": "Resources mentioned:\n\nCreating Websites with R Markdown by Yihui Xi, Amber Thomas, and Alison Presmanes Hill.\nâ€œUp & running with blogdown in 2021â€ Alison Hill.\nâ€œCreating a Geospatial Blog with blogdownâ€ on the UQGSAC blog by Mitch Rudge and StÃ©phane Guillou.\nExcuse me, do you have a moment to talk about version control? by Jenny Bryan\nHappy Git and GitHub for the useR by Jenny Bryan.\nGetting Started with GitHub R Ladies Brisbane presentation by Caitie Kuemple.\ngeocommunity/website GitHub repo\n18.6 Commit best practices from the R packages book by Hadley Wickham and Jenny Bryan.\nR Markdown\nKaTeX - Supported Functions\nCode Chuncks\nR Markdown Cookbook by Yihui Xie, Christophe Dervieux, Emily Riederer."
  },
  {
    "objectID": "posts/geospatial-blog-w-blogdown/index.html",
    "href": "posts/geospatial-blog-w-blogdown/index.html",
    "title": "Creating a geospatial blog with blogdown",
    "section": "",
    "text": "Note\n\n\n\nThis blog is now on quarto and thus some of the information below may be out of date.\nCheck out the updated post - Building a blog with git, GitHub, R, and quarto.\nIn this post, we will go through the process of creating a geospatial blog, specifically this blog.\nFirst, we will run through how to create a site and host it through github and netlify. Then we will show you the options for publishing both a raster and vector data."
  },
  {
    "objectID": "posts/geospatial-blog-w-blogdown/index.html#good-resources",
    "href": "posts/geospatial-blog-w-blogdown/index.html#good-resources",
    "title": "Creating a geospatial blog with blogdown",
    "section": "Good resources",
    "text": "Good resources\n\nhttps://www.apreshill.com/blog/2020-12-new-year-new-blogdown/\nhttps://www.youtube.com/watch?v=x-Ch0-w1UhY\nhttps://solomonkurz.netlify.app/post/2021-05-03-blogdown-updates-prompted-a-website-overhaul-these-are-my-notes/\nhttps://bookdown.org/yihui/blogdown/installation.html"
  },
  {
    "objectID": "posts/geospatial-blog-w-blogdown/index.html#prerequisites",
    "href": "posts/geospatial-blog-w-blogdown/index.html#prerequisites",
    "title": "Creating a geospatial blog with blogdown",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nFairly recent version of R studio (RStudio IDE version, v1.4.1106 +)\nGithub account\nGIT locally on computer. (Happy git with R https://happygitwithr.com/)\n\ngitforwindows.org\nDownload GNU\nDefault on all settings ï‚§ Make sure to select Git from the command line and also from 3rd party software\n\nSign up for Netlify using Github account"
  },
  {
    "objectID": "posts/geospatial-blog-w-blogdown/index.html#create-a-new-github-repository",
    "href": "posts/geospatial-blog-w-blogdown/index.html#create-a-new-github-repository",
    "title": "Creating a geospatial blog with blogdown",
    "section": "1. Create a new github repository",
    "text": "1. Create a new github repository\nInitialise with readme, but donâ€™t add the .gitignore file. Then copy link https link."
  },
  {
    "objectID": "posts/geospatial-blog-w-blogdown/index.html#create-a-new-project-in-r-studio",
    "href": "posts/geospatial-blog-w-blogdown/index.html#create-a-new-project-in-r-studio",
    "title": "Creating a geospatial blog with blogdown",
    "section": "2. Create a new project in R studio",
    "text": "2. Create a new project in R studio\nIn R studio, go to File > new project > Version control > git, and Paste the URL from before. Save the project somewhere sensible.\nNow install blogdown with Install.packages(â€œblogdownâ€), and load with library(blogdown).\n\ninstall.packages(\"blogdown\")\nlibrary(blogdown)\n\nNow to create a new site, just add\n\nnew_site()\n\nThis will give the default theme, but there are a lot of different themes to choose from!\nhttps://themes.gohugo.io/\nIts important to find one that you like, but also that is up to date and works. For this blog, we ended up going with https://themes.gohugo.io/themes/anatole/ over some other options which were buggy, probably due to being out of date.\nSo to build the site with your theme of choice, run\n\nnew_site(theme = \"lxndrblz/anatole\")\n\nAdding theme= â€œgighubusername/themerepoâ€ of the theme you choose.\nWhen prompted, select y to let blogdown start a server. This will let you preview the site in the viewer. To view in a browser, click the show in new window (next to the broom) to launch it locally.\nGenerally, you can serve the site, and stop serving the sites using\n\nblogdown::serve_site() #to serve the site locally\nblogdown::stop_server() #to stop serving the site"
  },
  {
    "objectID": "posts/geospatial-blog-w-blogdown/index.html#write-a-post",
    "href": "posts/geospatial-blog-w-blogdown/index.html#write-a-post",
    "title": "Creating a geospatial blog with blogdown",
    "section": "3. Write a post",
    "text": "3. Write a post\nHopefully the local site is working. We can now add a new blog post using either\n\nblogdown::new_post() \n\nOR, a better method is to navigate through addins dropdown (under help, right of git icon), click new_post. This brings up a dialog to fill out.\nSelect file type, markdown for simple text, or .Rmd or .Rmarkdown for embedding code.\nNow we can add code chunks! The easiest way to do this is to click the green +c just above the editor.\nAs an example\n\nlibrary(ggplot2)\nggplot(Orange, aes(x = age, \n                   y = circumference, \n                   color = Tree)) +\n  geom_point() +\n  theme_bw()\n\n\n\n\nIf its not working, run\n\nblogdown::check_site() \n\nand follow the instructions next to the [todo] items."
  },
  {
    "objectID": "posts/geospatial-blog-w-blogdown/index.html#load-to-github",
    "href": "posts/geospatial-blog-w-blogdown/index.html#load-to-github",
    "title": "Creating a geospatial blog with blogdown",
    "section": "4. load to github",
    "text": "4. load to github\nIn the files tab, navigate to the .gitignore file. Add so it contains the following .Rproj.user .Rhistory .RData .Ruserdata .DS_Store Thumbs.db /public/ /resources/\nNow run\n\nblogdown::check_gitignore() \n\n#and \n\nblogdown::check_content()\n\nThen commit the files and push to github.\nDue to the massive number of files associated with the themes, we found it better to do the first commit through the shell\nTools>shell>git add -A\nTo authorise github, we found the best option to be to\nControl Panel > User Account > Credential Manager > Windows Credential > Generic Credential\nThen remove git credential\nThen, when you push the repo itâ€™ll ask you for credential through the browser."
  },
  {
    "objectID": "posts/geospatial-blog-w-blogdown/index.html#publish-site",
    "href": "posts/geospatial-blog-w-blogdown/index.html#publish-site",
    "title": "Creating a geospatial blog with blogdown",
    "section": "5. Publish site!",
    "text": "5. Publish site!\nLog into netlify (using github account). Then click new site from git, continuous deployment: Github. you should be able to see the repo from within netlify. Select deploy site.\nIt will give you a temporary URL which is live! Now it will automatically update every time you push changes to github.\nTo change the site name, general > site details > change site name\nNow go back to R studio, and navigate to teh config (yaml or toml) and add in the correct url (probably around line 3)\nRun Blogdown::check_netlify() to find any issues."
  },
  {
    "objectID": "posts/geospatial-blog-w-blogdown/index.html#load-necessary-packages",
    "href": "posts/geospatial-blog-w-blogdown/index.html#load-necessary-packages",
    "title": "Creating a geospatial blog with blogdown",
    "section": "Load necessary packages",
    "text": "Load necessary packages\n\nlibrary(sf)\n\nLinking to GEOS 3.9.1, GDAL 3.3.2, PROJ 7.2.1; sf_use_s2() is TRUE\n\nlibrary(tmap)"
  },
  {
    "objectID": "posts/geospatial-blog-w-blogdown/index.html#get-the-data",
    "href": "posts/geospatial-blog-w-blogdown/index.html#get-the-data",
    "title": "Creating a geospatial blog with blogdown",
    "section": "Get the data",
    "text": "Get the data\nThe process to get the data is stored in a script (scripts/get_osm_data.R), instead of integrating it into this R Markdown file. This allows us to not overload the data provider but always querying the API, every single time the article is rendered! (And we donâ€™t need to process the data every time either.)\nHere, we only need to read the data from a file that was previously created:\n\ngreen_space <- st_read(\"data/green_spaces.geojson\")\n\nReading layer `green_spaces' from data source \n  `C:\\Users\\jk845\\OneDrive\\R\\geocommunity_blog\\posts\\geospatial-blog-w-blogdown\\data\\green_spaces.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 5861 features and 3 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 152.6764 ymin: -27.67486 xmax: 153.4664 ymax: -27.00613\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "posts/geospatial-blog-w-blogdown/index.html#visualise-on-a-slippy-map",
    "href": "posts/geospatial-blog-w-blogdown/index.html#visualise-on-a-slippy-map",
    "title": "Creating a geospatial blog with blogdown",
    "section": "Visualise on a slippy map",
    "text": "Visualise on a slippy map\nThe tmap package is useful to visualise vector data on a slippy map.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(green_space) +\n  tm_polygons(col = c(\"#43C467\"), alpha = 0.5)\n\n\n\n\n\n\n\nData is copyright OSM contributors but release under an ODBL licence."
  },
  {
    "objectID": "posts/geospatial-blog-w-blogdown/index.html#load-the-packages",
    "href": "posts/geospatial-blog-w-blogdown/index.html#load-the-packages",
    "title": "Creating a geospatial blog with blogdown",
    "section": "Load the packages",
    "text": "Load the packages\n\nlibrary(terra)\n\nterra 1.5.34"
  },
  {
    "objectID": "posts/geospatial-blog-w-blogdown/index.html#import-the-data",
    "href": "posts/geospatial-blog-w-blogdown/index.html#import-the-data",
    "title": "Creating a geospatial blog with blogdown",
    "section": "Import the data",
    "text": "Import the data\nThe data comes from the Bureau of Meteorology website, it is a raster file of average annual rainfall. Weâ€™ve put the file into a data directory, inside the blog postâ€™s directory.\n\nrain <- rast(\"data/rainan.txt\")"
  },
  {
    "objectID": "posts/geospatial-blog-w-blogdown/index.html#inspect",
    "href": "posts/geospatial-blog-w-blogdown/index.html#inspect",
    "title": "Creating a geospatial blog with blogdown",
    "section": "Inspect",
    "text": "Inspect\n\nrain\n\nclass       : SpatRaster \ndimensions  : 691, 886, 1  (nrow, ncol, nlyr)\nresolution  : 0.05, 0.05  (x, y)\nextent      : 111.975, 156.275, -44.525, -9.975  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 \nsource      : rainan.txt \nname        : rainan \n\n\nOne single band, by default with the WGS 84 CRS.\nThe average rainfall for the whole raster is 451.61 mm."
  },
  {
    "objectID": "posts/geospatial-blog-w-blogdown/index.html#visualise",
    "href": "posts/geospatial-blog-w-blogdown/index.html#visualise",
    "title": "Creating a geospatial blog with blogdown",
    "section": "Visualise",
    "text": "Visualise\nMake sure to add a caption to visualisations, and some alternative text if needed!\n\nplot(rain)\n\n\n\n\nAverage annual rainfall in mm (1980 to 2010)"
  },
  {
    "objectID": "posts/how-to-contribute-post/index.html",
    "href": "posts/how-to-contribute-post/index.html",
    "title": "How to contribute a post",
    "section": "",
    "text": "We will be covering some basics of multiple programming skills (Git/GitHub, R, html, etcâ€¦) with the aim of empowering people to contribute to blogdown websites such as the University of Queensland Geospatial Analysis Community of practice (UQGAC) blog. The idea is to encourage community members to contribute material directly instead of funneling everything through a website administrator."
  },
  {
    "objectID": "posts/how-to-contribute-post/index.html#geospatial-analysis-community-of-practice---the-university-of-queensland-uqgac",
    "href": "posts/how-to-contribute-post/index.html#geospatial-analysis-community-of-practice---the-university-of-queensland-uqgac",
    "title": "How to contribute a post",
    "section": "Geospatial Analysis Community of Practice - The University of Queensland (UQGAC)",
    "text": "Geospatial Analysis Community of Practice - The University of Queensland (UQGAC)\nUnveil the new website!\nPoint of contact - Mitchel Rudge: mitchel.rudge@uq.edu.au\nSee the About page for more info."
  },
  {
    "objectID": "posts/how-to-contribute-post/index.html#creating-a-post-on-the-uqgac-website",
    "href": "posts/how-to-contribute-post/index.html#creating-a-post-on-the-uqgac-website",
    "title": "How to contribute a post",
    "section": "Creating a post on the UQGAC website",
    "text": "Creating a post on the UQGAC website\nCatherine Kim, PhD\nPostdoctoral Associate, School of Biological Sciences\nTechnology Trainer, UQ Library\nTwitter: @fishiintheC\nWhat we will cover:\n\nblogdown basics\nGit and GitHub basics\nHow to create a post on the UQGSAC blogdown website\nR Markdown basics\n\nI have pieced this together using many other resources on the above which are mentioned throughout. Thank you to Mitch and StÃ©phane for their help with this tutorial and workshop!\nWhat you will need:\n\nInstallations - R, RStudio, Git\nA GitHub account (free) with your login and personal access token (PAT) details handy"
  },
  {
    "objectID": "posts/how-to-contribute-post/index.html#blogdown-basics",
    "href": "posts/how-to-contribute-post/index.html#blogdown-basics",
    "title": "How to contribute a post",
    "section": "blogdown basics",
    "text": "blogdown basics\nblogdown is an R package that allows the creation of websites using R Markdown and Hugo, a static site generator. blogdown websites in R have been all the rage the last few years and you have probably seen many â€˜Hugo-Academic themeâ€™ personal websites - all built in R!\n\n\n\nblogdown hex sticker Credit: Creating Website with R Markdown\n\n\n\nThere is a short online book on blogdown written by the developer, Yihui and others.\nA recent article by Allison Hill on starting your own blogdown website from scratch.\nSee Mitch and StÃ©phaneâ€™s tutorial for UQGSAC on creating a blogdown website.\n\nThis session focuses on how to go about contributing a post to an existing website.\nThe UQGSAC website is built using the anatole theme. There are many themes to choose from and if you know html/CSS you can even build your own theme.\nSo, how do we go about contributing to a blogdown website?\n\n\n\nProgrammer GIF Credit: Capgemini India on GIPHY\n\n\nA good place to start is making sure you have installed the blogdown package:\n\ninstall.packages(\"blogdown\")\n\nArticle about setting global options in blogdown if you need to set the Hugo version in your .Rprofile (blogdown::config_Rprofile()).\nTo allow multiple people to contribute to the same website, the website is hosted on GitHub and Netlify.\nAs the website is already set-up, we will be dealing with Git + GitHub and R + RStudio + R Markdown."
  },
  {
    "objectID": "posts/how-to-contribute-post/index.html#git---what-is-it",
    "href": "posts/how-to-contribute-post/index.html#git---what-is-it",
    "title": "How to contribute a post",
    "section": "Git - what is it?",
    "text": "Git - what is it?\nA version control software (think track changes) useful for collaborating on and sharing code.\nGit is the software itself that records changes to a set of files locally. There are several hosting platforms that are like online repositories (think Dropbox, Google Drive, etc.) that work with Git: Bitbucket, GitLab, and GitHub to name a few.\nThese platforms not only allow for version control but also to collaborate, organize, and back up projects.\nIn this case, we will be using GitHub to access the website files, make some changes (i.e., add a post), and then incorporate those changes back to the website repository on GitHub which will automatically update the website itself. ðŸ™Œ\nWe will focus on contributing a post to an existing website repository on GitHub, but there are lots of fabulous and free resources online that go more into depth on Git:\n\nIf you need to be convinced to use Git for version control see this article and Happy Git and GitHub for the useR to git started both by Git/R guru Jenny Bryan.\nSee Caitie Kuempelâ€™s R Ladies Brisbane presentation on getting started with GitHub in RStudio.\n\n\nGit Terminology\nRepository/repo - where a project is stored in GitHub. Think of it like a folder holding all the relevant documents that you can version control, view history, and add collaborators. The repository or repo holds all the relevant files for the website - most of which we will not touch.\nFork - A copy of another userâ€™s repo on your account. This allows you to freely change a project without affecting the original upstream repo. You can keep your fork synced with changes in the original repo. - this is fetching upstream.\nClone - a copy of a repository that lives on your computer instead of a website server like GitHub. Is still connected to the remote repo online and you can push/pull edits.\nCommit - is one or more changes to a file or set of files that you are asking GitHub to keep track of.\nPush - sending your committed changes to a remote repository on GitHub. Local changes updated on the GitHub website where other people can access.\nPull - incorporating and merging changes. An edit on the remote repository on GitHub can be pulled to a local repository.\nDiff - difference, or changes made that are visible as insertions/deletions for a commit.\nMain/Master - the default branch you are on. Master has recently updated to main, but they are the same thing. You are more likely to come across master on older resources. Jenny Bryan strongly urges you to create a new branch to work off of which requires using command line. For the purpose of contributing to a blogdown website, I will forgo covering this as it is unlikely more than one person will be contributing at the same time.\nOrigin - the remote repo online from which you have cloned your local copy from."
  },
  {
    "objectID": "posts/how-to-contribute-post/index.html#how-to-create-a-post-in-blogdown",
    "href": "posts/how-to-contribute-post/index.html#how-to-create-a-post-in-blogdown",
    "title": "How to contribute a post",
    "section": "How to create a post in blogdown",
    "text": "How to create a post in blogdown\nStarting with Git and GitHub:\n\n1. Fork the repo\n\nSign in with your GitHub account\nGo to the geocommunity/website repo\nPress the â€˜Forkâ€™ button at the top right. \nA forked copy of the repo should now be visible in your GitHub account. YOU/blog_website is the origin for your local copy of the repo in RStudio and geocommunity/blog_website is the upstream repo.\n\n\n\n\nScreenshot of a forked repo on GitHub.\n\n\n\n\n2. Clone the repo in a new RStudio project\n\nYou will need your GitHub credentials handy.\nYou can also set up RStudio so you do not need to input your GitHub credentials every time.\n\nFrom your forked repo, click on the green â€˜Codeâ€™ button and copy the link in the pop-up window.\n\n\n\nScreenshot of finding the url to clone.\n\n\nNext, in RStudio, go to File > New Project. In the pop-up window, click the last option â€˜Version Controlâ€™ and then â€˜Gitâ€™. In the following window, paste the url you copied from your forked GitHub repo in the first box which will automatically input the name of the project.\n\n\n\nPop-up windows of cloning a GitHub repo in RStudio\n\n\nConceptually, what we have done is:\n\n\n\nConceptual diagram of forking and cloning in GitHub Credit: Happy Git for the useR\n\n\nNow that we have cloned the repository, letâ€™s explore the file structure a little in the â€˜Filesâ€™ tab in RStudio. It is NOT a very intuitively set-up even for intermediate users of R. For the purposes of creating a new post to add to the blog, we are mostly concerned with the content/english/ directory that contains the post/ sub-directory.\nThe rest of the files are the â€˜backendâ€™ of the site using html, CSS, js, etc. to build the website. Have a look if you are curious but make changes at the risk of being â€˜that personâ€™ to break the site! But donâ€™t worry, since we are using Git version control all changes are tracked and reversible.\nNow that we are somewhat familiar with the project structure, letâ€™s create a new post.\n\n\n3. Create a new post\nIn our new RStudio project housing our forked and cloned GitHub repo of the website:\nUse blogdown::new_post(\"New post name\", ext = \".Rmd\") in the console to create a new post with a .Rmd extension. Alternatively, you can go to the Addins button under the menu and choose â€˜New Postâ€™ under the BLOGDOWN section and fill in the information in the pop-up window.\n\n\n\nA new blogdown post in RStudio.\n\n\n\nThis will create a new page/post bundle folder or sub-directory within post/ with the date and the name given in new_post() function. e.g., post/2021-11-18-New-post-name.\nAn index.Rmd file has been opened and only contains a YAML header (enclosed by ---). More on that later. Do not change the name of the .Rmd file.\nEach post gets its own bundle which is where your static post-specific files like images or data (.csv files etc.) used in your post should go.\nNote that the â€œNew post nameâ€ will not only be the incorporated into the sub-directory name, but also the url to the post. Read: choose wisely and concise > long descriptive name.\nThis â€œNew post nameâ€ will automatically be filled as the â€˜Title:â€™ in the .Rmd YAML heading. If you want a longer, descriptive title - change it in the YAML heading.\nIt is recommend you use either blogdown::new_post() or the Addin to create a new post instead of manually creating a new file (File > New File > R Markdown script)\n\nHere, we will stick with the .Rmd extension, but know there are a few file types:\n.md - markdown, cannot run code chunks\n.Rmd - R markdown -> rendered to .html using Pandoc\n.Rmarkdown - also R markdown -> compiled to .markdown documents\nIf you want more of this detailed stuff see: https://bookdown.org/yihui/blogdown/output-format.html.\n\n\n4. Commit the changes i.e., the new post\nLetâ€™s commit our new post. You can add something like a line of text, or not.\n\nIf you cloned the repo properly there should be a Git tab in the upper right hand window in RStudio where the Environment is. In the Git repo, there should be some files listed (i.e., post/2021-11-23-New-post-name) with different colored boxed under the â€˜Statusâ€™ column - hover with the cursor to see what they mean.\nCheck the â€˜Stagedâ€™ box for the files you want to include in this commit.\nClick the Commit button and a window will pop-up. In the bottom section, you will see the changes made to the file as additions (green) and deletions (red) - this is known as the diff in GitHub speak. For a new file, the whole thing will be green because it is all new.\nIn the â€˜Commit messageâ€™ box, add a concise but descriptive message of the changes like â€˜Added a new post bundle.â€™ Once you are happy with everything (file staged, commit messages, etc.) click the â€˜Commitâ€™ button.\n\n\n\n\nScreenshot of a forked repo on GitHub.\n\n\nSome stuff will happen and as long as you do not see any obvious errors then it has probably all gone well and youâ€™ve made your first commit!\n\n\n\nCelebrate! Credit: http://www.reactiongifs.com/cheering-minions/\n\n\nKnowing when and how often to commit is a bit of an art that comes with experience. In general, you want to commit changes that are related to a single problem and a good commit message. There is also a History button on the top left corner that will list all the commits with messages you have made and you can view the diff by clicking on a commit. All commits have a unique code which you can use to return to a previous commit etc.\nImportant notes:\n\nOnce you have served the site (see Step 6) it will create additional files within your post bundle directory. Be sure to commit all files in the post bundle created when knitting (/index.html, /index_files, etc.) not just the index.Rmd file as they will be necessary to build the site from GitHub. - You can stage them all together as one commit.\nYou will not be able to see diffs in the commit window until they have been saved.\n\nSee more on committing and best practices from the R packages book.\n\n\n\nHow committing goesâ€¦ Credit: xkcd comics\n\n\n\n\n5. Push the changes to GitHub\nThe changes and commits we have made are local, but we need to get them onto the GitHub repo and then the website. This is where we need to push.\nIn the Git window, you will see a blue down arrow for pulling and a green up arrow for pushing. You will also see a message along the lines of Your branch is ahead of 'origin/main' by X commits under those buttons.\nFor the purposes of contributing a post to a blogdown website, we will not worry about pulls and fetching upstream. This basically means keeping your origin/master repo synced with the original upstream repo that you forked.\nIf you stick to creating a new post bundle and only modifying files within the post bundles it should be okay without fetching upstream. BUT know that if you are using GitHub to work collaboratively, staying current with the original repo is important and in general it is a good practice to always pull before you push. Recommend Happy Git and GitHub for the useR as a trusty guide.\nIf you want to try fetching upstream it is easiest to do via GitHub. Followed by a pull in RStudio.\n\nLog into your GitHub account online, and navigate to your YOU/blog_website repo.\nUnder the green Code button, there should be a Fetch upstream button that will sync your forked repo with the original upstream repo.\nThere is information about the status of your branch compared to the original upstream repo e.g., â€˜up to dateâ€™ or â€˜X commits ahead/behindâ€™ to give you an idea if you need to fetch or not.\nNow in RStudio, you should be good to pull.\nRevisiting this diagram, the fetch upstream is updating your forked repo from the original yellow repo and then the pull is updating your local repo from your forked repo.\n\n\n\n\nDiagram of fetching upstream and pulling Credit: modified from Happy Git for the useR\n\n\nNow we will push our commits from or local repo to our remote origin/master repo on GitHub.\nIf this is your first time using Git with RStudio, you will have to set-up a personal access token or PAT in GitHub. For detailed directions, go to the GitHub page.\n\nGo to your GitHub account online and click on your profile photo in the upper-right and go to Settings.\nIn the left sidebar, click on Developer settings then Personal Access Tokens.\nClick the Generate a new token button and give a descriptive name and expiration.\nSelect scopes or privacy settings (defaults are generally fine) and the generate the token.\nCopy your PAT and put it in the password field for any pop-ups asking for your GitHub credentials when you push.\n\nIf you see HEAD -> main then all good.\n\n\n\nScreenshot of push window in RStudio.\n\n\nNow if you go back to your GitHub account and forked repo online, you should see the changes you made locally are now in the remote online repo and your commit message.\n\n\n\nScreenshot of pushed changes on forked GitHub repo.\n\n\nIn general, you should commit often and then push.\n\n\n6. Serve the site\nIn the console, run blogdown::serve_site(). Alternatively, can click on RStudio â€˜Addinsâ€™ and select â€˜Serve Siteâ€™. Be patient, but what happens?\n\n\n\nScreenshot of served site in RStudio.\n\n\nSome important information on what is going on from blogdown: Creating Websites with R Markdown:\n\nServing the site did the following: 1. Started a local Hugo server to help you preview your website, and 2. Knitted a sample .Rmd post to an .html page. You can see this from the progress message that printed to your console: Rendering content/english/post/2021-11-23-creating-a-post/index.Rmd... Done\n\nYou can also view the locally served website in a browser by clicking on the â€œShow in new windowâ€ button at the top left of the RStudio Viewer pane to the right of the broom.\nServing the site is using something called LiveReload:\n\nLetâ€™s introduce an important and helpful technology that you just used: LiveReload. Serving your site uses LiveReload, which means your website will be automatically rebuilt and reloaded in your web browser when you modify any source file of your website and save it. Basically, once you launch the website in a web browser, you do not need to rebuild it explicitly anymore. All you need to do is edit the source files, such as R Markdown documents, and save them. There is no need to click any buttons or run any commands. LiveReload is implemented via blogdown::serve_site() and Hugo, and you will only need to use it once per work session.\n\nRemember, every time you save your .Rmd file will activate the LiveReload. To stop serving the site locally run blogdown::stop_server() in the console.\n\n\n7. Create your content\nOnce the website is set-up, forked, and clonedâ€¦ you can get on with creating a new post with minimal coding. The main thing you will need to use is:\n\nR Markdown\nThis is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML documents that we can incorporate into the website. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nWhen you click the Knit button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. For a website post, knitting is not as important because we can serve our site locally which automatically knits anything new and view the changes as we just learned ðŸ‘†.\nNow letâ€™s add some information about R Markdown:\n\nYAML header\nThe YAML, or Yet Another Markdown Language, header at the top of the .Rmd is set between --- tags. Here is where information like the Title, Date, Author of the document go and will appear in the post.\nHave a look at previous posts and add any relevant tags or categories as you like.\nThe default .Rmd has some redundant settings (tags vs Tags) so if you use them stick with the lower case settings.\n\n\nFormatting\nCan bold and italicize text.\nHeadings:\nCan specify headings using # marks. The number of has symbols corresponds to the level of the header (2 hashs = level 2 header)\nThis will also create a structure outline of your document you can navigate either by using the â€˜Formattingâ€™ button at the bottom of the .Rmd or the right most button in the top right of the .Rmd.\n\n\n\nScreenshot of buttons to view document outline\n\n\nMake lists:\n\none\ntwo\nthree\n\nfull indent for sub-bullet\n\n\nOrdered lists:\n\nlists\nneed spaces\nbefore and after\n\nFor a return to start a new line, leave two spaces at the end of the line.\nLike this.\n\n\nIncluding code\nYou can embed an R code chunk like this:\n\nsummary(cars)\n\n     speed           dist       \n Min.   : 4.0   Min.   :  2.00  \n 1st Qu.:12.0   1st Qu.: 26.00  \n Median :15.0   Median : 36.00  \n Mean   :15.4   Mean   : 42.98  \n 3rd Qu.:19.0   3rd Qu.: 56.00  \n Max.   :25.0   Max.   :120.00  \n\n\nThere is also inline code: The mean of speed in the cars data set is 15.4.\n\n\nInclude mathematical notation\nMathematical notation can be enabled using third party JavaScript libraries like KaTeX. See resource of supported TeX functions. For these to render correctly you must add math: true to the YAML header at the top of the .Rmd.\nTo enter equations like a code chunk or block math, use two $ on separate lines surrounding your equations.\nPut two \\ after a line for a full return.\n\\[\ny = mx + \\beta\\\\\nE = mc^2\n\\]\n\\[ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } \\]\nYou can also use inline math notation by sandwiching it between $ without spaces. Like so \\(\\mu = 0.2566\\).\nAnother inline way: (= = 1.6180339887â€¦)\n\n\nIncluding Plots\nYou can also embed plots, for example:\n\n\n\n\n\n\n\nChunk options\nChunks are the gray areas in the .Rmd file where you can add code that will be run. These are defined by three back ticks (not a single quote, the key to the left of the 1). You can insert R code chunks but also in other languages! See the green â€˜Insertâ€™ code chunk button to see different options. An R code chunk will have the an {r  } after the opening back ticks.\nThe keyboard short cut to add an R code chunk is Ctrl + Alt + I\nYou can also set options in the {} of a chunk like hide the code chunk (echo = FALSE), suppress warnings (warnings = FALSE), and cache the chunk (cache = TRUE) if you have something that takes a while to run.\nLetâ€™s set echo = FALSE for our plot chunk above. We are only interested in seeing the plot, not the code that produces the plot.\nYou can add a code chunk at the beginning of the .Rmd file and set global options that will apply to the whole document.\n\nknitr::opts_chunk$set(echo = TRUE)\n\nSee more at:\n\nRStudio - https://rmarkdown.rstudio.com/lesson-3.html\nR Markdown Cookbook - https://bookdown.org/yihui/rmarkdown-cookbook/\n\nIt is also a good idea to name your chunks as chunks are included in the document outline. Chunks cannot have the same name - you will get an error.\n\n\nInsert objects\nYou can add pictures, weblinks, and GIFs in R Markdown. They all follow the similar hyperlink formats.\nFor a hyperlink to a website you put the word you want to hyperlink in square brackets [] followed immediately (no spaces or characters) by round parentheses (). E.g. [GitHub](www.github.com)\nTo insert an image or gif from a website you add a ! before the square brackets like so: ![description](https://media.giphy.com/media/sJWNLTclcvVmw/giphy.gif). The description in the [] will appear as a caption and the link must end in the appropriate file extension (.gif, .jpg, .png, etc) to work.\n\n\n\nFunny Yawn Credit: https://www.reddit.com/r/gifs/comments/54q75s/goodnight_tongue/\n\n\nYou can also insert pictures using the RStudio â€˜Addinsâ€™ > â€˜Insert Imageâ€™ and uploading an image saved on your computer with a few other options like alt text. This will result in the same hyperlink code as inserting an image, but with a relative path instead of the url.\nExample use Addin to insert image\nYou can also save files (like images, html presentations) in your post bundle to link using relative paths on your own.\n\n\n\n\n7. Pull Request\nOkay, so as you were creating the content of your post you should have been committing regularly and then pushing, right?\nLetâ€™s say we are finished with our beautiful post and read to incorporate it into the original upstream repo geocommunity/blog_website that we forked from. Remember, when we push we are pushing the commits we made locally on our computer to our YOU/blog_website repo that we forked from the original repo.\nBecause we are not owner/developers of the upstream geocommunity/blog_website repo we need to submit a pull request to submit our new blog post for approval into the upstream repo.\n\nOn your YOU/blog_website repo in your GitHub account, click on Pull requests.\nOn the right of the screen, there should be a green New pull request button. This will take to you a â€˜Comparing changesâ€™ window outlining the files and changes you have made. This will alert you to any merge conflicts with the original upstream repo. Again, sticking to creating a new post bundle/content should avoid any merge conflicts.\nClick the green Create pull request button on the right. This will take you to a â€˜Open a pull requestâ€™ window that will have your last commit and space to add a larger message with your pull request or PR.\nOnce you are happy, click the green button at the end and wait for approval. You can have a bit of a conversation to hash out any issues as well over the approval process.\n\n\n\n\nScreenshot of GitHub open a pull request.\n\n\nCongratulations - now you have submitted your blog post to a blogdown site!\n\n\n\nCheers Credit: Sony"
  },
  {
    "objectID": "posts/how-to-contribute-post/index.html#troubleshooting",
    "href": "posts/how-to-contribute-post/index.html#troubleshooting",
    "title": "How to contribute a post",
    "section": "Troubleshootingâ€¦",
    "text": "Troubleshootingâ€¦\nLetâ€™s face it, the likelihood of something going awry following this tutorial is not 0â€¦ Few things that might help along the way:\n\nSometimes it is difficult to tell when the â€˜LiveReloadâ€™ has finished or if you are used to saving regularly every few minutes that constant updating of â€˜LiveReloadâ€™ can freeze RStudio.\n\nSolution: The good â€™ole Restart R (Session > Restart R) or close and re-open.\n\nFormatting wise, itâ€™s a good idea to put full line returns before/after formatting bits like lists and inserting images. Something to check if your content is not formatting as you expect.\nOTHERS??"
  },
  {
    "objectID": "posts/how-to-contribute-post/index.html#resources-mentioned",
    "href": "posts/how-to-contribute-post/index.html#resources-mentioned",
    "title": "How to contribute a post",
    "section": "Resources mentioned:",
    "text": "Resources mentioned:\n\nCreating Websites with R Markdown by Yihui Xi, Amber Thomas, and Alison Presmanes Hill.\nâ€œUp & running with blogdown in 2021â€ Alison Hill.\nâ€œCreating a Geospatial Blog with blogdownâ€ on the UQGSAC blog by Mitch Rudge and StÃ©phane Guillou.\nExcuse me, do you have a moment to talk about version control? by Jenny Bryan\nHappy Git and GitHub for the useR by Jenny Bryan.\nGetting Started with GitHub R Ladies Brisbane presentation by Caitie Kuemple.\ngeocommunity/website GitHub repo\n18.6 Commit best practices from the R packages book by Hadley Wickham and Jenny Bryan.\nR Markdown\nKaTeX - Supported Functions\nCode Chuncks\nR Markdown Cookbook by Yihui Xie, Christophe Dervieux, Emily Riederer."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesnâ€™t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/build-blog-w-quarto/index.html#research-bazaar-queensland-2022",
    "href": "posts/build-blog-w-quarto/index.html#research-bazaar-queensland-2022",
    "title": "Build a blog with Quarto, Git, and RStudio",
    "section": "Research Bazaar Queensland 2022",
    "text": "Research Bazaar Queensland 2022\nThis session was run as a workshop for ResBaz Queensland 2022. ResBaz is a global festival promoting digital literacy at the centre of modern research.\nWhat we will cover:\n\nQuarto basics\nGit and GitHub basics\nHow to create/edit a post on a quarto website\n\nI have pieced this together using many other resources on the above which are mentioned throughout. This is also coming from a learning-as-we-go approach and by no means expert opinion. Thank you to Mitch and Christina for their help with this tutorial and workshop!\nWhat you will need:\n\nInstallations - Git, R Windows mac, RStudio (Quarto should be installed included with recent >2022.07 versions of RSTudio - otherwise download Quarto separately)\nGitHub account (free) with your login and personal access token (PAT) details handy\nNetlify account (free)"
  },
  {
    "objectID": "posts/build-blog-w-quarto/index.html#part-2-git---what-is-it",
    "href": "posts/build-blog-w-quarto/index.html#part-2-git---what-is-it",
    "title": "Build a blog with git, R, and quarto",
    "section": "Part 2: Git - what is it?",
    "text": "Part 2: Git - what is it?\nA version control software (think track changes) useful for collaborating on and sharing code.\nGit is the software itself that records changes to a set of files locally. There are several hosting platforms that are like online repositories (think Dropbox, Google Drive, etc.) that work with Git: Bitbucket, GitLab, and GitHub to name a few.\nThese platforms not only allow for version control but also to collaborate, organize, and back up projects.\nIn this case, we will be using GitHub to access the website files, make some changes (i.e., add a post), and then incorporate those changes back to the website repository on GitHub which will automatically update the website itself. ðŸ™Œ\nFirst, we will contribute a post to an existing website repository on GitHub, but there are lots of fabulous and free resources online that go more into depth on Git:\n\nIf you need to be convinced to use Git for version control see this article and Happy Git and GitHub for the useR to git started both by Git/R guru Jenny Bryan.\nSee Caitie Kuempelâ€™s R Ladies Brisbane presentation on getting started with GitHub in RStudio.\n\n\nGit Terminology\nRepository/repo - where a project is stored in GitHub. Think of it like a folder holding all the relevant documents that you can version control, view history, and add collaborators. The repository or repo holds all the relevant files for the website - most of which we will not touch.\nFork - A copy of another userâ€™s repo on your account. This allows you to freely change a project without affecting the original upstream repo. You can keep your fork synced with changes in the original repo. - this is fetching upstream.\nClone - a copy of a repository that lives on your computer instead of a website server like GitHub. Is still connected to the remote repo online and you can push/pull edits.\nCommit - is one or more changes to a file or set of files that you are asking GitHub to keep track of.\nPush - sending your committed changes to a remote repository on GitHub. Local changes updated on the GitHub website where other people can access.\nPull - incorporating and merging changes. An edit on the remote repository on GitHub can be pulled to a local repository.\nDiff - difference, or changes made that are visible as insertions/deletions for a commit.\nMain - the default branch you are on. Master has recently updated to main, but they are the same thing. You are more likely to come across master on older resources. Jenny Bryan strongly urges you to create a new branch to work off of which requires using command line. For the purpose of contributing to a quarto website, I will forgo covering this as it is unlikely more than one person will be contributing at the same time.\nOrigin - the remote repo online from which you have cloned your local copy from.\n\n\nPublishing our blog on Netlify\n\n\nHow to create a post in an existing blog\nStarting with Git and GitHub:\n\n\n1. Fork the repo\n\nSign in with your GitHub account\nGo to the geocommunity/website repo\nPress the â€˜Forkâ€™ button at the top right. \nA forked copy of the repo should now be visible in your GitHub account. YOU/blog_website is the origin for your local copy of the repo in RStudio and geocommunity/blog_website is the upstream repo.\n\n\n\n\nScreenshot of a forked repo on GitHub.\n\n\n\n\n2. Clone the repo in a new RStudio project\n\nYou will need your GitHub credentials handy.\nYou can also set up RStudio so you do not need to input your GitHub credentials every time.\n\nFrom your forked repo, click on the green â€˜Codeâ€™ button and copy the link in the pop-up window.\n\n\n\nScreenshot of finding the url to clone.\n\n\nNext, in RStudio, go to File > New Project. In the pop-up window, click the last option â€˜Version Controlâ€™ and then â€˜Gitâ€™. In the following window, paste the url you copied from your forked GitHub repo in the first box which will automatically input the name of the project.\n\n\n\nPop-up windows of cloning a GitHub repo in RStudio\n\n\nConceptually, what we have done is:\n\n\n\nConceptual diagram of forking and cloning in GitHub Credit: Happy Git for the useR\n\n\nNow that we have cloned the repository, letâ€™s explore the file structure a little in the â€˜Filesâ€™ tab in RStudio. It is NOT a very intuitively set-up even for intermediate users of R. For the purposes of creating a new post to add to the blog, we are mostly concerned with the content/english/ directory that contains the post/ sub-directory.\nThe rest of the files are the â€˜backendâ€™ of the site using html, CSS, js, etc. to build the website. Have a look if you are curious but make changes at the risk of being â€˜that personâ€™ to break the site! But donâ€™t worry, since we are using Git version control all changes are tracked and reversible.\nNow that we are somewhat familiar with the project structure, letâ€™s create a new post.\n\n\n3. Create a new post\nIn our new RStudio project housing our forked and cloned GitHub repo of the website:\nUse blogdown::new_post(\"New post name\", ext = \".Rmd\") in the console to create a new post with a .Rmd extension. Alternatively, you can go to the Addins button under the menu and choose â€˜New Postâ€™ under the BLOGDOWN section and fill in the information in the pop-up window.\n\n\n\nA new blogdown post in RStudio.\n\n\n\nThis will create a new page/post bundle folder or sub-directory within post/ with the date and the name given in new_post() function. e.g., post/2021-11-18-New-post-name.\nAn index.Rmd file has been opened and only contains a YAML header (enclosed by ---). More on that later. Do not change the name of the .Rmd file.\nEach post gets its own bundle which is where your static post-specific files like images or data (.csv files etc.) used in your post should go.\nNote that the â€œNew post nameâ€ will not only be the incorporated into the sub-directory name, but also the url to the post. Read: choose wisely and concise > long descriptive name.\nThis â€œNew post nameâ€ will automatically be filled as the â€˜Title:â€™ in the .Rmd YAML heading. If you want a longer, descriptive title - change it in the YAML heading.\nIt is recommend you use either blogdown::new_post() or the Addin to create a new post instead of manually creating a new file (File > New File > R Markdown script)\n\nHere, we will stick with the .Rmd extension, but know there are a few file types:\n.md - markdown, cannot run code chunks\n.Rmd - R markdown -> rendered to .html using Pandoc\n.Rmarkdown - also R markdown -> compiled to .markdown documents\nIf you want more of this detailed stuff see: https://bookdown.org/yihui/blogdown/output-format.html.\n\n\n4. Commit the changes i.e., the new post\nLetâ€™s commit our new post. You can add something like a line of text, or not.\n\nIf you cloned the repo properly there should be a Git tab in the upper right hand window in RStudio where the Environment is. In the Git repo, there should be some files listed (i.e., post/2021-11-23-New-post-name) with different colored boxed under the â€˜Statusâ€™ column - hover with the cursor to see what they mean.\nCheck the â€˜Stagedâ€™ box for the files you want to include in this commit.\nClick the Commit button and a window will pop-up. In the bottom section, you will see the changes made to the file as additions (green) and deletions (red) - this is known as the diff in GitHub speak. For a new file, the whole thing will be green because it is all new.\nIn the â€˜Commit messageâ€™ box, add a concise but descriptive message of the changes like â€˜Added a new post bundle.â€™ Once you are happy with everything (file staged, commit messages, etc.) click the â€˜Commitâ€™ button.\n\n\n\n\nScreenshot of a forked repo on GitHub.\n\n\nSome stuff will happen and as long as you do not see any obvious errors then it has probably all gone well and youâ€™ve made your first commit!\n\n\n\nCelebrate! Credit: http://www.reactiongifs.com/cheering-minions/\n\n\nKnowing when and how often to commit is a bit of an art that comes with experience. In general, you want to commit changes that are related to a single problem and a good commit message. There is also a History button on the top left corner that will list all the commits with messages you have made and you can view the diff by clicking on a commit. All commits have a unique code which you can use to return to a previous commit etc.\nImportant notes:\n\nOnce you have served the site (see Step 6) it will create additional files within your post bundle directory. Be sure to commit all files in the post bundle created when knitting (/index.html, /index_files, etc.) not just the index.Rmd file as they will be necessary to build the site from GitHub. - You can stage them all together as one commit.\nYou will not be able to see diffs in the commit window until they have been saved.\n\nSee more on committing and best practices from the R packages book.\n\n\n\nHow committing goesâ€¦ Credit: xkcd comics\n\n\n\n\n5. Push the changes to GitHub\nThe changes and commits we have made are local, but we need to get them onto the GitHub repo and then the website. This is where we need to push.\nIn the Git window, you will see a blue down arrow for pulling and a green up arrow for pushing. You will also see a message along the lines of Your branch is ahead of 'origin/main' by X commits under those buttons.\nFor the purposes of contributing a post to a blogdown website, we will not worry about pulls and fetching upstream. This basically means keeping your origin/master repo synced with the original upstream repo that you forked.\nIf you stick to creating a new post bundle and only modifying files within the post bundles it should be okay without fetching upstream. BUT know that if you are using GitHub to work collaboratively, staying current with the original repo is important and in general it is a good practice to always pull before you push. Recommend Happy Git and GitHub for the useR as a trusty guide.\nIf you want to try fetching upstream it is easiest to do via GitHub. Followed by a pull in RStudio.\n\nLog into your GitHub account online, and navigate to your YOU/blog_website repo.\nUnder the green Code button, there should be a Fetch upstream button that will sync your forked repo with the original upstream repo.\nThere is information about the status of your branch compared to the original upstream repo e.g., â€˜up to dateâ€™ or â€˜X commits ahead/behindâ€™ to give you an idea if you need to fetch or not.\nNow in RStudio, you should be good to pull.\nRevisiting this diagram, the fetch upstream is updating your forked repo from the original yellow repo and then the pull is updating your local repo from your forked repo.\n\n\n\n\nDiagram of fetching upstream and pulling Credit: modified from Happy Git for the useR\n\n\nNow we will push our commits from or local repo to our remote origin/master repo on GitHub.\nIf this is your first time using Git with RStudio, you will have to set-up a personal access token or PAT in GitHub. For detailed directions, go to the GitHub page.\n\nGo to your GitHub account online and click on your profile photo in the upper-right and go to Settings.\nIn the left sidebar, click on Developer settings then Personal Access Tokens.\nClick the Generate a new token button and give a descriptive name and expiration.\nSelect scopes or privacy settings (defaults are generally fine) and the generate the token.\nCopy your PAT and put it in the password field for any pop-ups asking for your GitHub credentials when you push.\n\nIf you see HEAD -> main then all good.\n\n\n\nScreenshot of push window in RStudio.\n\n\nNow if you go back to your GitHub account and forked repo online, you should see the changes you made locally are now in the remote online repo and your commit message.\n\n\n\nScreenshot of pushed changes on forked GitHub repo.\n\n\nIn general, you should commit often and then push.\n\n\n6. Serve the site\nIn the console, run blogdown::serve_site(). Alternatively, can click on RStudio â€˜Addinsâ€™ and select â€˜Serve Siteâ€™. Be patient, but what happens?\n\n\n\nScreenshot of served site in RStudio.\n\n\nSome important information on what is going on from blogdown: Creating Websites with R Markdown:\n\nServing the site did the following: 1. Started a local Hugo server to help you preview your website, and 2. Knitted a sample .Rmd post to an .html page. You can see this from the progress message that printed to your console: Rendering content/english/post/2021-11-23-creating-a-post/index.Rmd... Done\n\nYou can also view the locally served website in a browser by clicking on the â€œShow in new windowâ€ button at the top left of the RStudio Viewer pane to the right of the broom.\nServing the site is using something called LiveReload:\n\nLetâ€™s introduce an important and helpful technology that you just used: LiveReload. Serving your site uses LiveReload, which means your website will be automatically rebuilt and reloaded in your web browser when you modify any source file of your website and save it. Basically, once you launch the website in a web browser, you do not need to rebuild it explicitly anymore. All you need to do is edit the source files, such as R Markdown documents, and save them. There is no need to click any buttons or run any commands. LiveReload is implemented via blogdown::serve_site() and Hugo, and you will only need to use it once per work session.\n\nRemember, every time you save your .Rmd file will activate the LiveReload. To stop serving the site locally run blogdown::stop_server() in the console.\n\n\n7. Create your content\nOnce the website is set-up, forked, and clonedâ€¦ you can get on with creating a new post with minimal coding. The main thing you will need to use is:\n\nR Markdown\nThis is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML documents that we can incorporate into the website. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nWhen you click the Knit button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. For a website post, knitting is not as important because we can serve our site locally which automatically knits anything new and view the changes as we just learned ðŸ‘†.\nNow letâ€™s add some information about R Markdown:\n\nYAML header\nThe YAML, or Yet Another Markdown Language, header at the top of the .Rmd is set between --- tags. Here is where information like the Title, Date, Author of the document go and will appear in the post.\nHave a look at previous posts and add any relevant tags or categories as you like.\nThe default .Rmd has some redundant settings (tags vs Tags) so if you use them stick with the lower case settings.\n\n\nFormatting\nCan bold and italicize text.\nHeadings:\nCan specify headings using # marks. The number of has symbols corresponds to the level of the header (2 hashs = level 2 header)\nThis will also create a structure outline of your document you can navigate either by using the â€˜Formattingâ€™ button at the bottom of the .Rmd or the right most button in the top right of the .Rmd.\n\n\n\nScreenshot of buttons to view document outline\n\n\nMake lists:\n\none\ntwo\nthree\n\nfull indent for sub-bullet\n\n\nOrdered lists:\n\nlists\nneed spaces\nbefore and after\n\nFor a return to start a new line, leave two spaces at the end of the line.\nLike this.\n\n\nIncluding code\nYou can embed an R code chunk like this:\n\nsummary(cars)\n\n     speed           dist       \n Min.   : 4.0   Min.   :  2.00  \n 1st Qu.:12.0   1st Qu.: 26.00  \n Median :15.0   Median : 36.00  \n Mean   :15.4   Mean   : 42.98  \n 3rd Qu.:19.0   3rd Qu.: 56.00  \n Max.   :25.0   Max.   :120.00  \n\n\nThere is also inline code: The mean of speed in the cars data set is 15.4.\n\n\nInclude mathematical notation\nMathematical notation can be enabled using third party JavaScript libraries like KaTeX. See resource of supported TeX functions. For these to render correctly you must add math: true to the YAML header at the top of the .Rmd.\nTo enter equations like a code chunk or block math, use two $ on separate lines surrounding your equations.\nPut two \\ after a line for a full return.\n\\[\ny = mx + \\beta\\\\\nE = mc^2\n\\]\n\\[ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } \\]\nYou can also use inline math notation by sandwiching it between $ without spaces. Like so \\(\\mu = 0.2566\\).\nAnother inline way: (= = 1.6180339887â€¦)\n\n\nIncluding Plots\nYou can also embed plots, for example:\n\n\n\n\n\n\n\nChunk options\nChunks are the gray areas in the .Rmd file where you can add code that will be run. These are defined by three back ticks (not a single quote, the key to the left of the 1). You can insert R code chunks but also in other languages! See the green â€˜Insertâ€™ code chunk button to see different options. An R code chunk will have the an {r  } after the opening back ticks.\nThe keyboard short cut to add an R code chunk is Ctrl + Alt + I\nYou can also set options in the {} of a chunk like hide the code chunk (echo = FALSE), suppress warnings (warnings = FALSE), and cache the chunk (cache = TRUE) if you have something that takes a while to run.\nLetâ€™s set echo = FALSE for our plot chunk above. We are only interested in seeing the plot, not the code that produces the plot.\nYou can add a code chunk at the beginning of the .Rmd file and set global options that will apply to the whole document.\n\nknitr::opts_chunk$set(echo = TRUE)\n\nSee more at:\n\nRStudio - https://rmarkdown.rstudio.com/lesson-3.html\nR Markdown Cookbook - https://bookdown.org/yihui/rmarkdown-cookbook/\n\nIt is also a good idea to name your chunks as chunks are included in the document outline. Chunks cannot have the same name - you will get an error.\n\n\nInsert objects\nYou can add pictures, weblinks, and GIFs in R Markdown. They all follow the similar hyperlink formats.\nFor a hyperlink to a website you put the word you want to hyperlink in square brackets [] followed immediately (no spaces or characters) by round parentheses (). E.g. [GitHub](www.github.com)\nTo insert an image or gif from a website you add a ! before the square brackets like so: ![description](https://media.giphy.com/media/sJWNLTclcvVmw/giphy.gif). The description in the [] will appear as a caption and the link must end in the appropriate file extension (.gif, .jpg, .png, etc) to work.\n\n\n\nFunny Yawn Credit: https://www.reddit.com/r/gifs/comments/54q75s/goodnight_tongue/\n\n\nYou can also insert pictures using the RStudio â€˜Addinsâ€™ > â€˜Insert Imageâ€™ and uploading an image saved on your computer with a few other options like alt text. This will result in the same hyperlink code as inserting an image, but with a relative path instead of the url.\nExample use Addin to insert image\nYou can also save files (like images, html presentations) in your post bundle to link using relative paths on your own.\n\n\n\n\n7. Pull Request\nOkay, so as you were creating the content of your post you should have been committing regularly and then pushing, right?\nLetâ€™s say we are finished with our beautiful post and read to incorporate it into the original upstream repo geocommunity/blog_website that we forked from. Remember, when we push we are pushing the commits we made locally on our computer to our YOU/blog_website repo that we forked from the original repo.\nBecause we are not owner/developers of the upstream geocommunity/blog_website repo we need to submit a pull request to submit our new blog post for approval into the upstream repo.\n\nOn your YOU/blog_website repo in your GitHub account, click on Pull requests.\nOn the right of the screen, there should be a green New pull request button. This will take to you a â€˜Comparing changesâ€™ window outlining the files and changes you have made. This will alert you to any merge conflicts with the original upstream repo. Again, sticking to creating a new post bundle/content should avoid any merge conflicts.\nClick the green Create pull request button on the right. This will take you to a â€˜Open a pull requestâ€™ window that will have your last commit and space to add a larger message with your pull request or PR.\nOnce you are happy, click the green button at the end and wait for approval. You can have a bit of a conversation to hash out any issues as well over the approval process.\n\n\n\n\nScreenshot of GitHub open a pull request.\n\n\nCongratulations - now you have submitted your blog post to a blogdown site!\n\n\n\nCheers Credit: Sony"
  },
  {
    "objectID": "posts/build-blog-w-quarto/index.html#not-sure-if-will-include-all-of-this-content",
    "href": "posts/build-blog-w-quarto/index.html#not-sure-if-will-include-all-of-this-content",
    "title": "Build a blog with Quarto, git, RStudio",
    "section": "not sure if will include all of this content:",
    "text": "not sure if will include all of this content:\n\nHow to create a post in an existing blog\nStarting with Git and GitHub:\n\n\n1. Fork the repo\n\nSign in with your GitHub account\nGo to the geocommunity/website repo\nPress the â€˜Forkâ€™ button at the top right. \nA forked copy of the repo should now be visible in your GitHub account. YOU/blog_website is the origin for your local copy of the repo in RStudio and geocommunity/blog_website is the upstream repo.\n\n\n\n\nScreenshot of a forked repo on GitHub.\n\n\n\n\n2. Clone the repo in a new RStudio project\n\nYou will need your GitHub credentials handy.\nYou can also set up RStudio so you do not need to input your GitHub credentials every time.\n\nFrom your forked repo, click on the green â€˜Codeâ€™ button and copy the link in the pop-up window.\n\n\n\nScreenshot of finding the url to clone.\n\n\nNext, in RStudio, go to File > New Project. In the pop-up window, click the last option â€˜Version Controlâ€™ and then â€˜Gitâ€™. In the following window, paste the url you copied from your forked GitHub repo in the first box which will automatically input the name of the project.\n\n\n\nPop-up windows of cloning a GitHub repo in RStudio\n\n\nConceptually, what we have done is:\n\n\n\nConceptual diagram of forking and cloning in GitHub Credit: Happy Git for the useR\n\n\nNow that we have cloned the repository, letâ€™s explore the file structure a little in the â€˜Filesâ€™ tab in RStudio. It is NOT a very intuitively set-up even for intermediate users of R. For the purposes of creating a new post to add to the blog, we are mostly concerned with the content/english/ directory that contains the post/ sub-directory.\nThe rest of the files are the â€˜backendâ€™ of the site using html, CSS, js, etc. to build the website. Have a look if you are curious but make changes at the risk of being â€˜that personâ€™ to break the site! But donâ€™t worry, since we are using Git version control all changes are tracked and reversible.\nNow that we are somewhat familiar with the project structure, letâ€™s create a new post.\n\n\n3. Create a new post\nIn our new RStudio project housing our forked and cloned GitHub repo of the website:\nUse blogdown::new_post(\"New post name\", ext = \".Rmd\") in the console to create a new post with a .Rmd extension. Alternatively, you can go to the Addins button under the menu and choose â€˜New Postâ€™ under the BLOGDOWN section and fill in the information in the pop-up window.\n\n\n\nA new blogdown post in RStudio.\n\n\n\nThis will create a new page/post bundle folder or sub-directory within post/ with the date and the name given in new_post() function. e.g., post/2021-11-18-New-post-name.\nAn index.Rmd file has been opened and only contains a YAML header (enclosed by ---). More on that later. Do not change the name of the .Rmd file.\nEach post gets its own bundle which is where your static post-specific files like images or data (.csv files etc.) used in your post should go.\nNote that the â€œNew post nameâ€ will not only be the incorporated into the sub-directory name, but also the url to the post. Read: choose wisely and concise > long descriptive name.\nThis â€œNew post nameâ€ will automatically be filled as the â€˜Title:â€™ in the .Rmd YAML heading. If you want a longer, descriptive title - change it in the YAML heading.\nIt is recommend you use either blogdown::new_post() or the Addin to create a new post instead of manually creating a new file (File > New File > R Markdown script)\n\nHere, we will stick with the .Rmd extension, but know there are a few file types:\n.md - markdown, cannot run code chunks\n.Rmd - R markdown -> rendered to .html using Pandoc\n.Rmarkdown - also R markdown -> compiled to .markdown documents\nIf you want more of this detailed stuff see: https://bookdown.org/yihui/blogdown/output-format.html.\n\n\n4. Commit the changes i.e., the new post\nLetâ€™s commit our new post. You can add something like a line of text, or not.\n\nIf you cloned the repo properly there should be a Git tab in the upper right hand window in RStudio where the Environment is. In the Git repo, there should be some files listed (i.e., post/2021-11-23-New-post-name) with different colored boxed under the â€˜Statusâ€™ column - hover with the cursor to see what they mean.\nCheck the â€˜Stagedâ€™ box for the files you want to include in this commit.\nClick the Commit button and a window will pop-up. In the bottom section, you will see the changes made to the file as additions (green) and deletions (red) - this is known as the diff in GitHub speak. For a new file, the whole thing will be green because it is all new.\nIn the â€˜Commit messageâ€™ box, add a concise but descriptive message of the changes like â€˜Added a new post bundle.â€™ Once you are happy with everything (file staged, commit messages, etc.) click the â€˜Commitâ€™ button.\n\n\n\n\nScreenshot of a forked repo on GitHub.\n\n\nSome stuff will happen and as long as you do not see any obvious errors then it has probably all gone well and youâ€™ve made your first commit!\n\n\n\nCelebrate! Credit: http://www.reactiongifs.com/cheering-minions/\n\n\nKnowing when and how often to commit is a bit of an art that comes with experience. In general, you want to commit changes that are related to a single problem and a good commit message. There is also a History button on the top left corner that will list all the commits with messages you have made and you can view the diff by clicking on a commit. All commits have a unique code which you can use to return to a previous commit etc.\nImportant notes:\n\nOnce you have served the site (see Step 6) it will create additional files within your post bundle directory. Be sure to commit all files in the post bundle created when knitting (/index.html, /index_files, etc.) not just the index.Rmd file as they will be necessary to build the site from GitHub. - You can stage them all together as one commit.\nYou will not be able to see diffs in the commit window until they have been saved.\n\nSee more on committing and best practices from the R packages book.\n\n\n5. Push the changes to GitHub\nThe changes and commits we have made are local, but we need to get them onto the GitHub repo and then the website. This is where we need to push.\nIn the Git window, you will see a blue down arrow for pulling and a green up arrow for pushing. You will also see a message along the lines of Your branch is ahead of 'origin/main' by X commits under those buttons.\nFor the purposes of contributing a post to a blogdown website, we will not worry about pulls and fetching upstream. This basically means keeping your origin/master repo synced with the original upstream repo that you forked.\nIf you stick to creating a new post bundle and only modifying files within the post bundles it should be okay without fetching upstream. BUT know that if you are using GitHub to work collaboratively, staying current with the original repo is important and in general it is a good practice to always pull before you push. Recommend Happy Git and GitHub for the useR as a trusty guide.\nIf you want to try fetching upstream it is easiest to do via GitHub. Followed by a pull in RStudio.\n\nLog into your GitHub account online, and navigate to your YOU/blog_website repo.\nUnder the green Code button, there should be a Fetch upstream button that will sync your forked repo with the original upstream repo.\nThere is information about the status of your branch compared to the original upstream repo e.g., â€˜up to dateâ€™ or â€˜X commits ahead/behindâ€™ to give you an idea if you need to fetch or not.\nNow in RStudio, you should be good to pull.\nRevisiting this diagram, the fetch upstream is updating your forked repo from the original yellow repo and then the pull is updating your local repo from your forked repo.\n\n\n\n\nDiagram of fetching upstream and pulling Credit: modified from Happy Git for the useR\n\n\nNow we will push our commits from or local repo to our remote origin/master repo on GitHub.\nIf this is your first time using Git with RStudio, you will have to set-up a personal access token or PAT in GitHub. For detailed directions, go to the GitHub page.\n\nGo to your GitHub account online and click on your profile photo in the upper-right and go to Settings.\nIn the left sidebar, click on Developer settings then Personal Access Tokens.\nClick the Generate a new token button and give a descriptive name and expiration.\nSelect scopes or privacy settings (defaults are generally fine) and the generate the token.\nCopy your PAT and put it in the password field for any pop-ups asking for your GitHub credentials when you push.\n\nIf you see HEAD -> main then all good.\n\n\n\nScreenshot of push window in RStudio.\n\n\nNow if you go back to your GitHub account and forked repo online, you should see the changes you made locally are now in the remote online repo and your commit message.\n\n\n\nScreenshot of pushed changes on forked GitHub repo.\n\n\nIn general, you should commit often and then push.\n\n\n6. Serve the site\nIn the console, run blogdown::serve_site(). Alternatively, can click on RStudio â€˜Addinsâ€™ and select â€˜Serve Siteâ€™. Be patient, but what happens?\n\n\n\nScreenshot of served site in RStudio.\n\n\nSome important information on what is going on from blogdown: Creating Websites with R Markdown:\n\nServing the site did the following: 1. Started a local Hugo server to help you preview your website, and 2. Knitted a sample .Rmd post to an .html page. You can see this from the progress message that printed to your console: Rendering content/english/post/2021-11-23-creating-a-post/index.Rmd... Done\n\nYou can also view the locally served website in a browser by clicking on the â€œShow in new windowâ€ button at the top left of the RStudio Viewer pane to the right of the broom.\nServing the site is using something called LiveReload:\n\nLetâ€™s introduce an important and helpful technology that you just used: LiveReload. Serving your site uses LiveReload, which means your website will be automatically rebuilt and reloaded in your web browser when you modify any source file of your website and save it. Basically, once you launch the website in a web browser, you do not need to rebuild it explicitly anymore. All you need to do is edit the source files, such as R Markdown documents, and save them. There is no need to click any buttons or run any commands. LiveReload is implemented via blogdown::serve_site() and Hugo, and you will only need to use it once per work session.\n\nRemember, every time you save your .Rmd file will activate the LiveReload. To stop serving the site locally run blogdown::stop_server() in the console.\n\n\n7. Create your content\nOnce the website is set-up, forked, and clonedâ€¦ you can get on with creating a new post with minimal coding. The main thing you will need to use is:\n\nR Markdown\nThis is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML documents that we can incorporate into the website. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nWhen you click the Knit button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. For a website post, knitting is not as important because we can serve our site locally which automatically knits anything new and view the changes as we just learned ðŸ‘†.\nNow letâ€™s add some information about R Markdown:\n\nYAML header\nThe YAML, or Yet Another Markdown Language, header at the top of the .Rmd is set between --- tags. Here is where information like the Title, Date, Author of the document go and will appear in the post.\nHave a look at previous posts and add any relevant tags or categories as you like.\nThe default .Rmd has some redundant settings (tags vs Tags) so if you use them stick with the lower case settings.\n\n\nFormatting\nCan bold and italicize text.\nHeadings:\nCan specify headings using # marks. The number of has symbols corresponds to the level of the header (2 hashs = level 2 header)\nThis will also create a structure outline of your document you can navigate either by using the â€˜Formattingâ€™ button at the bottom of the .Rmd or the right most button in the top right of the .Rmd.\n\n\n\nScreenshot of buttons to view document outline\n\n\nMake lists:\n\none\ntwo\nthree\n\nfull indent for sub-bullet\n\n\nOrdered lists:\n\nlists\nneed spaces\nbefore and after\n\nFor a return to start a new line, leave two spaces at the end of the line.\nLike this.\n\n\nIncluding code\nYou can embed an R code chunk like this:\n\nsummary(cars)\n\n     speed           dist       \n Min.   : 4.0   Min.   :  2.00  \n 1st Qu.:12.0   1st Qu.: 26.00  \n Median :15.0   Median : 36.00  \n Mean   :15.4   Mean   : 42.98  \n 3rd Qu.:19.0   3rd Qu.: 56.00  \n Max.   :25.0   Max.   :120.00  \n\n\nThere is also inline code: The mean of speed in the cars data set is 15.4.\n\n\nInclude mathematical notation\nMathematical notation can be enabled using third party JavaScript libraries like KaTeX. See resource of supported TeX functions. For these to render correctly you must add math: true to the YAML header at the top of the .Rmd.\nTo enter equations like a code chunk or block math, use two $ on separate lines surrounding your equations.\nPut two \\ after a line for a full return.\n\\[\ny = mx + \\beta\\\\\nE = mc^2\n\\]\n\\[ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } \\]\nYou can also use inline math notation by sandwiching it between $ without spaces. Like so \\(\\mu = 0.2566\\).\nAnother inline way: (= = 1.6180339887â€¦)\n\n\nIncluding Plots\nYou can also embed plots, for example:\n\n\n\n\n\n\n\nChunk options\nChunks are the gray areas in the .Rmd file where you can add code that will be run. These are defined by three back ticks (not a single quote, the key to the left of the 1). You can insert R code chunks but also in other languages! See the green â€˜Insertâ€™ code chunk button to see different options. An R code chunk will have the an {r  } after the opening back ticks.\nThe keyboard short cut to add an R code chunk is Ctrl + Alt + I\nYou can also set options in the {} of a chunk like hide the code chunk (echo = FALSE), suppress warnings (warnings = FALSE), and cache the chunk (cache = TRUE) if you have something that takes a while to run.\nLetâ€™s set echo = FALSE for our plot chunk above. We are only interested in seeing the plot, not the code that produces the plot.\nYou can add a code chunk at the beginning of the .Rmd file and set global options that will apply to the whole document.\n\nknitr::opts_chunk$set(echo = TRUE)\n\nSee more at:\n\nRStudio - https://rmarkdown.rstudio.com/lesson-3.html\nR Markdown Cookbook - https://bookdown.org/yihui/rmarkdown-cookbook/\n\nIt is also a good idea to name your chunks as chunks are included in the document outline. Chunks cannot have the same name - you will get an error.\n\n\nInsert objects\nYou can add pictures, weblinks, and GIFs in R Markdown. They all follow the similar hyperlink formats.\nFor a hyperlink to a website you put the word you want to hyperlink in square brackets [] followed immediately (no spaces or characters) by round parentheses (). E.g. [GitHub](www.github.com)\nTo insert an image or gif from a website you add a ! before the square brackets like so: ![description](https://media.giphy.com/media/sJWNLTclcvVmw/giphy.gif). The description in the [] will appear as a caption and the link must end in the appropriate file extension (.gif, .jpg, .png, etc) to work.\n\n\n\nFunny Yawn Credit: https://www.reddit.com/r/gifs/comments/54q75s/goodnight_tongue/\n\n\nYou can also insert pictures using the RStudio â€˜Addinsâ€™ > â€˜Insert Imageâ€™ and uploading an image saved on your computer with a few other options like alt text. This will result in the same hyperlink code as inserting an image, but with a relative path instead of the url.\nExample use Addin to insert image\nYou can also save files (like images, html presentations) in your post bundle to link using relative paths on your own.\n\n\n\n\n7. Pull Request\nOkay, so as you were creating the content of your post you should have been committing regularly and then pushing, right?\nLetâ€™s say we are finished with our beautiful post and read to incorporate it into the original upstream repo geocommunity/blog_website that we forked from. Remember, when we push we are pushing the commits we made locally on our computer to our YOU/blog_website repo that we forked from the original repo.\nBecause we are not owner/developers of the upstream geocommunity/blog_website repo we need to submit a pull request to submit our new blog post for approval into the upstream repo.\n\nOn your YOU/blog_website repo in your GitHub account, click on Pull requests.\nOn the right of the screen, there should be a green New pull request button. This will take to you a â€˜Comparing changesâ€™ window outlining the files and changes you have made. This will alert you to any merge conflicts with the original upstream repo. Again, sticking to creating a new post bundle/content should avoid any merge conflicts.\nClick the green Create pull request button on the right. This will take you to a â€˜Open a pull requestâ€™ window that will have your last commit and space to add a larger message with your pull request or PR.\nOnce you are happy, click the green button at the end and wait for approval. You can have a bit of a conversation to hash out any issues as well over the approval process.\n\n\n\n\nScreenshot of GitHub open a pull request.\n\n\nCongratulations - now you have submitted your blog post to a blogdown site!\n\n\n\nCheers Credit: Sony"
  },
  {
    "objectID": "posts/build-blog-w-quarto/index.html#publishing",
    "href": "posts/build-blog-w-quarto/index.html#publishing",
    "title": "Build a blog with Quarto, Git, and RStudio",
    "section": "Publishing",
    "text": "Publishing\nThere are several options for publishing your quarto blog outlined here. Such as Quarto Pub and Netlify.\n\n\n\n\n\n\nNote\n\n\n\nQuarto Pub is a free publishing service for quarto content. It requires having a login and an access token. This is a relatively straight forward way to get your blog online. There are some limitations to the size and everything published on Quarto Pub is publicly visible. The link above outlines the steps to publish with Quart Pub. This method does not involve using git.\n\n\nFor this workshop, we will focus on Netlify. In your Netlify account, click on the teal Add new site button.\nImport an existing project from a GitHub repository. You will probably need to configure your Netlify on GitHub. Can either configure all repositories or pick a specific repository.\n\nAuthorize Quarto to access Netlify.\n\nNow that weâ€™ve connected our GitHub to Netlify, go to the Site settings. At the bottom â€˜Publish directoryâ€™ section put the _site/ folder where your website is rendered.\n\nIt will take a few minutes to deploy your website. Netlify automatically generates a random url like â€œlighthearted-travesseiro-492jfg3â€ which can be changed in the â€˜Domain settingsâ€™. Or course, you can also use/pay for a custom url to remove the â€˜netlify.appâ€™ at the end of the url.\nNow, make a change in the welcome post, render the site, commit the changes, and push the changes in the .qmd file. Look at your GitHub remote repo to check that the changes are there. Now check your website - did it update as well?\nAs we defined above, unless you also commited the updated contents of the _site/ foldr the website will not have updated. This folder is where all the rendered outputs are that are used to build the site on Netlify. Commit the updated _site/ folder and push. Now check your website again.\n\n\n\nCheers"
  },
  {
    "objectID": "posts/build-blog-w-quarto/index.html#git---what-is-it-1",
    "href": "posts/build-blog-w-quarto/index.html#git---what-is-it-1",
    "title": "Build a blog with Quarto, git, RStudio",
    "section": "Git - what is it?",
    "text": "Git - what is it?"
  },
  {
    "objectID": "posts/build-blog-w-quarto/index.html#add-a-map",
    "href": "posts/build-blog-w-quarto/index.html#add-a-map",
    "title": "Build a blog with Quarto, Git, and RStudio",
    "section": "Add a map",
    "text": "Add a map\nThis is a spatial community of practice - letâ€™s add a map of ResBazQld 2022 to a post using leaflet.\n\n# install.packages(\"leaflet\")\nlibrary(leaflet)\nlibrary(magrittr)\nleaflet() %>% \n  addTiles() %>% # default background map\n  addMarkers(lat = -27.552, lng = 153.0535,\n             popup = \"Location of ResBazQld 2022\")"
  },
  {
    "objectID": "posts/build-blog-w-quarto/index.html#troubleshooting-tbc",
    "href": "posts/build-blog-w-quarto/index.html#troubleshooting-tbc",
    "title": "Build a blog with Quarto, Git, and RStudio",
    "section": "Troubleshooting TBC",
    "text": "Troubleshooting TBC"
  },
  {
    "objectID": "posts/build-blog-w-quarto/index.html#resources",
    "href": "posts/build-blog-w-quarto/index.html#resources",
    "title": "Build a blog with Quarto, Git, and RStudio",
    "section": "Resources",
    "text": "Resources\nQuarto\n\nBuilding a blog with quarto, Youtube video, website - Isabella Valasquez, Rstudio\nWelcome to Quarto!, Tom Mock, RStudio"
  },
  {
    "objectID": "posts/2023-02-05-calculating-areas-with-vector-and-raster-data-in-r/index.html",
    "href": "posts/2023-02-05-calculating-areas-with-vector-and-raster-data-in-r/index.html",
    "title": "Calculating areas with vector and raster data in R",
    "section": "",
    "text": "This short tutorial will focus on area calculation in R using both vector and raster data. Use the following code to install all necessary packages\ninstall.packages('terra', 'tmap', 'sf', 'tidyverse', 'exactextractr', 'rnaturalearthdata', 'microbenchmark')\nDisclaimer: the author of these notes is by no means an expert on this topic. This is merely a compilation of information Iâ€™ve gathered while going down a googling â€˜rabbit-holeâ€™. So please get in touch if anything in the notes should be corrected.\n\nArea in 3-dimensions vs.Â 2-dimensions\nCan I calculate area accurately using a latitude-longitude geographic coordinate reference system (GCS), or should I use a projected coordinate reference system (PCS)?\nGCSâ€™s represent the Earthâ€™s surface in 3-dimensions and have angular, lat-long units (Figure 1). They are defined by a datum (reference points associated with an ellipsoid (a model of the size and shape of the Earth)), a prime meridian, and an angular unit of measure. See here for more detail. Calculating area in a 3-D GCS requires geodesic (i.e., ellipsoidal) computations, which can be complex and computationally expensive.\nPCSâ€™s flatten a GCS into 2-dimensions representing linear units (e.g., metres), helping to make area computations less complex and therefore faster, but also causing some distortion of the Earthâ€™s surface. There are many PCSâ€™s available to use (see here), some of which preserve area (i.e., equal-area projections).\n.\n\nWhich coordinate reference system to use?\nHere weâ€™ll focus on how coordinate reference systems influence area calculations. There is a common misconception that you cannot calculate area accurately when in a lat-long GCS, but this is not true. For example, read the help documentation from the expanse function in {terra}:\n\n?terra::expanse\n\nstarting httpd help server ... done\n\n\nâ€˜For vector data, the best way to compute area is to use the longitude/latitude CRS. This is contrary to (erroneous) popular belief that suggest that you should use a planar coordinate reference system.â€™\nMore generally however, choosing the best coordinate reference system will depend on the scale and location of your spatial data, and the goal of your analysis. Sometimes you will need to use multiple CRSâ€™s to complete various tasks associated with a single analysis. We wonâ€™t dive into the details here, but find a good overview things to consider when choosing a CRS here.\nNote also that itâ€™s always preferable to leave your raster data in itâ€™s native projection if your analysis requires use of values stored in the raster pixels. This is because projecting rasters involves calculating new pixel values via resampling, which results in slight inaccuracies and potential loss of information. There are several methods for resampling depending on they type of data stored in the raster pixels (e.g., categorical vs.Â continuous), see descriptions here.\n\n\n\nVector area calculations and the new-ish s2 geometry library\nSince 2021, {sf} (versions >1) uses Googleâ€™s s2 spherical geometry engine by default when representing vector polygons that are in a lat-long GCS. Previously {sf} would use a planar geometry engine called GEOS, meaning that if you were in a 3-D lat-long GCS, {sf} was assuming flat, planar coordinates. This would result in warning messages like:\nalthough coordinates are longitude/latitude, st_intersects assumes that they are planar\nNow, when the s2 spherical geometry is on and your data is in a 3-D lat-long GCS, {sf} performs processes and computations on a sphere, rather than in 2-D. The advantages of using the s2 geometry library instead of GEOS are outlined in detail here: r-spatial.github.io/sf/articles/sf7.html. If your data is in a 2-D PCS, {sf} reverts to the planar GEOS geometry engine, assuming flat coordinates (so make sure youâ€™re using a projection that preserves area).\n\nShould I have s2 turned on when calculating area in a geographic CRS?\nWhile the s2 geometry library offers many advantages, when it comes to area there is a speed vs.Â accuracy trade-off. When s2 is on, {sf} calculates area assuming a spherical approximation of the Earth. But the Earth isnâ€™t a perfect sphere, itâ€™s a spheroid. It bulges at the equator.\nWhen s2 is off, {sf} performs geodesic (i.e., ellipsoidal) area calculations using the high precision GeographicLib that uses a spheroid to represent the Earthâ€™s size and shape. Geodesic calculations will be more accurate than those performed with s2 on, as s2 assumes a spherical representation of the Earth. But geodesic computations more complex, and time costly.\nLetâ€™s examine the speed vs.Â accuracy trade-off. Weâ€™ll start by loading some vector polygons representing countries of the world and check if the geometries are valid.\n\nlibrary(tidyverse)\n\nâ”€â”€ Attaching core tidyverse packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 2.0.0 â”€â”€\nâœ” dplyr     1.1.0     âœ” readr     2.1.4\nâœ” forcats   1.0.0     âœ” stringr   1.5.0\nâœ” ggplot2   3.4.1     âœ” tibble    3.1.8\nâœ” lubridate 1.9.2     âœ” tidyr     1.3.0\nâœ” purrr     1.0.1     \nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€\nâœ– dplyr::filter() masks stats::filter()\nâœ– dplyr::lag()    masks stats::lag()\nâ„¹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nlibrary(sf)\n\nLinking to GEOS 3.9.3, GDAL 3.5.2, PROJ 8.2.1; sf_use_s2() is TRUE\n\nlibrary(tmap)\noptions(scipen=999)\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\nsf_use_s2() # check if s2 is on (it should be as default when sf is loaded)\n\n[1] TRUE\n\ndat <- rnaturalearthdata::countries50 %>% # load country polygons for the world\n  st_as_sf() %>% # turn into a simple features dataframe\n  filter(admin == 'Sudan') # filter for a single country\nst_is_valid(dat) # check if geometry is valid\n\n[1] FALSE\n\n\nThe geometry is invalid. Compared to GEOS, s2 has strict polygon conformance that if violated will render invalid geometries. For vector data created in older versions of sf, this can be a bit of a headache. First thing is to try fixing the geometry.\n\ndat_v <- dat %>% st_make_valid()\nst_is_valid(dat_v) # check if geometry is valid\n\n[1] TRUE\n\nqtm(dat_v)\n\n\n\n\n\n\nIt works in this case - the geometry is valid. Now, letâ€™s compare area estimates with s2 on and off.\n\narea_s2 <- st_area(dat_v)/1e6 # area in km2, s2 on by default\nsf_use_s2(FALSE) # turn off s2\n\nSpherical geometry (s2) switched off\n\narea_GeoLib <- st_area(dat_v)/1e6 # area in km2, s2 off, sf calculates geodesic area using GeographicLib\narea_s2 - area_GeoLib # subtract to get the difference in area estimates \n\n6381.861 [m^2]\n\n\nThere is an ~6000 km2 difference in area (note the m2 indicated in the output is incorrect, because we divided by 1e6 to convert m2 to km2). The geodesic calculation using the GeographicLib (i.e, s2 turned off) will be the most accurate estimate because it doesnâ€™t assume the Earth is a perfect sphere. But which is faster? Letâ€™s use {microbenchmark} to find out.\n\nlibrary(microbenchmark)\n\nmicrobenchmark(\n  {sf_use_s2(TRUE); area_s2 <- st_area(dat_v)},\n  {sf_use_s2(FALSE); area_GeoLib <- st_area(dat_v)})\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nSpherical geometry (s2) switched on\n\n\nSpherical geometry (s2) switched off\n\n\nUnit: milliseconds\n                                                       expr     min       lq\n      {     sf_use_s2(TRUE)     area_s2 <- st_area(dat_v) } 12.2718 13.34335\n {     sf_use_s2(FALSE)     area_GeoLib <- st_area(dat_v) } 16.3018 17.57485\n     mean   median       uq     max neval cld\n 14.36035 14.27930 14.99475 23.3392   100  a \n 18.86507 18.94435 19.95495 25.2909   100   b\n\n\nSo computing geodesic area takes more time. In this case itâ€™s only a few milliseconds, so we would turn s2 off and opt for the most accurate, albeit slower, area calculation.\nHow do geodesic area computations using a lat-long GCS compare to an equal-area PCS, like mollweide?\n\ndat_p <- dat_v %>% st_transform('ESRI:54009')\narea_mollweide <- st_area(dat_p)/1e6 # sf uses planar geometry library GEOS\narea_mollweide - (area_GeoLib/1e6)\n\n10556.15 [m^2]\n\n\nThere is an ~ 10000 km2 difference in area estimates, much larger than the difference between area on a sphere (s2 on) and on a spheroid (s2 off, geodesic estimates using GeographicLib).\n\n\nIn summaryâ€¦\nWhen calculating area of vector polygons in a lat-long GCS using {sf}, itâ€™s best to turn-off s2 and let {sf} calculate area on an ellipsoid (instead of a spherical approximation of the Earth). However, if speed is an issue and youâ€™re not as worried about accuracy, leave s2 on and calculate area using on a sphere.\nIf youâ€™re calculating area in an equal-area PCS using {sf}, it doesnâ€™t matter if s2 is on or off, area will be calculated using GEOS planar geometry engine.\n\n\n\nRaster area calculations\nLike {sf}, if your raster data is in a lat-long GCS, {terra} will compute area in meters squared using geodesic computations based on your spatial dataâ€™s ellipsoid with GeographicLib.\nNote that {terra} also has a class for vector data, called â€˜SpatVectorsâ€™ (raster objects are called â€˜SpatRastersâ€™). So we can also calculate area of vector data with {terra}. {sf} should provide the same estimate of area if s2 is turned off, meaning it is using GeographicLib for lat-long GCS computations. Letâ€™s see if this is the case.\nNote: The workflows below are borrowed from here.\nFirst, weâ€™ll create a polygon and a raster.\n\nlibrary(terra)\n\nterra 1.6.3\n\n\n\nAttaching package: 'terra'\n\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n\n#| warning: false\nsf_use_s2(TRUE) # make sure s2 is on (we already have sf loaded)\n\nSpherical geometry (s2) switched on\n\nr <- rast(nrows=10, ncols=10, xmin=0, ymin=0, xmax=10, ymax=10) # make a raster\nr <- init(r, 8) # initialise a spatraster with values\np <- vect('POLYGON ((2 2, 7 6, 4 9, 2 2))', crs = crs(r)) # make a vector polygon\nr_mask <- mask(r, p) # mask the raster to the polygon\nqtm(r) + qtm(r_mask) + qtm(st_as_sf(p))\n\n\n\n\n\nTry toggling the different layers on and off in the interactive map to see what the mask does.\nNote that the raster pixels cover a larger area than the polygon. By default â€˜maskâ€™ includes all raster pixels that the polygon touches. We could use the disagg function to reduce the resolution and better match the area of the raster to the area of the polygon (but we wonâ€™t do that here).\nNow letâ€™s compare area estimates with {terra} and {sf}.\n\narea_t <- expanse(p, unit = 'km') # here 'terra' is computing geodesic area (i.e., based on a spheroid, not planar)\nsf_use_s2(FALSE) # turn off s2 to uses the GeographicLig\n\nSpherical geometry (s2) switched off\n\narea_sf <- st_area(st_as_sf(p))/1e6 # here 'sf' using GEOS to calculate area\nround(area_t - as.numeric(area_sf))\n\n[1] 0\n\n\nGreat, so as we expect, no difference in area estimates between {terra} and {sf} when s2 geometry library is turned off.\n\nCompute area of raster data using {terra}\nLetâ€™s use {terra} to compute the area of a raster that intersects with a vector polygon. Weâ€™ll use the functions cellSize and mask from {terra}.\n\nr_area <- cellSize(r_mask, unit=\"km\") # create a raster where pixel values are area in km2\nqtm(r_area) + qtm(st_as_sf(p)) # have a quick look\n\n\n\n\ne <- extract(r_area, p, exact=TRUE) # extract pixel values that intersect with vector polygon, and get fraction of each cell that is covered\narea_t - sum(e$area * e$fraction) # calculate difference between area of the vector polygon, and the estimate of area of the 'raster'\n\n[1] 165.0552\n\n\nThere is a 165 km2 difference in area calculated using a raster vs.Â vector polygon.\n\n\nCompute area of raster data using {exactextractr}\n{exactextractr} can be used to perform raster computations within vector polygon areas very quickly, and it can do similar things as {terra}â€™s extract function that we used above. However, it uses a spherical approximation of the Earth, rather than a spheroid. Letâ€™s compare estimates of area between {terra} and {exactextractr}.\n\nlibrary(exactextractr)\n\ne2 <- exact_extract(r_area, st_as_sf(p))[[1]]\nsum(e$area * e$fraction) - sum(e2$value * e2$coverage_fraction)\n\n[1] 18.47752\n\n\nThe difference in area is very minor, ~18 km2. Which is faster?\n\nmicrobenchmark(extract(r_area, p, exact=TRUE), \n               exact_extract(r_area, st_as_sf(p)))\n\nUnit: milliseconds\n                               expr     min      lq      mean   median       uq\n   extract(r_area, p, exact = TRUE)  3.3216  3.7748  5.323969  4.06955  4.46350\n exact_extract(r_area, st_as_sf(p)) 21.1588 23.0546 26.905784 24.70470 26.17255\n      max neval cld\n  93.5680   100  a \n 168.5884   100   b\n\n\n{terra} wins! So in this case there is no speed vs.Â accuracy trade-off. {terra} is faster and more accurate, because it is not assuming that the Earth is a sphere to make area calculations.\n\n\nComparing PCS area computations between {terra} and {sf}\nDo estimates of vector polygon area differ between {terra} and {sf} when in an equal-area PCS, like mollweide?\n\narea_t_mollweide <- expanse(vect(dat_p), 'km', transform = F)\nround(as.numeric(area_mollweide) - area_t_mollweide)\n\n[1] 0\n\n\nNo difference.\n\n\nIn summaryâ€¦\nIf using a lat-long GCS to calculate area in R, {terra} and {sf} will provide the same estimates for vector polygons, as long as s2 is turned off. For raster areas in polygons, {terra} is faster and more accurate than {exactextractr}."
  },
  {
    "objectID": "posts/2023-01-22-newsletter-happy-new-year-february-meet-up-r-training/index.html",
    "href": "posts/2023-01-22-newsletter-happy-new-year-february-meet-up-r-training/index.html",
    "title": "Newsletter | Happy New Year! | February meet-up | R Training",
    "section": "",
    "text": "2023 is going to be a big year for the UQ Geospatial CoP.\nIn addition to monthly coding get-togethers, weâ€™d like to kick-start the year with a survey to get input on the following:\n\nWho is the geospatial community? Tell us what your career stage is so we can better cater to the demographic of the community.\nWhat should our new name be? Weâ€™d like to re-brand the community, mainly to remove â€˜UQâ€™ from the title as over the years the group has grown to include individuals from other universities and organisations.\nEstablishing a Code of conduct, mission statement, and organising committee for the group. More details to come, but if you are interested in volunteering your time to help organise activities throughout the year, please let us know in the survey and/or reach out by email. Roles may include: Speaker facilitator, Website and communications manager, Listserv manager, Treasurer/funding manager, etc.\nSpeaker and/or topic recommendations for 2023. Let us know who the heroes are in your field that youâ€™d like us to invite to speak to the Geospatial community. Alternatively, let us know what topics you are interested in learning about at one of the sessions.\n\n\n\n\nOn February 9th (2-4 pm) weâ€™ll have our first hybrid coding meet-up of the year, how to calculate areas accurately in R using both vector and raster data.\n\n\n\nUpcoming R courses on statistics and spatial analysis (Feb 14th-17th, register here):"
  },
  {
    "objectID": "posts/2022-09-09-newsletter/index.en.html",
    "href": "posts/2022-09-09-newsletter/index.en.html",
    "title": "Newsletter | Climate data blog post + problem solving session + conference in Fiji + more",
    "section": "",
    "text": "Last Thursday Ralph ran us through the basics of climate analysis in R. This was a really informative workshop that demystified climate data. All the scripts are now up on the blog, as well as a link to the materials. If you missed the workshop, the recording is up on cloudstor (let me know if you donâ€™t have access).\n\n\n\nOur next workshop will be a free-range problem-solving session. So, if you have any questions or issues you think someone in the community could help with, please bring them along.\n\n\n\nYou heard right! The Pacific Geospatial Conference will be held in Suva, Fiji from the 28th of November till 2nd December. Here is the Conference Program. By all reports this is an excellent conference that would be interesting to members of this community.\n\n\n\nThe UQ library will be hosting a QGIS: Custom Maps on your Phone workshop on Thursday 22 September 2022, 9.30am - 11.30am.\nThis session is split into two main sections. First it will cover useful spatial data portals (freely accessing aerial photography, government spatial data, quality digital elevation models, and more), and then it will cover how to package this data for use in the field on a mobile phone.\n\n\n\nResearch Fellow â€“ Remote sensing riparian vegetation, CDU, Darwin\nTeam Leader Conservation Planner / GIS analyst, Centre for Conservation Geography, Byron Bay\nGIS Analyst / Senior GIS Analyst, Ecology Australia, Melbourne\nGraduate GIS Analyst, Biosis, Melbourne"
  },
  {
    "objectID": "posts/2022-09-01-analysing-climate-data-with-r/index.en.html",
    "href": "posts/2022-09-01-analysing-climate-data-with-r/index.en.html",
    "title": "Analysing Climate data with R",
    "section": "",
    "text": "This post contains the scripts provided by Ralph Trancoso in the Analysing Climate Data in R workshop. The recording is also available, just email mitchel.rudge@uq.edu.au for access.\n\n1 Installing and loading the data, and the raster, ncdf4, rgdal, and ggplot2 packages, setting directory, loading gridded data\nTo follow this tutorial, you will need to download some prepared climate data.\nSave this link to somewhere on you computer, in our example the c drive, the unzip the folder.\nIf you donâ€™t have the â€˜rasterâ€™ and ncdf4 packages installed, install them:\n\ninstall.packages(\"raster\") # Installing the packages required for the workshop\ninstall.packages(\"ncdf4\")\ninstall.packages(\"rgdal\")\ninstall.packages(\"ggplot2\")\n\nNow load the raster package, and set the directory to where you stored the Rclim folder.\nSet your home directory, for example, if you put the rclim folder on you C drive:\nwriteClipboard(gsub(â€œ\\\\â€, â€œ/â€, readClipboard())\n\nhome <- \"C:/Rclim\"\n\nNow load the raster packages, and set your directory to where the climate data is.\n\nlibrary(raster)\nsetwd(home) #workshop dataset\n\nsetwd(paste0(home, \"/worldclim\")) # Set work directory to worldclim data\n#getwd() # get work directory\n#dir() # list files in the work directory\n?stack # what does stack do?\naus_temp <- stack(\"tmean_australia_wc.nc\")  # Loading gridded #data as RasterStack\n\n\n\n2 Querying the RasterStack data and quick plot using raster::plot and raster::spplot\nBelow are a whole bunch of checks that you can run on the raster data set.\n\nncol(aus_temp) #check the number of columns\n\n[1] 554\n\nnrow(aus_temp) #check the number of rows\n\n[1] 551\n\nncell(aus_temp) #check the number of cells\n\n[1] 305254\n\nnlayers(aus_temp) #check the number of layers\n\n[1] 12\n\ndim(aus_temp) #check the dimensions (rows, columns, layers)\n\n[1] 551 554  12\n\nprojection(aus_temp) #check the projection\n\n[1] \"+proj=longlat +datum=WGS84 +no_defs\"\n\nres(aus_temp) #check the resolution\n\n[1] 0.08333333 0.08333333\n\ninMemory(aus_temp) #check if the data is stored in memory\n\n[1] FALSE\n\nfromDisk(aus_temp) #check if the data was read from disk\n\n[1] TRUE\n\nnames(aus_temp) #check the names of the layers\n\n [1] \"X1\"  \"X2\"  \"X3\"  \"X4\"  \"X5\"  \"X6\"  \"X7\"  \"X8\"  \"X9\"  \"X10\" \"X11\" \"X12\"\n\n\nNow plot the rasters using the plot function:\n\nplot(aus_temp/10)\n\n\n\n\nOr use spplot:\n\nspplot(aus_temp/10) # lattice plot, returns a trellice \n\n\n\n\nEach layer represents a month of the year, from 1-12. So lets rename the layers and plot again.\n\nmonths <- c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\",\n            \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\")\n\nnames(aus_temp) <- months #set the layer names to months\n\nplot(aus_temp/10)\n\n\n\n\nOr, using spplot to create a lattice plot\n\nspplot(aus_temp/10) # lattice plot, returns a trellice  \n\n\n\n\n\n\n3 Calculating anomalies as gridded time-series and global average\nFirst, load the CMIP6 data set.\n\nsetwd(paste0(home, \"/CMIP6\")) # Set work directory to CMIP6 data\nproj_temp <- stack(\"tas_Asea_ACCESS-ESM1-5_ssp370_r1i1p1f1_gr1.5_1950-2100.nc\")\nnames(proj_temp)\n\n  [1] \"X1\"   \"X2\"   \"X3\"   \"X4\"   \"X5\"   \"X6\"   \"X7\"   \"X8\"   \"X9\"   \"X10\" \n [11] \"X11\"  \"X12\"  \"X13\"  \"X14\"  \"X15\"  \"X16\"  \"X17\"  \"X18\"  \"X19\"  \"X20\" \n [21] \"X21\"  \"X22\"  \"X23\"  \"X24\"  \"X25\"  \"X26\"  \"X27\"  \"X28\"  \"X29\"  \"X30\" \n [31] \"X31\"  \"X32\"  \"X33\"  \"X34\"  \"X35\"  \"X36\"  \"X37\"  \"X38\"  \"X39\"  \"X40\" \n [41] \"X41\"  \"X42\"  \"X43\"  \"X44\"  \"X45\"  \"X46\"  \"X47\"  \"X48\"  \"X49\"  \"X50\" \n [51] \"X51\"  \"X52\"  \"X53\"  \"X54\"  \"X55\"  \"X56\"  \"X57\"  \"X58\"  \"X59\"  \"X60\" \n [61] \"X61\"  \"X62\"  \"X63\"  \"X64\"  \"X65\"  \"X66\"  \"X67\"  \"X68\"  \"X69\"  \"X70\" \n [71] \"X71\"  \"X72\"  \"X73\"  \"X74\"  \"X75\"  \"X76\"  \"X77\"  \"X78\"  \"X79\"  \"X80\" \n [81] \"X81\"  \"X82\"  \"X83\"  \"X84\"  \"X85\"  \"X86\"  \"X87\"  \"X88\"  \"X89\"  \"X90\" \n [91] \"X91\"  \"X92\"  \"X93\"  \"X94\"  \"X95\"  \"X96\"  \"X97\"  \"X98\"  \"X99\"  \"X100\"\n[101] \"X101\" \"X102\" \"X103\" \"X104\" \"X105\" \"X106\" \"X107\" \"X108\" \"X109\" \"X110\"\n[111] \"X111\" \"X112\" \"X113\" \"X114\" \"X115\" \"X116\" \"X117\" \"X118\" \"X119\" \"X120\"\n[121] \"X121\" \"X122\" \"X123\" \"X124\" \"X125\" \"X126\" \"X127\" \"X128\" \"X129\" \"X130\"\n[131] \"X131\" \"X132\" \"X133\" \"X134\" \"X135\" \"X136\" \"X137\" \"X138\" \"X139\" \"X140\"\n[141] \"X141\" \"X142\" \"X143\" \"X144\" \"X145\" \"X146\" \"X147\" \"X148\" \"X149\" \"X150\"\n[151] \"X151\"\n\n\nWe can see that these names make no sense. So the names relate to years, we can re-name each layer:\n\nyears <- seq(1950, 2100, by=1)\nnames(proj_temp ) <- years\nnames(proj_temp)\n\n  [1] \"X1950\" \"X1951\" \"X1952\" \"X1953\" \"X1954\" \"X1955\" \"X1956\" \"X1957\" \"X1958\"\n [10] \"X1959\" \"X1960\" \"X1961\" \"X1962\" \"X1963\" \"X1964\" \"X1965\" \"X1966\" \"X1967\"\n [19] \"X1968\" \"X1969\" \"X1970\" \"X1971\" \"X1972\" \"X1973\" \"X1974\" \"X1975\" \"X1976\"\n [28] \"X1977\" \"X1978\" \"X1979\" \"X1980\" \"X1981\" \"X1982\" \"X1983\" \"X1984\" \"X1985\"\n [37] \"X1986\" \"X1987\" \"X1988\" \"X1989\" \"X1990\" \"X1991\" \"X1992\" \"X1993\" \"X1994\"\n [46] \"X1995\" \"X1996\" \"X1997\" \"X1998\" \"X1999\" \"X2000\" \"X2001\" \"X2002\" \"X2003\"\n [55] \"X2004\" \"X2005\" \"X2006\" \"X2007\" \"X2008\" \"X2009\" \"X2010\" \"X2011\" \"X2012\"\n [64] \"X2013\" \"X2014\" \"X2015\" \"X2016\" \"X2017\" \"X2018\" \"X2019\" \"X2020\" \"X2021\"\n [73] \"X2022\" \"X2023\" \"X2024\" \"X2025\" \"X2026\" \"X2027\" \"X2028\" \"X2029\" \"X2030\"\n [82] \"X2031\" \"X2032\" \"X2033\" \"X2034\" \"X2035\" \"X2036\" \"X2037\" \"X2038\" \"X2039\"\n [91] \"X2040\" \"X2041\" \"X2042\" \"X2043\" \"X2044\" \"X2045\" \"X2046\" \"X2047\" \"X2048\"\n[100] \"X2049\" \"X2050\" \"X2051\" \"X2052\" \"X2053\" \"X2054\" \"X2055\" \"X2056\" \"X2057\"\n[109] \"X2058\" \"X2059\" \"X2060\" \"X2061\" \"X2062\" \"X2063\" \"X2064\" \"X2065\" \"X2066\"\n[118] \"X2067\" \"X2068\" \"X2069\" \"X2070\" \"X2071\" \"X2072\" \"X2073\" \"X2074\" \"X2075\"\n[127] \"X2076\" \"X2077\" \"X2078\" \"X2079\" \"X2080\" \"X2081\" \"X2082\" \"X2083\" \"X2084\"\n[136] \"X2085\" \"X2086\" \"X2087\" \"X2088\" \"X2089\" \"X2090\" \"X2091\" \"X2092\" \"X2093\"\n[145] \"X2094\" \"X2095\" \"X2096\" \"X2097\" \"X2098\" \"X2099\" \"X2100\"\n\n\nThe X is at the start of each of each year to ensure they are of type character.\nNow we can create a simple function to calculate the temperature anomaly.\n\nanomaly <- function(x) {\n    anom <-  x - mean(x[[32:61]]) # for reference period 1981-2100\n    names(anom) <- seq(1950, 2100, by=1)    \n    return(anom)\n}\n\n\nT_anom <- anomaly(proj_temp)\n\nNow plot the temperature anomaly, from 1:16 (1950 - 1965)\n\nspplot(T_anom[[1:16]])\n\n\n\n\nAnd from 2084 - 2100\n\nspplot(T_anom[[135:151]])\n\n\n\n\nThen we can calculate the average temperature anomaly\n\nT_anom_mean <- as.data.frame(cbind(years, cellStats(T_anom, mean)))\nnames(T_anom_mean) <- c(\"year\", \"T_anom_mean\")\n\nFinally, we can take a look at the average temperature anomaloy for the entire dataset.\n\nsetwd(home) # Set work directory to main folder\ndir.create(\"output\")\nsetwd(paste0(home, \"/output\")) #set directory to output\njpeg(file=\"anomaly_ts.jpeg\", height = 600,  width = 1000, res=150)\nplot(T_anom_mean$year, T_anom_mean$T_anom_mean, type = \"p\", pch = 19, \n     col = \"red\", xlab=\"year\", ylab=\"Projected temperature anomaly\", \n     main=\"ACCESS-ESM1-5 SSP370 - ref period:1981-2010\")\ndev.off()\n\npng \n  2 \n\n\nHave a look in the output folder, you should see something like this\n\n\n\n4 Handling regions as shapefiles\nHere, we load and plot a shapefile of the worlds country boundaries.\nHere, we load and plot a shapefile of the worlds country boundaries.\n\nlibrary(rgdal)\n\nsetwd(paste0(home, \"/shp\"))\ncountries = readOGR(dsn=\".\", layer=\"TM_WORLD_BORDERS_SIMPL-0.3\")\n\nOGR data source with driver: ESRI Shapefile \nSource: \"C:\\Users\\uqnwiggi\\OneDrive - The University of Queensland\\UQGAC\\Rclim\\shp\", layer: \"TM_WORLD_BORDERS_SIMPL-0.3\"\nwith 246 features\nIt has 11 fields\nInteger64 fields read as strings:  POP2005 \n\nplot(countries)\n\n\n\n\nOr use spplot to color by population:\n\nspplot(countries, \"POP2005\")\n\n\n\n\n\n\n5 Regionalizations of climate data - plotting time-series as line plot and bar chart\n\nlibrary(ggplot2)\n\nsetwd(paste0(home, \"/CMIP6\")) # Set work directory to CMIP6 data\nproj_temp <- stack(\"tas_Asea_ACCESS-ESM1-5_ssp370_r1i1p1f1_gr1.5_1950-2100.nc\")\nproj_temp <- proj_temp -273.15\nnames(proj_temp) <- c(seq(1950,2100, by=1))\n\n## From your countries vector we read in, select a country customise your study area for the workshop analysis:\nmy_country <- subset(countries, NAME == \"Australia\")\n\n\ndf<- as.data.frame(countries@data)\n#fix(df) # to have a look at the dataframe of the countries\n\nmydf <- structure(list(\nlongitude = c(153.0251, 145.7781, 149.1821, 146.8169, 139.4927, 144.2555), \nlatitude = c(-27.4698, -16.9186, -21.1425, -19.2590, -20.7256, -23.4422)), \n.Names = c(\"longitude\", \"latitude\"), class = \"data.frame\", row.names = c(NA, -6L))\nxy <- mydf[,c(1,2)]\nspdf <- SpatialPointsDataFrame(coords = xy, data = mydf, proj4string = CRS(\"+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0\"))\n\nFinally, plot the points we chose on the map of Australia.\n\nplot(my_country)\nplot(spdf, add=T, col=\"red\")\n\n\n\n\n\nproj_temp_cities <- extract(proj_temp, spdf)\nproj_temp_cities <- as.data.frame(proj_temp_cities)\nproj_temp_cities <-as.data.frame(t(proj_temp_cities))\nproj_temp_cities$year <- 1:nrow(proj_temp_cities)+1980\nnames(proj_temp_cities) <- c(\"Brisbane\", \"Cairns\", \"Mackay\", \"Townsville\", \"Mount_Isa\", \"Longreach\", \"year\")\n\nWe can plot the projected temperature change of the cities we have selected.\nWe can plot the projected temperature change of the cities we have selected.\n\n#install.packages(\"reshape2\")\nlibrary(reshape2)\nproj_temp_cities_melt <- melt(proj_temp_cities, id=\"year\")\n\nts1 <- ggplot(proj_temp_cities_melt) +\n    geom_line(aes(x=year, y=value, colour=variable)) +\n    ggtitle(\"Projected average temperature ACCESS-ESM1.5 SSP3-7.0\") +\n    ylab(\"Temperature (Â°C)\")  +\n    scale_color_brewer(name= \"cities\", palette=\"Set1\") +\n    theme_bw() \nts1\n\n\n\n\n\n\n6 Convertig gridcells to data frame within a study area mask and plotting boxplots in ggplot2\n\nsetwd(paste0(home, \"/IPCC\")) # Set work directory to CMIP6 data\ndir() \n\n [1] \"CMIP6 - Consecutive Dry Days (CDD) Change days - Warming 1.5Â°C SSP5-8.5 (rel. to 1850-1900) - Annual (32 models).nc\"\n [2] \"CMIP6 - Consecutive Dry Days (CDD) Change days - Warming 2Â°C SSP5-8.5 (rel. to 1850-1900) - Annual (32 models).nc\"  \n [3] \"CMIP6 - Consecutive Dry Days (CDD) Change days - Warming 3Â°C SSP5-8.5 (rel. to 1850-1900) - Annual (32 models).nc\"  \n [4] \"CMIP6 - Consecutive Dry Days (CDD) Change days - Warming 4Â°C SSP5-8.5 (rel. to 1850-1900) - Annual (19 models).nc\"  \n [5] \"CMIP6 - Maximum temperature (TX) Change deg C - Warming 1.5Â°C SSP5-8.5 (rel. to 1850-1900) - Annual (27 models).nc\" \n [6] \"CMIP6 - Maximum temperature (TX) Change deg C - Warming 2Â°C SSP5-8.5 (rel. to 1850-1900) - Annual (27 models).nc\"   \n [7] \"CMIP6 - Maximum temperature (TX) Change deg C - Warming 3Â°C SSP5-8.5 (rel. to 1850-1900) - Annual (27 models).nc\"   \n [8] \"CMIP6 - Maximum temperature (TX) Change deg C - Warming 4Â°C SSP5-8.5 (rel. to 1850-1900) - Annual (16 models).nc\"   \n [9] \"CMIP6 - Mean temperature (T) Change deg C - Warming 1.5Â°C SSP5-8.5 (rel. to 1850-1900) - Annual (34 models).nc\"     \n[10] \"CMIP6 - Mean temperature (T) Change deg C - Warming 2Â°C SSP5-8.5 (rel. to 1850-1900) - Annual (34 models).nc\"       \n[11] \"CMIP6 - Mean temperature (T) Change deg C - Warming 3Â°C SSP5-8.5 (rel. to 1850-1900) - Annual (34 models).nc\"       \n[12] \"CMIP6 - Mean temperature (T) Change deg C - Warming 4Â°C SSP5-8.5 (rel. to 1850-1900) - Annual (20 models).nc\"       \n[13] \"CMIP6 - Total precipitation (PR) Change % - Warming 1.5Â°C SSP5-8.5 (rel. to 1850-1900) - Annual (33 models).nc\"     \n[14] \"CMIP6 - Total precipitation (PR) Change % - Warming 2Â°C SSP5-8.5 (rel. to 1850-1900) - Annual (33 models).nc\"       \n[15] \"CMIP6 - Total precipitation (PR) Change % - Warming 3Â°C SSP5-8.5 (rel. to 1850-1900) - Annual (33 models).nc\"       \n[16] \"CMIP6 - Total precipitation (PR) Change % - Warming 4Â°C SSP5-8.5 (rel. to 1850-1900) - Annual (19 models).nc\"       \n\n# Mean temperature\ntemp_list <- list.files(path= paste0(home, \"/IPCC\"), pattern = \"Mean temperature\", full.names = TRUE)\ntemp_GW <- stack(temp_list)\nnames(temp_GW) <- c(\"GW1.5\", \"GW2.0\", \"GW3.0\", \"GW4.0\") \nplot(temp_GW)\n\n\n\n\n\n#masking data outside country and converting grid to dataframe\n\ntemp_GW_country <- as.data.frame(mask(temp_GW, my_country))\ndim(temp_GW_country)\n\n[1] 64800     4\n\nhead(temp_GW_country)   \n\n  GW1.5 GW2.0 GW3.0 GW4.0\n1    NA    NA    NA    NA\n2    NA    NA    NA    NA\n3    NA    NA    NA    NA\n4    NA    NA    NA    NA\n5    NA    NA    NA    NA\n6    NA    NA    NA    NA\n\ntemp_GW_country <- na.omit(temp_GW_country)\ndim(temp_GW_country)\n\n[1] 699   4\n\n#install.packages(\"reshape2\")\nlibrary(reshape2)\ntemp_GW_country_m <- melt(temp_GW_country)\n\nNo id variables; using all as measure variables\n\n#creating a boxplot of avg temp per global warming level on ggplot2\n\nbp1 <- ggplot(temp_GW_country_m, aes(x=variable, y=value, fill=variable)) +\ngeom_boxplot()+\nxlab(\"Global warming level (Â°C)\")+\nylab(\"Change in average surface temperature (Â°C)\")+\nggtitle(paste(\"Change in average surface temperature per global warming level in \", my_country@data$NAME[1], sep=\"\")) +\ntheme_bw()\n\nbp1 <- bp1 + scale_color_brewer(name= \"GW level\", palette=\"YlOrRd\") # why it does not work? - change from color to fill\nbp1\n\n\n\n\n\n\n7 Repeat the extraction and plot for precipitation and/or other metrics\n\n# Total precipitation\nprec_list <- list.files(path= paste0(home, \"/IPCC\"), pattern = \"Total precipitation\", full.names = TRUE)\nprec_GW <- stack(prec_list)\nnames(prec_GW) <- c(\"GW1.5\", \"GW2.0\", \"GW3.0\", \"GW4.0\") \nplot(prec_GW)\n\n\n\n\n\n#masking data outside country and converting grid to dataframe\n\nprec_GW_country <- as.data.frame(mask(prec_GW, my_country))\nprec_GW_GW_country <- na.omit(prec_GW_country)\nprec_GW_country_m <- melt(prec_GW_country)\n\nNo id variables; using all as measure variables\n\n#creating a boxplot of precipitation per global warming level on ggplot2\n\nbp2 <- ggplot(prec_GW_country_m, aes(x=variable, y=value, fill=variable)) +\ngeom_boxplot()+\nxlab(\"Global warming level (Â°C)\")+\nylab(\"Change in total precipitation (%)\")+\nggtitle(paste(\"Change in total precipitation per global warming level in \", my_country@data$NAME[1], sep=\"\")) +\ntheme_bw() +\nscale_fill_brewer(name= \"GW level\", palette=\"YlOrRd\")\nbp2\n\nWarning: Removed 256404 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\n\n\nWhere to find climate data\nIPCC interactive atlas The authority for climate data is the IPCC. And the interactive atlas has the latest data https://interactive-atlas.ipcc.ch/regional-information\nWorldclim Global climate and weather data. WorldClim is a database of high spatial resolution global weather and climate data. https://www.worldclim.org/\nSILO gridded data for Australia until yesterday: https://longpaddock.qld.gov.au/silo/gridded-data/\nLongPaddock Provided by the Queensland Government, gridded data available for a range of variables in NetCDF and GeoTiff formats. The NetCDF datasets are arranged in annual blocks where each file contains all of the grids for the selected year and variable. https://longpaddock.qld.gov.au\nCMIP5 downscaled climate projections over Queensland High-resolution climate change projections for Queensland using dynamical downscaling of CMIP5 global climate models are available for download in gridded format with spatial resolution of 10 km at Terrestrial Ecosystem Research Network (TERN) https://longpaddock.qld.gov.au/qld-future-climate/data-info/tern/\n\n\nAbout the author\n\n \nRalph is a research scientist with expertise in climate change, ecohydrology, and deforestation impacts. Ralph is particularly interested in how climate and landscape changes affect the environment and impact society. He is a Principal Climate Change Scientist at the Department of Environment and Science (Queensland Government) and a Research Fellow at the School of Biological Sciences (University of Queensland)."
  },
  {
    "objectID": "posts/2022-08-16-newsletter/index.en.html",
    "href": "posts/2022-08-16-newsletter/index.en.html",
    "title": "Newsletter | Analysing climate data with R + Interactive Maps + AEO Forum + more.",
    "section": "",
    "text": "A huge thanks to Christina for the interactive mapping with RShiny workshop. All the material is available here. There was a lot of interest in the subject of interactive maps, and talk of a follow up session. Christina is very knowledgeable on all thing R-spatial, and would be happy to help if you are stuck trying to make a web map.\n\n\n\nWe have another great workshop is lined up. Ralph Trancoso is going to show us how to delve into climate data - both observations and projections - using R. If you want to include climate data in your research but donâ€™t know where to start, you really wonâ€™t want to miss this one!\n\n\n\nNick Wiggins is taking over from Stephane in organising the UQ R user group sessions. The next one will be on August 24th. Each session is recorded on this collaborative document.\nAs well as the R users group, Nick will be hosting some beginner spatial analysis sessions. Introduction to QGIS will be held on Thursday 25 August 2022, 9.30am - 11.30am Introduction to Raster Analysis Will be held on Thursday 8 September 2022, 9.30am - 11.30am All hosted through the UQ library, book through here.\n\n\n\nThe Advancing Earth Observation Forum will be held next week, 22nd â€“ 26th August at the Brisbane Convention and Exhibition Centre. This will be a great opportunity to connect with and learn from others in the earth observation community. Registrations are still open.\n\n\n\nUnfortunately, the 2022 ResBaz conference has been postponed due to the Covid and flu surge. We will provide updates as they become available.\n\n\n\nmapscaping is a spatial podcast where they discuss a lot of interesting geospatial topics that come up in our sessions, so definitely worth checking out.\n\n\n\nHere are a few job vacancies from across the country that might be of interest. If you know of any vacancies, send them in and they will be included with the next newsletter.\nGraduate Spatial information officer, QLD government, Location flexible.\nGeospatial engineer, Nova Systems, Brisbane\nGIS technician, TerraLab, Victoria\nTeam Leader Conservation Planner / GIS analyst, Centre for Conservation Geography, Byron Bay."
  },
  {
    "objectID": "posts/2022-04-28-cloud-computing-with-open-data-cube-and-python/index.en.html",
    "href": "posts/2022-04-28-cloud-computing-with-open-data-cube-and-python/index.en.html",
    "title": "Cloud computing with Open Data Cube and Python",
    "section": "",
    "text": "This workshop broadly covered remote sensing data analysis using the Open Data Cube (ODC), developed by Geoscience Australia. We went over some important Python packages that the ODC is built upon: Numpy, Xarray, and Dask, and explored how they enable fast and scalable computation.\nAll the learning material used in this tutorial is available on the Digital Earth Australia Sandbox as Jupyter Notebooks. An account was required to participate, which can easily be created here.\nAdditional documentation for the DEA Sandbox is available here which includes useful guides, a dataset catalogue and examples.\nIf you missed the demonstration, the recording is available on our cloudstor site, email mitchel.rudge@uq.edu.au to get access.\n\nAbout the presenter\nThe workshop was be presented by Tim Devereux.\n\n\n\n \n\nTim is a PhD candidate with the UQ Remote Sensing Research Centre (RSRC), and has a background in Environmental and Computational Sciences. His research is focused on the development of high fidelity digital representations of Australian forests for next generation simulations. He is also a demonstrator for the SEES advanced remote sensing course at UQ."
  },
  {
    "objectID": "posts/2022-07-14-newsletter-mapping-interactively-r-for-ecologists-data-wrangling-more/index.html",
    "href": "posts/2022-07-14-newsletter-mapping-interactively-r-for-ecologists-data-wrangling-more/index.html",
    "title": "Newsletter | Mapping interactively + R for ecologists + Data wrangling + more.",
    "section": "",
    "text": "We have put together a summary of last weekâ€™s workshop.\nThanks to everyone who had questions, answers, and contributions. It should all be captured in the post now. If you would like me to make any edits to the post, or better still if there are development on the problems, please let me know and I can easily update the details.\n\n\n\nChristina Buelow from Griffith will be hosting this 1-day course. It will be extremely useful whether you are relatively new to geospatial in R, or looking to hone your skills. https://smp.uq.edu.au/event/session/11370 Cost is $150 for students (hopefully there are still spots available)\n\n\n\nChristina will also be hosting a 100% free Mapping interactively with Rshiny workshop later in the month. Please spread the word, this is sure to be an excellent use of time if you have ever thought about putting your maps and data online.\n\n\n\nAdvanced R workshop with Bill Venables The advanced R workshop with Bill Venables was cancelled but he is doing it for free over several weeks 1 hr on Monday, Wednesday and Friday.\nIf youâ€™re interested, email roxanne.jemison@uq.edu.au who is organising it.\n\n\n\nEcoCommons, who are creating a platform for digital modelling and analysis (read more here https://www.ecocommons.org.au/about/), have a new educational package: R for Ecologists (https://www.ecocommons.org.au/educational-material/). This is based on this data carpentry module. All videos are 100% free on youtube, and include plenty of spatial content including species distribution modelling.\n\n\n\nWe are putting together an organising committee to help coordinate workshops, this newsletter, and any other new ideas we might have. If you would be interested in volunteering a small amount of time, please get in touch.\n\n\n\nHere are a few job vacancies from across the country that might be of interest. Mainly taken from NRM jobs. If you know of any vacancies, send them in and Iâ€™ll include them on the next newsletter.\nSpatial Scientist â€“ NSW Department of Planning and Environment (Paramatta, NSW)\nAssistant Director â€“ Scientist (Geospatial â€“ Land use). Federal department of Agriculture, Fisheries and Forestry. (Canberra)\nSpatial Information Systems Officer. Timberlands Pacific (Launceston, Tasmania)\nGIS analyst. Eco Logical Australia. (Adelaide, SA)\nNatural Hazard and Spatial Analyst. Molino Stewart (Paramatta, NSW)"
  },
  {
    "objectID": "posts/2022-07-07-problem-solving-session-ii/index.html",
    "href": "posts/2022-07-07-problem-solving-session-ii/index.html",
    "title": "Problem Solving Session II",
    "section": "",
    "text": "Following the success of our last problem solving session, we ran another one in June.\n\nWe had interesting and wide-ranging discussions about the issues people are having with geospatial analysis.\nBelow are some of the key issues / contributions / suggestions that came up.\n\n\nLorna has been processing some massive raster datasets in R, and has been running into persistent RAM issues. The code below contains a few tricks of the trade to try to help get you up and running if you are running into RAM issues.\n\n\nThis includes a section about changing the RAM allocated to java - which is required for the species distribution modelling package MaxEnt.\n\n#increase RAM allocation; once increased you cannot decrease it until you restart your session\nmemory.limit(8000)\nmemory.limit(5000) #is ignored\n###check current RAM allocation\nmemory.limit()\n\n#if you restart r session it goes back to original RAM allocation\nmemory.limit()\n####\n# change RAM allocated to java (heap space)\n###\n#more niche, but java is needed to run MaxEnt (species distribution modelling)\n#settings need to be changed before opening the library\noptions(java.parameters = c(\"-XX:+UseConcMarkSweepGC\", \"-Xmx16000m\"))\n\n\n\n\n\nYou can also increase the RAM available to specific packages - namely the raster and terra packages:\n\n###with raster package\n\n#check allocated fraction (and other raster settings, including temporary directory)\nrasterOptions()\n\n#can increase or decrease in same session\nrasterOptions(memfrac=0.9)\nrasterOptions(memfrac=0.3)\n\n#restarting session goes back to original allocation\n\nwith terra package; Mitch showed us: https://geospatial-community.netlify.app/post/2022-02-23-raster-analysis/\n\nlibrary(terra)\nterraOptions()\nterraOptions(memfrac=0.7)\n\n#and you can also change the temp directory directly for terra... but only terra\nterraOptions(memfrac=0.2, tempdir = \"R:/big_drive/Trial\")\n\n\n\n\nAs described here, you can change the temp directory so it doesnâ€™t fill up your computer.\n\nSys.getenv() #to check all setting of the environment\n\n#check the directories now\nSys.getenv(\"TMPDIR\",\"TMP\",\"TEMP\")\n\n#each path needs to be specifically written (otherwise it doesnt work, because of the quotations) \ntochange<-c(\"TMPDIR = 'R:/large_disk/RtempFiles'\",\n            \"TMP = 'R:/large_disk/RtempFiles'\",\n            \"TEMP = 'R:/large_disk/RtempFiles'\")\n#\"R:/large_disk/Trial\"\n\n#write the file as .Renviron in your associated user path (R_USER)\nwrite(tochange, sep=\"c\", file=file.path(Sys.getenv('R_USER'), '.Renviron'))\nSys.getenv('R_USER') #the path where the file was written\n\n#restart session, can be without closing R\nSys.getenv(\"TMPDIR\",\"TMP\",\"TEMP\")\n\n\n\n\nBy default, R uses only one core;but most computers these days have multiple cores\nHere is a summary.\nHere are 2 ways to do this. ###1.\n\n#specific to an operation, but cannot do many raster operations\nclusterR(x, fun, args=NULL, cl=mycluster)\n\n###2.\nThis is the easiest, because you can put anything you need in between\n\nbeginCluster()\nendCluster()\n\nAs an example:\n\n#e.g.\nParentDir<-\"R:\\\\FITZBIO-A6478\\\\4_Analysis\\\\R\\\\1_HSModel\\\\2_RasterTifs\\\\F3_90m\"\nLayer1 <-raster(file.path(paste0(ParentDir,\"\\\\Bio1.tif\")))\nLayer2 <-raster(file.path(paste0(ParentDir,\"\\\\Bio2.tif\")))\n#plot(Layer1) \n#plot(Layer2)\n#without using multiple cores\nstart_time <- Sys.time()\ns<-stack(Layer1,Layer2)\nLay1xLay2<-overlay(s, fun=function(x,y) x*y )\nend_time <- Sys.time()\nNoCore<-end_time - start_time\n\n#using multiple cores, but measuring time only of the process itself\nbeginCluster()\nstart_time <- Sys.time()\ns<-stack(Layer1,Layer2)\nLay1xLay2<-overlay(s, fun=function(x,y) x*y )\nend_time <- Sys.time()\nendCluster()\nTimeExlcudeCore<-end_time - start_time\n\n#using multiple cores, measuring time of whole process (including parallelizing)\nstart_time <- Sys.time()\nbeginCluster()\ns<-stack(Layer1,Layer2)\nLay1xLay2<-overlay(s, fun=function(x,y) x*y )\nendCluster()\nend_time <- Sys.time()\nTimeIncludeCore<-end_time - start_time\n\n#check time results\nNoCore\nTimeExlcudeCore\nTimeIncludeCore\n#when preparing this, sometimes I got same results sometimes I didn't\n\n\n\n\nRunning gc() gets rid of temp files, so be sure to save results needed and not do it half way through a process that relies on temp files\n\n\n\nIf all else fails, you could think about how much resolution you actually need, and whether it could be reduced.\n\n#rescale base layer; basis for the rest\nBaseLayerFX<-aggregate(Layer1, fact=factor) #factor defined where paths are loaded\n\nLayer2_coarse<-resample(Layer2,BaseLayerFX) #it will match the extent of the baselayer\n#if you aggregate Layer2, there might be slight differences in pixel positions/extents etc-so they may not match\n#it is best to resample using the first one as basis\n\n####\n# save layers you create in between\n###\n#so next time you don't have to re-do them... \n#it saves times for you and it frees up memory both for new processes -and garbage collection gc()\n\n#e.g.\n#writeRaster(Layer2_coarse, filename=file.path(ProcessOut,paste0(\"uchas.tif\")), format=\"GTiff\", overwrite=FALSE)\n\n\n\n\nStill on the subject of memory, Tim showed us how to use the doParallel package in R, with a reproducible example.\nThis is a very basic example of what is called an embarrassingly parallel task, but should be a nice short intro for absolute beginners to parallel programming.\nParallel computing is a complex field of computer science. Performance is dependent on many factors including algorithm complexity, hardware IO performance and input data interdependence. Wikipedia has a nice overview of these topics here: https://en.wikipedia.org/wiki/Parallel_computing#Types_of_parallelism\n\n# First we define our function. For the sake of clear example this function just sleeps for n seconds which is given as input.\n\ndo_something <- function(n)\n{\n    Sys.sleep(n)\n}\n\n\n### Base R for loop ###\n\n# Define number of iterations\niterations = 6\n\n# Start process timer\nstart <- proc.time()\n\n# Call our function using a base R for loop, this is executed sequentially using one process. \nfor (x in 1:iterations){\n  do_something(1)\n}\n\n# Stop process timer\nbase_loop <- proc.time()-start\n\n\n# Print duration to console\nprint(base_loop)\n\n   user  system elapsed \n   0.01    0.00    6.11 \n\n\n\n# Import doParallel \nlibrary(doParallel)\n\nLoading required package: foreach\n\n\nLoading required package: iterators\n\n\nLoading required package: parallel\n\n\n\n# Using doParallel.detectCores(), detect the number of cores on your machine.\ndetectCores()\n\n[1] 8\n\n\n\n# Using doParallel.registerDoParallel(), allocate a number of cores available for processing in parallel.\nregisterDoParallel(6)\n\n\n### doParaellel %do% ###\n\n# Start process timer\nstart <- proc.time()\n\n# Call our function using a doParaellel %do% loop, this is also executed sequentially using one process. \n\nr <- foreach(icount(iterations)) %do% {\n  do_something(1)\n}\n\n# Stop process timer\ndo_loop <- proc.time()-start\n\n# Print duration to console\nprint(do_loop)\n\n   user  system elapsed \n   0.00    0.00    6.15 \n\n\nThis takes a similar amount of time to process as base R. Some functions do not gain performance when parallelised or the output of a function may be more reliable when executed as a single process. So in some situations parallelism is not always desired.\n\n### doParaellel %dopar% ###\n  \n# Start process timer\nstart <- proc.time()\n\n# Call our function using a doParaellel %dopar% loop, this is executed in parallel.\nr <- foreach(icount(6)) %dopar% {\n  do_something(1)\n}\n\n# Stop process timer\ndopar_loop <- proc.time()-start\n\n# Print duration to console\nprint(dopar_loop)\n\n   user  system elapsed \n   0.02    0.00    1.08 \n\n\nIt takes ~1 seconds to run the our function on 6 cores. How long would it take on 3 cores, or 12 cores? What happens if we change the number of iterations?\n\n# Print concatenated results to console. \nprint(rbind(base_loop,do_loop,dopar_loop)[,1:3])\n\n           user.self sys.self elapsed\nbase_loop       0.01        0    6.11\ndo_loop         0.00        0    6.15\ndopar_loop      0.02        0    1.08\n\n\n\n\n\nRichard is running some geospatial analysis using the terra package.He ultimately wants this code to be free of warnings etc, so he can turn it into a shiny app.\nBut is constantly getting this warning: Error in (function (x) : attempt to apply non-function\nThis is discussed here.\nWhere Robert Hijmans (the main terra developer), seems to say that it is an annoying problem with no solution.\nApril 2022, from Robert Hijmans: >You can ignore these messages from the garbage collector. They do not affect your data. They are very annoying. I have done a lot of things to get to the bottom of this, but sofar to no avail. I have much simpler packages that also show these messages and I need to go back to one of these to create a reproducible example for others to look at (even it only happens on the first run) that does not require installation of GDAL etc.\nIt appears to be related to the garbage collection R function gc()\nOne person suggested this as a â€œdirty workaroundâ€ try(terra::XXX, silent = TRUE)\nSo it seems that there is no easy solution to this particular error.\n\n\n\nThis is currently unsolved, so please get in touch if you have a solution\nCatherine is having an issue with reprojecting between rasters with certain EPSG codes in terra.\nProject CRS is epsg:28355, but also has one raster in epsg:9001. So trying to convert the 9001 to 28355 and it is not working.\nAlso found that when trying to make a reproducible example, got NAs for the reprojected raster - whether reprojecting from 9001 or 28355â€¦\nTesting reproject from EPSG 9001 to 4326\n\nlibrary(terra)\n\nterra 1.7.18\n\n    # Create a raster with EPSG:4326 projection\n    target <- rast(nrows=108, ncols=21, xmin=0, xmax=50,\n              vals = rep(1:21, each = 2),\n              crs = \"EPSG:4326\")\n\nWarning: [setValues] values were recycled\n\n    plot(target)\n\n\n\n    crs(target)\n\n[1] \"GEOGCRS[\\\"WGS 84\\\",\\n    ENSEMBLE[\\\"World Geodetic System 1984 ensemble\\\",\\n        MEMBER[\\\"World Geodetic System 1984 (Transit)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G730)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G873)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1150)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1674)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1762)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G2139)\\\"],\\n        ELLIPSOID[\\\"WGS 84\\\",6378137,298.257223563,\\n            LENGTHUNIT[\\\"metre\\\",1]],\\n        ENSEMBLEACCURACY[2.0]],\\n    PRIMEM[\\\"Greenwich\\\",0,\\n        ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    CS[ellipsoidal,2],\\n        AXIS[\\\"geodetic latitude (Lat)\\\",north,\\n            ORDER[1],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n        AXIS[\\\"geodetic longitude (Lon)\\\",east,\\n            ORDER[2],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    USAGE[\\n        SCOPE[\\\"Horizontal component of 3D system.\\\"],\\n        AREA[\\\"World.\\\"],\\n        BBOX[-90,-180,90,180]],\\n    ID[\\\"EPSG\\\",4326]]\"\n\n\n\n# Create a raster with EPSG:4326 projection \n    y <- rast(nrows = 54, ncols = 21, xmin = 0, xmax = 50,\n              vals = rep(1:21, each = 2),\n              crs = \"EPSG:9001\")\n\nWarning: [setValues] values were recycled\n\n    y\n\nclass       : SpatRaster \ndimensions  : 54, 21, 1  (nrow, ncol, nlyr)\nresolution  : 2.380952, 3.333333  (x, y)\nextent      : 0, 50, -90, 90  (xmin, xmax, ymin, ymax)\ncoord. ref. : +proj=geocent +ellps=GRS80 +units=m +no_defs \nsource(s)   : memory\nname        : lyr.1 \nmin value   :     1 \nmax value   :    21 \n\n    plot(y)\n\n\n\n    # project to target raster\n    z <- project(y, target, method = \"near\")\n    z\n\nclass       : SpatRaster \ndimensions  : 108, 21, 1  (nrow, ncol, nlyr)\nresolution  : 2.380952, 1.666667  (x, y)\nextent      : 0, 50, -90, 90  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsource(s)   : memory\nname        : lyr.1 \nmin value   :   NaN \nmax value   :   NaN \n\n    # the min/max values are NaN?\n    plot(z) # blank...\n\n\n\n\n\n\n\nPaul is wanting to make some interactive maps as part of his thesis. Some discussion about the options that are out there. ### Blogdown. One option is to use something like blogdown. There are examples on this website, like Stephanes excellent work describing tidy networks.\n\n\nLeaflet is another option.\nThis might give more flexibility in terms of map making, but doesnâ€™t give you the document format.\nWe will stay posted with what Paul ends up doing!\n\n\n\n\nDeqiang is wanting to know how to run arcpy on the supercomputer.\nBecause Arcpy uses windows, it is not able to be run on any of the university HPCsâ€¦\nGabriel had had similar issues with arcpy, and confirmed that the HPC will not support arcpy with because it uses linux based clusters\nGabriel suggested running arcpy using the multiprocessing library\nAn alternative would be to re-code the least cost algorithm using python https://gis.stackexchange.com/questions/28583/gdal-perform-simple-least-cost-path-analysis\n\n\n\nThere was some discussion of debugging in R. This post was shared as a starting point.\nBecause debugging is something most of thought we could do better at, it might be a good candidate for a workshop down the track."
  },
  {
    "objectID": "posts/2021-10-28-creating-a-geospatial-blog-with-blogdown/index.html",
    "href": "posts/2021-10-28-creating-a-geospatial-blog-with-blogdown/index.html",
    "title": "Creating a geospatial blog with blogdown",
    "section": "",
    "text": "In this post, we will go through the process of creating a geospatial blog, specifically this blog.\nFirst, we will run through how to create a site and host it through github and netlify. Then we will show you the options for publishing both a raster and vector data."
  },
  {
    "objectID": "posts/2021-10-28-creating-a-geospatial-blog-with-blogdown/index.html#good-resources",
    "href": "posts/2021-10-28-creating-a-geospatial-blog-with-blogdown/index.html#good-resources",
    "title": "Creating a geospatial blog with blogdown",
    "section": "Good resources",
    "text": "Good resources\n\nhttps://www.apreshill.com/blog/2020-12-new-year-new-blogdown/\nhttps://www.youtube.com/watch?v=x-Ch0-w1UhY\nhttps://solomonkurz.netlify.app/post/2021-05-03-blogdown-updates-prompted-a-website-overhaul-these-are-my-notes/\nhttps://bookdown.org/yihui/blogdown/installation.html"
  },
  {
    "objectID": "posts/2021-10-28-creating-a-geospatial-blog-with-blogdown/index.html#prerequisites",
    "href": "posts/2021-10-28-creating-a-geospatial-blog-with-blogdown/index.html#prerequisites",
    "title": "Creating a geospatial blog with blogdown",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nFairly recent version of R studio (RStudio IDE version, v1.4.1106 +)\nGithub account\nGIT locally on computer. (Happy git with R https://happygitwithr.com/)\n\ngitforwindows.org\nDownload GNU\nDefault on all settings ï‚§ Make sure to select Git from the command line and also from 3rd party software\n\nSign up for Netlify using Github account"
  },
  {
    "objectID": "posts/2021-10-28-creating-a-geospatial-blog-with-blogdown/index.html#create-a-new-github-repository",
    "href": "posts/2021-10-28-creating-a-geospatial-blog-with-blogdown/index.html#create-a-new-github-repository",
    "title": "Creating a geospatial blog with blogdown",
    "section": "1. Create a new github repository",
    "text": "1. Create a new github repository\nInitialise with readme, but donâ€™t add the .gitignore file. Then copy link https link."
  },
  {
    "objectID": "posts/2021-10-28-creating-a-geospatial-blog-with-blogdown/index.html#create-a-new-project-in-r-studio",
    "href": "posts/2021-10-28-creating-a-geospatial-blog-with-blogdown/index.html#create-a-new-project-in-r-studio",
    "title": "Creating a geospatial blog with blogdown",
    "section": "2. Create a new project in R studio",
    "text": "2. Create a new project in R studio\nIn R studio, go to File > new project > Version control > git, and Paste the URL from before. Save the project somewhere sensible.\nNow install blogdown with Install.packages(â€œblogdownâ€), and load with library(blogdown).\n\ninstall.packages(\"blogdown\")\nlibrary(blogdown)\n\nNow to create a new site, just add\n\nnew_site()\n\nThis will give the default theme, but there are a lot of different themes to choose from!\nhttps://themes.gohugo.io/\nIts important to find one that you like, but also that is up to date and works. For this blog, we ended up going with https://themes.gohugo.io/themes/anatole/ over some other options which were buggy, probably due to being out of date.\nSo to build the site with your theme of choice, run\n\nnew_site(theme = \"lxndrblz/anatole\")\n\nAdding theme= â€œgighubusername/themerepoâ€ of the theme you choose.\nWhen prompted, select y to let blogdown start a server. This will let you preview the site in the viewer. To view in a browser, click the show in new window (next to the broom) to launch it locally.\nGenerally, you can serve the site, and stop serving the sites using\n\nblogdown::serve_site() #to serve the site locally\nblogdown::stop_server() #to stop serving the site"
  },
  {
    "objectID": "posts/2021-10-28-creating-a-geospatial-blog-with-blogdown/index.html#write-a-post",
    "href": "posts/2021-10-28-creating-a-geospatial-blog-with-blogdown/index.html#write-a-post",
    "title": "Creating a geospatial blog with blogdown",
    "section": "3. Write a post",
    "text": "3. Write a post\nHopefully the local site is working. We can now add a new blog post using either\n\nblogdown::new_post() \n\nOR, a better method is to navigate through addins dropdown (under help, right of git icon), click new_post. This brings up a dialog to fill out.\nSelect file type, markdown for simple text, or .Rmd or .Rmarkdown for embedding code.\nNow we can add code chunks! The easiest way to do this is to click the green +c just above the editor.\nAs an example\n\nlibrary(ggplot2)\nggplot(Orange, aes(x = age, \n                   y = circumference, \n                   color = Tree)) +\n  geom_point() +\n  theme_bw()\n\n\n\n\nIf its not working, run\n\nblogdown::check_site() \n\nand follow the instructions next to the [todo] items."
  },
  {
    "objectID": "posts/2021-10-28-creating-a-geospatial-blog-with-blogdown/index.html#load-to-github",
    "href": "posts/2021-10-28-creating-a-geospatial-blog-with-blogdown/index.html#load-to-github",
    "title": "Creating a geospatial blog with blogdown",
    "section": "4. load to github",
    "text": "4. load to github\nIn the files tab, navigate to the .gitignore file. Add so it contains the following .Rproj.user .Rhistory .RData .Ruserdata .DS_Store Thumbs.db /public/ /resources/\nNow run\n\nblogdown::check_gitignore() \n\n#and \n\nblogdown::check_content()\n\nThen commit the files and push to github.\nDue to the massive number of files associated with the themes, we found it better to do the first commit through the shell\nTools>shell>git add -A\nTo authorise github, we found the best option to be to\nControl Panel > User Account > Credential Manager > Windows Credential > Generic Credential\nThen remove git credential\nThen, when you push the repo itâ€™ll ask you for credential through the browser."
  },
  {
    "objectID": "posts/2021-10-28-creating-a-geospatial-blog-with-blogdown/index.html#publish-site",
    "href": "posts/2021-10-28-creating-a-geospatial-blog-with-blogdown/index.html#publish-site",
    "title": "Creating a geospatial blog with blogdown",
    "section": "5. Publish site!",
    "text": "5. Publish site!\nLog into netlify (using github account). Then click new site from git, continuous deployment: Github. you should be able to see the repo from within netlify. Select deploy site.\nIt will give you a temporary URL which is live! Now it will automatically update every time you push changes to github.\nTo change the site name, general > site details > change site name\nNow go back to R studio, and navigate to teh config (yaml or toml) and add in the correct url (probably around line 3)\nRun Blogdown::check_netlify() to find any issues."
  },
  {
    "objectID": "posts/2021-10-28-creating-a-geospatial-blog-with-blogdown/index.html#load-necessary-packages",
    "href": "posts/2021-10-28-creating-a-geospatial-blog-with-blogdown/index.html#load-necessary-packages",
    "title": "Creating a geospatial blog with blogdown",
    "section": "Load necessary packages",
    "text": "Load necessary packages\n\nlibrary(sf)\n\nLinking to GEOS 3.9.3, GDAL 3.5.2, PROJ 8.2.1; sf_use_s2() is TRUE\n\nlibrary(tmap)"
  },
  {
    "objectID": "posts/2021-10-28-creating-a-geospatial-blog-with-blogdown/index.html#get-the-data",
    "href": "posts/2021-10-28-creating-a-geospatial-blog-with-blogdown/index.html#get-the-data",
    "title": "Creating a geospatial blog with blogdown",
    "section": "Get the data",
    "text": "Get the data\nThe process to get the data is stored in a script (scripts/get_osm_data.R), instead of integrating it into this R Markdown file. This allows us to not overload the data provider but always querying the API, every single time the article is rendered! (And we donâ€™t need to process the data every time either.)\nHere, we only need to read the data from a file that was previously created:\n\ngreen_space <- st_read(\"data/green_spaces.geojson\")\n\nReading layer `green_spaces' from data source \n  `C:\\Git\\geocommunity_blog\\posts\\2021-10-28-creating-a-geospatial-blog-with-blogdown\\data\\green_spaces.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 5861 features and 3 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 152.6764 ymin: -27.67486 xmax: 153.4664 ymax: -27.00613\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "posts/2021-10-28-creating-a-geospatial-blog-with-blogdown/index.html#visualise-on-a-slippy-map",
    "href": "posts/2021-10-28-creating-a-geospatial-blog-with-blogdown/index.html#visualise-on-a-slippy-map",
    "title": "Creating a geospatial blog with blogdown",
    "section": "Visualise on a slippy map",
    "text": "Visualise on a slippy map\nThe tmap package is useful to visualise vector data on a slippy map.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(green_space) +\n  tm_polygons(col = c(\"#43C467\"), alpha = 0.5)\n\n\n\n\n\n\n\nData is copyright OSM contributors but release under an ODBL licence."
  },
  {
    "objectID": "posts/2021-10-28-creating-a-geospatial-blog-with-blogdown/index.html#load-the-packages",
    "href": "posts/2021-10-28-creating-a-geospatial-blog-with-blogdown/index.html#load-the-packages",
    "title": "Creating a geospatial blog with blogdown",
    "section": "Load the packages",
    "text": "Load the packages\n\nlibrary(terra)\n\nterra 1.7.18"
  },
  {
    "objectID": "posts/2021-10-28-creating-a-geospatial-blog-with-blogdown/index.html#import-the-data",
    "href": "posts/2021-10-28-creating-a-geospatial-blog-with-blogdown/index.html#import-the-data",
    "title": "Creating a geospatial blog with blogdown",
    "section": "Import the data",
    "text": "Import the data\nThe data comes from the Bureau of Meteorology website, it is a raster file of average annual rainfall. Weâ€™ve put the file into a data directory, inside the blog postâ€™s directory.\n\nrain <- rast(\"data/rainan.txt\")"
  },
  {
    "objectID": "posts/2021-10-28-creating-a-geospatial-blog-with-blogdown/index.html#inspect",
    "href": "posts/2021-10-28-creating-a-geospatial-blog-with-blogdown/index.html#inspect",
    "title": "Creating a geospatial blog with blogdown",
    "section": "Inspect",
    "text": "Inspect\n\nrain\n\nclass       : SpatRaster \ndimensions  : 691, 886, 1  (nrow, ncol, nlyr)\nresolution  : 0.05, 0.05  (x, y)\nextent      : 111.975, 156.275, -44.525, -9.975  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 \nsource      : rainan.txt \nname        : rainan \n\n\nOne single band, by default with the WGS 84 CRS.\nThe average rainfall for the whole raster is 451.61 mm."
  },
  {
    "objectID": "posts/2021-10-28-creating-a-geospatial-blog-with-blogdown/index.html#visualise",
    "href": "posts/2021-10-28-creating-a-geospatial-blog-with-blogdown/index.html#visualise",
    "title": "Creating a geospatial blog with blogdown",
    "section": "Visualise",
    "text": "Visualise\nMake sure to add a caption to visualisations, and some alternative text if needed!\n\nplot(rain)\n\n\n\n\nAverage annual rainfall in mm (1980 to 2010)"
  },
  {
    "objectID": "posts/2021-11-23-creating-a-post/index.html",
    "href": "posts/2021-11-23-creating-a-post/index.html",
    "title": "How to contribute a post",
    "section": "",
    "text": "We will be covering some basics of multiple programming skills (Git/GitHub, R, html, etcâ€¦) with the aim of empowering people to contribute to blogdown websites such as the University of Queensland Geospatial Analysis Community of practice (UQGAC) blog. The idea is to encourage community members to contribute material directly instead of funneling everything through a website administrator."
  },
  {
    "objectID": "posts/2021-11-23-creating-a-post/index.html#geospatial-analysis-community-of-practice---the-university-of-queensland-uqgac",
    "href": "posts/2021-11-23-creating-a-post/index.html#geospatial-analysis-community-of-practice---the-university-of-queensland-uqgac",
    "title": "How to contribute a post",
    "section": "Geospatial Analysis Community of Practice - The University of Queensland (UQGAC)",
    "text": "Geospatial Analysis Community of Practice - The University of Queensland (UQGAC)\nUnveil the new website!\nPoint of contact - Mitchel Rudge: mitchel.rudge@uq.edu.au\nSee the About page for more info."
  },
  {
    "objectID": "posts/2021-11-23-creating-a-post/index.html#creating-a-post-on-the-uqgac-website",
    "href": "posts/2021-11-23-creating-a-post/index.html#creating-a-post-on-the-uqgac-website",
    "title": "How to contribute a post",
    "section": "Creating a post on the UQGAC website",
    "text": "Creating a post on the UQGAC website\nCatherine Kim, PhD\nPostdoctoral Associate, School of Biological Sciences\nTechnology Trainer, UQ Library\nTwitter: @fishiintheC\nWhat we will cover:\n\nblogdown basics\nGit and GitHub basics\nHow to create a post on the UQGSAC blogdown website\nR Markdown basics\n\nI have pieced this together using many other resources on the above which are mentioned throughout. Thank you to Mitch and StÃ©phane for their help with this tutorial and workshop!\nWhat you will need:\n\nInstallations - R, RStudio, Git\nA GitHub account (free) with your login and personal access token (PAT) details handy"
  },
  {
    "objectID": "posts/2021-11-23-creating-a-post/index.html#blogdown-basics",
    "href": "posts/2021-11-23-creating-a-post/index.html#blogdown-basics",
    "title": "How to contribute a post",
    "section": "blogdown basics",
    "text": "blogdown basics\nblogdown is an R package that allows the creation of websites using R Markdown and Hugo, a static site generator. blogdown websites in R have been all the rage the last few years and you have probably seen many â€˜Hugo-Academic themeâ€™ personal websites - all built in R!\n\n\n\nblogdown hex sticker Credit: Creating Website with R Markdown\n\n\n\nThere is a short online book on blogdown written by the developer, Yihui and others.\nA recent article by Allison Hill on starting your own blogdown website from scratch.\nSee Mitch and StÃ©phaneâ€™s tutorial for UQGSAC on creating a blogdown website.\n\nThis session focuses on how to go about contributing a post to an existing website.\nThe UQGSAC website is built using the anatole theme. There are many themes to choose from and if you know html/CSS you can even build your own theme.\nSo, how do we go about contributing to a blogdown website?\n\n\n\nProgrammer GIF Credit: Capgemini India on GIPHY\n\n\nA good place to start is making sure you have installed the blogdown package:\n\ninstall.packages(\"blogdown\")\n\nArticle about setting global options in blogdown if you need to set the Hugo version in your .Rprofile (blogdown::config_Rprofile()).\nTo allow multiple people to contribute to the same website, the website is hosted on GitHub and Netlify.\nAs the website is already set-up, we will be dealing with Git + GitHub and R + RStudio + R Markdown."
  },
  {
    "objectID": "posts/2021-11-23-creating-a-post/index.html#git---what-is-it",
    "href": "posts/2021-11-23-creating-a-post/index.html#git---what-is-it",
    "title": "How to contribute a post",
    "section": "Git - what is it?",
    "text": "Git - what is it?\nA version control software (think track changes) useful for collaborating on and sharing code.\nGit is the software itself that records changes to a set of files locally. There are several hosting platforms that are like online repositories (think Dropbox, Google Drive, etc.) that work with Git: Bitbucket, GitLab, and GitHub to name a few.\nThese platforms not only allow for version control but also to collaborate, organize, and back up projects.\nIn this case, we will be using GitHub to access the website files, make some changes (i.e., add a post), and then incorporate those changes back to the website repository on GitHub which will automatically update the website itself. ðŸ™Œ\nWe will focus on contributing a post to an existing website repository on GitHub, but there are lots of fabulous and free resources online that go more into depth on Git:\n\nIf you need to be convinced to use Git for version control see this article and Happy Git and GitHub for the useR to git started both by Git/R guru Jenny Bryan.\nSee Caitie Kuempelâ€™s R Ladies Brisbane presentation on getting started with GitHub in RStudio.\n\n\nGit Terminology\nRepository/repo - where a project is stored in GitHub. Think of it like a folder holding all the relevant documents that you can version control, view history, and add collaborators. The repository or repo holds all the relevant files for the website - most of which we will not touch.\nFork - A copy of another userâ€™s repo on your account. This allows you to freely change a project without affecting the original upstream repo. You can keep your fork synced with changes in the original repo. - this is fetching upstream.\nClone - a copy of a repository that lives on your computer instead of a website server like GitHub. Is still connected to the remote repo online and you can push/pull edits.\nCommit - is one or more changes to a file or set of files that you are asking GitHub to keep track of.\nPush - sending your committed changes to a remote repository on GitHub. Local changes updated on the GitHub website where other people can access.\nPull - incorporating and merging changes. An edit on the remote repository on GitHub can be pulled to a local repository.\nDiff - difference, or changes made that are visible as insertions/deletions for a commit.\nMain/Master - the default branch you are on. Master has recently updated to main, but they are the same thing. You are more likely to come across master on older resources. Jenny Bryan strongly urges you to create a new branch to work off of which requires using command line. For the purpose of contributing to a blogdown website, I will forgo covering this as it is unlikely more than one person will be contributing at the same time.\nOrigin - the remote repo online from which you have cloned your local copy from."
  },
  {
    "objectID": "posts/2021-11-23-creating-a-post/index.html#how-to-create-a-post-in-blogdown",
    "href": "posts/2021-11-23-creating-a-post/index.html#how-to-create-a-post-in-blogdown",
    "title": "How to contribute a post",
    "section": "How to create a post in blogdown",
    "text": "How to create a post in blogdown\nStarting with Git and GitHub:\n\n1. Fork the repo\n\nSign in with your GitHub account\nGo to the geocommunity/website repo\nPress the â€˜Forkâ€™ button at the top right. \nA forked copy of the repo should now be visible in your GitHub account. YOU/blog_website is the origin for your local copy of the repo in RStudio and geocommunity/blog_website is the upstream repo.\n\n\n\n\nScreenshot of a forked repo on GitHub.\n\n\n\n\n2. Clone the repo in a new RStudio project\n\nYou will need your GitHub credentials handy.\nYou can also set up RStudio so you do not need to input your GitHub credentials every time.\n\nFrom your forked repo, click on the green â€˜Codeâ€™ button and copy the link in the pop-up window.\n\n\n\nScreenshot of finding the url to clone.\n\n\nNext, in RStudio, go to File > New Project. In the pop-up window, click the last option â€˜Version Controlâ€™ and then â€˜Gitâ€™. In the following window, paste the url you copied from your forked GitHub repo in the first box which will automatically input the name of the project.\n\n\n\nPop-up windows of cloning a GitHub repo in RStudio\n\n\nConceptually, what we have done is:\n\n\n\nConceptual diagram of forking and cloning in GitHub Credit: Happy Git for the useR\n\n\nNow that we have cloned the repository, letâ€™s explore the file structure a little in the â€˜Filesâ€™ tab in RStudio. It is NOT a very intuitively set-up even for intermediate users of R. For the purposes of creating a new post to add to the blog, we are mostly concerned with the content/english/ directory that contains the post/ sub-directory.\nThe rest of the files are the â€˜backendâ€™ of the site using html, CSS, js, etc. to build the website. Have a look if you are curious but make changes at the risk of being â€˜that personâ€™ to break the site! But donâ€™t worry, since we are using Git version control all changes are tracked and reversible.\nNow that we are somewhat familiar with the project structure, letâ€™s create a new post.\n\n\n3. Create a new post\nIn our new RStudio project housing our forked and cloned GitHub repo of the website:\nUse blogdown::new_post(\"New post name\", ext = \".Rmd\") in the console to create a new post with a .Rmd extension. Alternatively, you can go to the Addins button under the menu and choose â€˜New Postâ€™ under the BLOGDOWN section and fill in the information in the pop-up window.\n\n\n\nA new blogdown post in RStudio.\n\n\n\nThis will create a new page/post bundle folder or sub-directory within post/ with the date and the name given in new_post() function. e.g., post/2021-11-18-New-post-name.\nAn index.Rmd file has been opened and only contains a YAML header (enclosed by ---). More on that later. Do not change the name of the .Rmd file.\nEach post gets its own bundle which is where your static post-specific files like images or data (.csv files etc.) used in your post should go.\nNote that the â€œNew post nameâ€ will not only be the incorporated into the sub-directory name, but also the url to the post. Read: choose wisely and concise > long descriptive name.\nThis â€œNew post nameâ€ will automatically be filled as the â€˜Title:â€™ in the .Rmd YAML heading. If you want a longer, descriptive title - change it in the YAML heading.\nIt is recommend you use either blogdown::new_post() or the Addin to create a new post instead of manually creating a new file (File > New File > R Markdown script)\n\nHere, we will stick with the .Rmd extension, but know there are a few file types:\n.md - markdown, cannot run code chunks\n.Rmd - R markdown -> rendered to .html using Pandoc\n.Rmarkdown - also R markdown -> compiled to .markdown documents\nIf you want more of this detailed stuff see: https://bookdown.org/yihui/blogdown/output-format.html.\n\n\n4. Commit the changes i.e., the new post\nLetâ€™s commit our new post. You can add something like a line of text, or not.\n\nIf you cloned the repo properly there should be a Git tab in the upper right hand window in RStudio where the Environment is. In the Git repo, there should be some files listed (i.e., post/2021-11-23-New-post-name) with different colored boxed under the â€˜Statusâ€™ column - hover with the cursor to see what they mean.\nCheck the â€˜Stagedâ€™ box for the files you want to include in this commit.\nClick the Commit button and a window will pop-up. In the bottom section, you will see the changes made to the file as additions (green) and deletions (red) - this is known as the diff in GitHub speak. For a new file, the whole thing will be green because it is all new.\nIn the â€˜Commit messageâ€™ box, add a concise but descriptive message of the changes like â€˜Added a new post bundle.â€™ Once you are happy with everything (file staged, commit messages, etc.) click the â€˜Commitâ€™ button.\n\n\n\n\nScreenshot of a forked repo on GitHub.\n\n\nSome stuff will happen and as long as you do not see any obvious errors then it has probably all gone well and youâ€™ve made your first commit!\n\n\n\nCelebrate! Credit: http://www.reactiongifs.com/cheering-minions/\n\n\nKnowing when and how often to commit is a bit of an art that comes with experience. In general, you want to commit changes that are related to a single problem and a good commit message. There is also a History button on the top left corner that will list all the commits with messages you have made and you can view the diff by clicking on a commit. All commits have a unique code which you can use to return to a previous commit etc.\nImportant notes:\n\nOnce you have served the site (see Step 6) it will create additional files within your post bundle directory. Be sure to commit all files in the post bundle created when knitting (/index.html, /index_files, etc.) not just the index.Rmd file as they will be necessary to build the site from GitHub. - You can stage them all together as one commit.\nYou will not be able to see diffs in the commit window until they have been saved.\n\nSee more on committing and best practices from the R packages book.\n\n\n\nHow committing goesâ€¦ Credit: xkcd comics\n\n\n\n\n5. Push the changes to GitHub\nThe changes and commits we have made are local, but we need to get them onto the GitHub repo and then the website. This is where we need to push.\nIn the Git window, you will see a blue down arrow for pulling and a green up arrow for pushing. You will also see a message along the lines of Your branch is ahead of 'origin/main' by X commits under those buttons.\nFor the purposes of contributing a post to a blogdown website, we will not worry about pulls and fetching upstream. This basically means keeping your origin/master repo synced with the original upstream repo that you forked.\nIf you stick to creating a new post bundle and only modifying files within the post bundles it should be okay without fetching upstream. BUT know that if you are using GitHub to work collaboratively, staying current with the original repo is important and in general it is a good practice to always pull before you push. Recommend Happy Git and GitHub for the useR as a trusty guide.\nIf you want to try fetching upstream it is easiest to do via GitHub. Followed by a pull in RStudio.\n\nLog into your GitHub account online, and navigate to your YOU/blog_website repo.\nUnder the green Code button, there should be a Fetch upstream button that will sync your forked repo with the original upstream repo.\nThere is information about the status of your branch compared to the original upstream repo e.g., â€˜up to dateâ€™ or â€˜X commits ahead/behindâ€™ to give you an idea if you need to fetch or not.\nNow in RStudio, you should be good to pull.\nRevisiting this diagram, the fetch upstream is updating your forked repo from the original yellow repo and then the pull is updating your local repo from your forked repo.\n\n\n\n\nDiagram of fetching upstream and pulling Credit: modified from Happy Git for the useR\n\n\nNow we will push our commits from or local repo to our remote origin/master repo on GitHub.\nIf this is your first time using Git with RStudio, you will have to set-up a personal access token or PAT in GitHub. For detailed directions, go to the GitHub page.\n\nGo to your GitHub account online and click on your profile photo in the upper-right and go to Settings.\nIn the left sidebar, click on Developer settings then Personal Access Tokens.\nClick the Generate a new token button and give a descriptive name and expiration.\nSelect scopes or privacy settings (defaults are generally fine) and the generate the token.\nCopy your PAT and put it in the password field for any pop-ups asking for your GitHub credentials when you push.\n\nIf you see HEAD -> main then all good.\n\n\n\nScreenshot of push window in RStudio.\n\n\nNow if you go back to your GitHub account and forked repo online, you should see the changes you made locally are now in the remote online repo and your commit message.\n\n\n\nScreenshot of pushed changes on forked GitHub repo.\n\n\nIn general, you should commit often and then push.\n\n\n6. Serve the site\nIn the console, run blogdown::serve_site(). Alternatively, can click on RStudio â€˜Addinsâ€™ and select â€˜Serve Siteâ€™. Be patient, but what happens?\n\n\n\nScreenshot of served site in RStudio.\n\n\nSome important information on what is going on from blogdown: Creating Websites with R Markdown:\n\nServing the site did the following: 1. Started a local Hugo server to help you preview your website, and 2. Knitted a sample .Rmd post to an .html page. You can see this from the progress message that printed to your console: Rendering content/english/post/2021-11-23-creating-a-post/index.Rmd... Done\n\nYou can also view the locally served website in a browser by clicking on the â€œShow in new windowâ€ button at the top left of the RStudio Viewer pane to the right of the broom.\nServing the site is using something called LiveReload:\n\nLetâ€™s introduce an important and helpful technology that you just used: LiveReload. Serving your site uses LiveReload, which means your website will be automatically rebuilt and reloaded in your web browser when you modify any source file of your website and save it. Basically, once you launch the website in a web browser, you do not need to rebuild it explicitly anymore. All you need to do is edit the source files, such as R Markdown documents, and save them. There is no need to click any buttons or run any commands. LiveReload is implemented via blogdown::serve_site() and Hugo, and you will only need to use it once per work session.\n\nRemember, every time you save your .Rmd file will activate the LiveReload. To stop serving the site locally run blogdown::stop_server() in the console.\n\n\n7. Create your content\nOnce the website is set-up, forked, and clonedâ€¦ you can get on with creating a new post with minimal coding. The main thing you will need to use is:\n\nR Markdown\nThis is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML documents that we can incorporate into the website. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nWhen you click the Knit button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. For a website post, knitting is not as important because we can serve our site locally which automatically knits anything new and view the changes as we just learned ðŸ‘†.\nNow letâ€™s add some information about R Markdown:\n\nYAML header\nThe YAML, or Yet Another Markdown Language, header at the top of the .Rmd is set between --- tags. Here is where information like the Title, Date, Author of the document go and will appear in the post.\nHave a look at previous posts and add any relevant tags or categories as you like.\nThe default .Rmd has some redundant settings (tags vs Tags) so if you use them stick with the lower case settings.\n\n\nFormatting\nCan bold and italicize text.\nHeadings:\nCan specify headings using # marks. The number of has symbols corresponds to the level of the header (2 hashs = level 2 header)\nThis will also create a structure outline of your document you can navigate either by using the â€˜Formattingâ€™ button at the bottom of the .Rmd or the right most button in the top right of the .Rmd.\n\n\n\nScreenshot of buttons to view document outline\n\n\nMake lists:\n\none\ntwo\nthree\n\nfull indent for sub-bullet\n\n\nOrdered lists:\n\nlists\nneed spaces\nbefore and after\n\nFor a return to start a new line, leave two spaces at the end of the line.\nLike this.\n\n\nIncluding code\nYou can embed an R code chunk like this:\n\nsummary(cars)\n\n     speed           dist       \n Min.   : 4.0   Min.   :  2.00  \n 1st Qu.:12.0   1st Qu.: 26.00  \n Median :15.0   Median : 36.00  \n Mean   :15.4   Mean   : 42.98  \n 3rd Qu.:19.0   3rd Qu.: 56.00  \n Max.   :25.0   Max.   :120.00  \n\n\nThere is also inline code: The mean of speed in the cars data set is 15.4.\n\n\nInclude mathematical notation\nMathematical notation can be enabled using third party JavaScript libraries like KaTeX. See resource of supported TeX functions. For these to render correctly you must add math: true to the YAML header at the top of the .Rmd.\nTo enter equations like a code chunk or block math, use two $ on separate lines surrounding your equations.\nPut two \\ after a line for a full return.\n\\[\ny = mx + \\beta\\\\\nE = mc^2\n\\]\n\\[ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } \\] You can also use inline math notation by sandwiching it between $ without spaces. Like so \\(\\mu = 0.2566\\).\nAnother inline way: (= = 1.6180339887â€¦)\n\n\nIncluding Plots\nYou can also embed plots, for example:\n\n\n\n\n\n\n\nChunk options\nChunks are the gray areas in the .Rmd file where you can add code that will be run. These are defined by three back ticks (not a single quote, the key to the left of the 1). You can insert R code chunks but also in other languages! See the green â€˜Insertâ€™ code chunk button to see different options. An R code chunk will have the an {r  } after the opening back ticks.\nThe keyboard short cut to add an R code chunk is Ctrl + Alt + I\nYou can also set options in the {} of a chunk like hide the code chunk (echo = FALSE), suppress warnings (warnings = FALSE), and cache the chunk (cache = TRUE) if you have something that takes a while to run.\nLetâ€™s set echo = FALSE for our plot chunk above. We are only interested in seeing the plot, not the code that produces the plot.\nYou can add a code chunk at the beginning of the .Rmd file and set global options that will apply to the whole document.\n\nknitr::opts_chunk$set(echo = TRUE)\n\nSee more at:\n\nRStudio - https://rmarkdown.rstudio.com/lesson-3.html\nR Markdown Cookbook - https://bookdown.org/yihui/rmarkdown-cookbook/\n\nIt is also a good idea to name your chunks as chunks are included in the document outline. Chunks cannot have the same name - you will get an error.\n\n\nInsert objects\nYou can add pictures, weblinks, and GIFs in R Markdown. They all follow the similar hyperlink formats.\nFor a hyperlink to a website you put the word you want to hyperlink in square brackets [] followed immediately (no spaces or characters) by round parentheses (). E.g. [GitHub](www.github.com)\nTo insert an image or gif from a website you add a ! before the square brackets like so: ![description](https://media.giphy.com/media/sJWNLTclcvVmw/giphy.gif). The description in the [] will appear as a caption and the link must end in the appropriate file extension (.gif, .jpg, .png, etc) to work.\n\n\n\nFunny Yawn Credit: https://www.reddit.com/r/gifs/comments/54q75s/goodnight_tongue/\n\n\nYou can also insert pictures using the RStudio â€˜Addinsâ€™ > â€˜Insert Imageâ€™ and uploading an image saved on your computer with a few other options like alt text. This will result in the same hyperlink code as inserting an image, but with a relative path instead of the url.\nExample use Addin to insert image\nYou can also save files (like images, html presentations) in your post bundle to link using relative paths on your own.\n\n\n\n\n7. Pull Request\nOkay, so as you were creating the content of your post you should have been committing regularly and then pushing, right?\nLetâ€™s say we are finished with our beautiful post and read to incorporate it into the original upstream repo geocommunity/blog_website that we forked from. Remember, when we push we are pushing the commits we made locally on our computer to our YOU/blog_website repo that we forked from the original repo.\nBecause we are not owner/developers of the upstream geocommunity/blog_website repo we need to submit a pull request to submit our new blog post for approval into the upstream repo.\n\nOn your YOU/blog_website repo in your GitHub account, click on Pull requests.\nOn the right of the screen, there should be a green New pull request button. This will take to you a â€˜Comparing changesâ€™ window outlining the files and changes you have made. This will alert you to any merge conflicts with the original upstream repo. Again, sticking to creating a new post bundle/content should avoid any merge conflicts.\nClick the green Create pull request button on the right. This will take you to a â€˜Open a pull requestâ€™ window that will have your last commit and space to add a larger message with your pull request or PR.\nOnce you are happy, click the green button at the end and wait for approval. You can have a bit of a conversation to hash out any issues as well over the approval process.\n\n\n\n\nScreenshot of GitHub open a pull request.\n\n\nCongratulations - now you have submitted your blog post to a blogdown site!\n\n\n\nCheers Credit: Sony"
  },
  {
    "objectID": "posts/2021-11-23-creating-a-post/index.html#troubleshooting",
    "href": "posts/2021-11-23-creating-a-post/index.html#troubleshooting",
    "title": "How to contribute a post",
    "section": "Troubleshootingâ€¦",
    "text": "Troubleshootingâ€¦\nLetâ€™s face it, the likelihood of something going awry following this tutorial is not 0â€¦ Few things that might help along the way:\n\nSometimes it is difficult to tell when the â€˜LiveReloadâ€™ has finished or if you are used to saving regularly every few minutes that constant updating of â€˜LiveReloadâ€™ can freeze RStudio.\n\nSolution: The good â€™ole Restart R (Session > Restart R) or close and re-open.\n\nFormatting wise, itâ€™s a good idea to put full line returns before/after formatting bits like lists and inserting images. Something to check if your content is not formatting as you expect.\nOTHERS??"
  },
  {
    "objectID": "posts/2021-11-23-creating-a-post/index.html#resources-mentioned",
    "href": "posts/2021-11-23-creating-a-post/index.html#resources-mentioned",
    "title": "How to contribute a post",
    "section": "Resources mentioned:",
    "text": "Resources mentioned:\n\nCreating Websites with R Markdown by Yihui Xi, Amber Thomas, and Alison Presmanes Hill.\nâ€œUp & running with blogdown in 2021â€ Alison Hill.\nâ€œCreating a Geospatial Blog with blogdownâ€ on the UQGSAC blog by Mitch Rudge and StÃ©phane Guillou.\nExcuse me, do you have a moment to talk about version control? by Jenny Bryan\nHappy Git and GitHub for the useR by Jenny Bryan.\nGetting Started with GitHub R Ladies Brisbane presentation by Caitie Kuemple.\ngeocommunity/website GitHub repo\n18.6 Commit best practices from the R packages book by Hadley Wickham and Jenny Bryan.\nR Markdown\nKaTeX - Supported Functions\nCode Chuncks\nR Markdown Cookbook by Yihui Xie, Christophe Dervieux, Emily Riederer."
  },
  {
    "objectID": "posts/2022-09-09-newsletter/index.html",
    "href": "posts/2022-09-09-newsletter/index.html",
    "title": "Newsletter | Climate data blog post + problem solving session + conference in Fiji + more",
    "section": "",
    "text": "Last Thursday Ralph ran us through the basics of climate analysis in R. This was a really informative workshop that demystified climate data. All the scripts are now up on the blog, as well as a link to the materials. If you missed the workshop, the recording is up on cloudstor (let me know if you donâ€™t have access).\n\n\n\nOur next workshop will be a free-range problem-solving session. So, if you have any questions or issues you think someone in the community could help with, please bring them along.\n\n\n\nYou heard right! The Pacific Geospatial Conference will be held in Suva, Fiji from the 28th of November till 2nd December. Here is the Conference Program. By all reports this is an excellent conference that would be interesting to members of this community.\n\n\n\nThe UQ library will be hosting a QGIS: Custom Maps on your Phone workshop on Thursday 22 September 2022, 9.30am - 11.30am.\nThis session is split into two main sections. First it will cover useful spatial data portals (freely accessing aerial photography, government spatial data, quality digital elevation models, and more), and then it will cover how to package this data for use in the field on a mobile phone.\n\n\n\nResearch Fellow â€“ Remote sensing riparian vegetation, CDU, Darwin\nTeam Leader Conservation Planner / GIS analyst, Centre for Conservation Geography, Byron Bay\nGIS Analyst / Senior GIS Analyst, Ecology Australia, Melbourne\nGraduate GIS Analyst, Biosis, Melbourne"
  },
  {
    "objectID": "posts/2022-09-01-analysing-climate-data-with-r/index.html",
    "href": "posts/2022-09-01-analysing-climate-data-with-r/index.html",
    "title": "Analysing Climate data with R",
    "section": "",
    "text": "This post contains the scripts provided by Ralph Trancoso in the Analysing Climate Data in R workshop. The recording is also available, just email mitchel.rudge@uq.edu.au for access.\n\n1 Installing and loading the data, and the raster, ncdf4, rgdal, and ggplot2 packages, setting directory, loading gridded data\nTo follow this tutorial, you will need to download some prepared climate data.\nSave this link to somewhere on you computer, in our example the c drive, the unzip the folder.\nIf you donâ€™t have the â€˜rasterâ€™ and ncdf4 packages installed, install them:\n\ninstall.packages(\"raster\") # Installing the packages required for the workshop\ninstall.packages(\"ncdf4\")\ninstall.packages(\"rgdal\")\ninstall.packages(\"ggplot2\")\n\nNow load the raster package, and set the directory to where you stored the Rclim folder.\nSet your home directory, for example, if you put the rclim folder on you C drive:\nwriteClipboard(gsub(â€œ\\\\â€, â€œ/â€, readClipboard())\n\nhome <- \"C:/Rclim\"\n\nNow load the raster packages, and set your directory to where the climate data is.\n\nlibrary(raster)\nsetwd(home) #workshop dataset\n\nsetwd(paste0(home, \"/worldclim\")) # Set work directory to worldclim data\n#getwd() # get work directory\n#dir() # list files in the work directory\n?stack # what does stack do?\naus_temp <- stack(\"tmean_australia_wc.nc\")  # Loading gridded #data as RasterStack\n\n\n\n2 Querying the RasterStack data and quick plot using raster::plot and raster::spplot\nBelow are a whole bunch of checks that you can run on the raster data set.\n\nncol(aus_temp) #check the number of columns\n\n[1] 554\n\nnrow(aus_temp) #check the number of rows\n\n[1] 551\n\nncell(aus_temp) #check the number of cells\n\n[1] 305254\n\nnlayers(aus_temp) #check the number of layers\n\n[1] 12\n\ndim(aus_temp) #check the dimensions (rows, columns, layers)\n\n[1] 551 554  12\n\nprojection(aus_temp) #check the projection\n\n[1] \"+proj=longlat +datum=WGS84 +no_defs\"\n\nres(aus_temp) #check the resolution\n\n[1] 0.08333333 0.08333333\n\ninMemory(aus_temp) #check if the data is stored in memory\n\n[1] FALSE\n\nfromDisk(aus_temp) #check if the data was read from disk\n\n[1] TRUE\n\nnames(aus_temp) #check the names of the layers\n\n [1] \"X1\"  \"X2\"  \"X3\"  \"X4\"  \"X5\"  \"X6\"  \"X7\"  \"X8\"  \"X9\"  \"X10\" \"X11\" \"X12\"\n\n\nNow plot the rasters using the plot function:\n\nplot(aus_temp/10)\n\n\n\n\nOr use spplot:\n\nspplot(aus_temp/10) # lattice plot, returns a trellice \n\n\n\n\nEach layer represents a month of the year, from 1-12. So lets rename the layers and plot again.\n\nmonths <- c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\",\n            \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\")\n\nnames(aus_temp) <- months #set the layer names to months\n\nplot(aus_temp/10)\n\n\n\n\nOr, using spplot to create a lattice plot\n\nspplot(aus_temp/10) # lattice plot, returns a trellice  \n\n\n\n\n\n\n3 Calculating anomalies as gridded time-series and global average\nFirst, load the CMIP6 data set.\n\nsetwd(paste0(home, \"/CMIP6\")) # Set work directory to CMIP6 data\nproj_temp <- stack(\"tas_Asea_ACCESS-ESM1-5_ssp370_r1i1p1f1_gr1.5_1950-2100.nc\")\nnames(proj_temp)\n\n  [1] \"X1\"   \"X2\"   \"X3\"   \"X4\"   \"X5\"   \"X6\"   \"X7\"   \"X8\"   \"X9\"   \"X10\" \n [11] \"X11\"  \"X12\"  \"X13\"  \"X14\"  \"X15\"  \"X16\"  \"X17\"  \"X18\"  \"X19\"  \"X20\" \n [21] \"X21\"  \"X22\"  \"X23\"  \"X24\"  \"X25\"  \"X26\"  \"X27\"  \"X28\"  \"X29\"  \"X30\" \n [31] \"X31\"  \"X32\"  \"X33\"  \"X34\"  \"X35\"  \"X36\"  \"X37\"  \"X38\"  \"X39\"  \"X40\" \n [41] \"X41\"  \"X42\"  \"X43\"  \"X44\"  \"X45\"  \"X46\"  \"X47\"  \"X48\"  \"X49\"  \"X50\" \n [51] \"X51\"  \"X52\"  \"X53\"  \"X54\"  \"X55\"  \"X56\"  \"X57\"  \"X58\"  \"X59\"  \"X60\" \n [61] \"X61\"  \"X62\"  \"X63\"  \"X64\"  \"X65\"  \"X66\"  \"X67\"  \"X68\"  \"X69\"  \"X70\" \n [71] \"X71\"  \"X72\"  \"X73\"  \"X74\"  \"X75\"  \"X76\"  \"X77\"  \"X78\"  \"X79\"  \"X80\" \n [81] \"X81\"  \"X82\"  \"X83\"  \"X84\"  \"X85\"  \"X86\"  \"X87\"  \"X88\"  \"X89\"  \"X90\" \n [91] \"X91\"  \"X92\"  \"X93\"  \"X94\"  \"X95\"  \"X96\"  \"X97\"  \"X98\"  \"X99\"  \"X100\"\n[101] \"X101\" \"X102\" \"X103\" \"X104\" \"X105\" \"X106\" \"X107\" \"X108\" \"X109\" \"X110\"\n[111] \"X111\" \"X112\" \"X113\" \"X114\" \"X115\" \"X116\" \"X117\" \"X118\" \"X119\" \"X120\"\n[121] \"X121\" \"X122\" \"X123\" \"X124\" \"X125\" \"X126\" \"X127\" \"X128\" \"X129\" \"X130\"\n[131] \"X131\" \"X132\" \"X133\" \"X134\" \"X135\" \"X136\" \"X137\" \"X138\" \"X139\" \"X140\"\n[141] \"X141\" \"X142\" \"X143\" \"X144\" \"X145\" \"X146\" \"X147\" \"X148\" \"X149\" \"X150\"\n[151] \"X151\"\n\n\nWe can see that these names make no sense. So the names relate to years, we can re-name each layer:\n\nyears <- seq(1950, 2100, by=1)\nnames(proj_temp ) <- years\nnames(proj_temp)\n\n  [1] \"X1950\" \"X1951\" \"X1952\" \"X1953\" \"X1954\" \"X1955\" \"X1956\" \"X1957\" \"X1958\"\n [10] \"X1959\" \"X1960\" \"X1961\" \"X1962\" \"X1963\" \"X1964\" \"X1965\" \"X1966\" \"X1967\"\n [19] \"X1968\" \"X1969\" \"X1970\" \"X1971\" \"X1972\" \"X1973\" \"X1974\" \"X1975\" \"X1976\"\n [28] \"X1977\" \"X1978\" \"X1979\" \"X1980\" \"X1981\" \"X1982\" \"X1983\" \"X1984\" \"X1985\"\n [37] \"X1986\" \"X1987\" \"X1988\" \"X1989\" \"X1990\" \"X1991\" \"X1992\" \"X1993\" \"X1994\"\n [46] \"X1995\" \"X1996\" \"X1997\" \"X1998\" \"X1999\" \"X2000\" \"X2001\" \"X2002\" \"X2003\"\n [55] \"X2004\" \"X2005\" \"X2006\" \"X2007\" \"X2008\" \"X2009\" \"X2010\" \"X2011\" \"X2012\"\n [64] \"X2013\" \"X2014\" \"X2015\" \"X2016\" \"X2017\" \"X2018\" \"X2019\" \"X2020\" \"X2021\"\n [73] \"X2022\" \"X2023\" \"X2024\" \"X2025\" \"X2026\" \"X2027\" \"X2028\" \"X2029\" \"X2030\"\n [82] \"X2031\" \"X2032\" \"X2033\" \"X2034\" \"X2035\" \"X2036\" \"X2037\" \"X2038\" \"X2039\"\n [91] \"X2040\" \"X2041\" \"X2042\" \"X2043\" \"X2044\" \"X2045\" \"X2046\" \"X2047\" \"X2048\"\n[100] \"X2049\" \"X2050\" \"X2051\" \"X2052\" \"X2053\" \"X2054\" \"X2055\" \"X2056\" \"X2057\"\n[109] \"X2058\" \"X2059\" \"X2060\" \"X2061\" \"X2062\" \"X2063\" \"X2064\" \"X2065\" \"X2066\"\n[118] \"X2067\" \"X2068\" \"X2069\" \"X2070\" \"X2071\" \"X2072\" \"X2073\" \"X2074\" \"X2075\"\n[127] \"X2076\" \"X2077\" \"X2078\" \"X2079\" \"X2080\" \"X2081\" \"X2082\" \"X2083\" \"X2084\"\n[136] \"X2085\" \"X2086\" \"X2087\" \"X2088\" \"X2089\" \"X2090\" \"X2091\" \"X2092\" \"X2093\"\n[145] \"X2094\" \"X2095\" \"X2096\" \"X2097\" \"X2098\" \"X2099\" \"X2100\"\n\n\nThe X is at the start of each of each year to ensure they are of type character.\nNow we can create a simple function to calculate the temperature anomaly.\n\nanomaly <- function(x) {\n    anom <-  x - mean(x[[32:61]]) # for reference period 1981-2100\n    names(anom) <- seq(1950, 2100, by=1)    \n    return(anom)\n}\n\n\nT_anom <- anomaly(proj_temp)\n\nNow plot the temperature anomaly, from 1:16 (1950 - 1965)\n\nspplot(T_anom[[1:16]])\n\n\n\n\nAnd from 2084 - 2100\n\nspplot(T_anom[[135:151]])\n\n\n\n\nThen we can calculate the average temperature anomaly\n\nT_anom_mean <- as.data.frame(cbind(years, cellStats(T_anom, mean)))\nnames(T_anom_mean) <- c(\"year\", \"T_anom_mean\")\n\nFinally, we can take a look at the average temperature anomaloy for the entire dataset.\n\nsetwd(home) # Set work directory to main folder\ndir.create(\"output\")\nsetwd(paste0(home, \"/output\")) #set directory to output\njpeg(file=\"anomaly_ts.jpeg\", height = 600,  width = 1000, res=150)\nplot(T_anom_mean$year, T_anom_mean$T_anom_mean, type = \"p\", pch = 19, \n     col = \"red\", xlab=\"year\", ylab=\"Projected temperature anomaly\", \n     main=\"ACCESS-ESM1-5 SSP370 - ref period:1981-2010\")\ndev.off()\n\npng \n  2 \n\n\nHave a look in the output folder, you should see something like this\n\n\n\n4 Handling regions as shapefiles\nHere, we load and plot a shapefile of the worlds country boundaries.\nHere, we load and plot a shapefile of the worlds country boundaries.\n\nlibrary(rgdal)\n\nsetwd(paste0(home, \"/shp\"))\ncountries = readOGR(dsn=\".\", layer=\"TM_WORLD_BORDERS_SIMPL-0.3\")\n\nOGR data source with driver: ESRI Shapefile \nSource: \"C:\\Users\\uqnwiggi\\OneDrive - The University of Queensland\\UQGAC\\Rclim\\shp\", layer: \"TM_WORLD_BORDERS_SIMPL-0.3\"\nwith 246 features\nIt has 11 fields\nInteger64 fields read as strings:  POP2005 \n\nplot(countries)\n\n\n\n\nOr use spplot to color by population:\n\nspplot(countries, \"POP2005\")\n\n\n\n\n\n\n5 Regionalizations of climate data - plotting time-series as line plot and bar chart\n\nlibrary(ggplot2)\n\nsetwd(paste0(home, \"/CMIP6\")) # Set work directory to CMIP6 data\nproj_temp <- stack(\"tas_Asea_ACCESS-ESM1-5_ssp370_r1i1p1f1_gr1.5_1950-2100.nc\")\nproj_temp <- proj_temp -273.15\nnames(proj_temp) <- c(seq(1950,2100, by=1))\n\n## From your countries vector we read in, select a country customise your study area for the workshop analysis:\nmy_country <- subset(countries, NAME == \"Australia\")\n\n\ndf<- as.data.frame(countries@data)\n#fix(df) # to have a look at the dataframe of the countries\n\nmydf <- structure(list(\nlongitude = c(153.0251, 145.7781, 149.1821, 146.8169, 139.4927, 144.2555), \nlatitude = c(-27.4698, -16.9186, -21.1425, -19.2590, -20.7256, -23.4422)), \n.Names = c(\"longitude\", \"latitude\"), class = \"data.frame\", row.names = c(NA, -6L))\nxy <- mydf[,c(1,2)]\nspdf <- SpatialPointsDataFrame(coords = xy, data = mydf, proj4string = CRS(\"+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0\"))\n\nFinally, plot the points we chose on the map of Australia.\n\nplot(my_country)\nplot(spdf, add=T, col=\"red\")\n\n\n\n\n\nproj_temp_cities <- extract(proj_temp, spdf)\nproj_temp_cities <- as.data.frame(proj_temp_cities)\nproj_temp_cities <-as.data.frame(t(proj_temp_cities))\nproj_temp_cities$year <- 1:nrow(proj_temp_cities)+1980\nnames(proj_temp_cities) <- c(\"Brisbane\", \"Cairns\", \"Mackay\", \"Townsville\", \"Mount_Isa\", \"Longreach\", \"year\")\n\nWe can plot the projected temperature change of the cities we have selected.\nWe can plot the projected temperature change of the cities we have selected.\n\n#install.packages(\"reshape2\")\nlibrary(reshape2)\nproj_temp_cities_melt <- melt(proj_temp_cities, id=\"year\")\n\nts1 <- ggplot(proj_temp_cities_melt) +\n    geom_line(aes(x=year, y=value, colour=variable)) +\n    ggtitle(\"Projected average temperature ACCESS-ESM1.5 SSP3-7.0\") +\n    ylab(\"Temperature (Â°C)\")  +\n    scale_color_brewer(name= \"cities\", palette=\"Set1\") +\n    theme_bw() \nts1\n\n\n\n\n\n\n6 Convertig gridcells to data frame within a study area mask and plotting boxplots in ggplot2\n\nsetwd(paste0(home, \"/IPCC\")) # Set work directory to CMIP6 data\ndir() \n\n [1] \"CMIP6 - Consecutive Dry Days (CDD) Change days - Warming 1.5Â°C SSP5-8.5 (rel. to 1850-1900) - Annual (32 models).nc\"\n [2] \"CMIP6 - Consecutive Dry Days (CDD) Change days - Warming 2Â°C SSP5-8.5 (rel. to 1850-1900) - Annual (32 models).nc\"  \n [3] \"CMIP6 - Consecutive Dry Days (CDD) Change days - Warming 3Â°C SSP5-8.5 (rel. to 1850-1900) - Annual (32 models).nc\"  \n [4] \"CMIP6 - Consecutive Dry Days (CDD) Change days - Warming 4Â°C SSP5-8.5 (rel. to 1850-1900) - Annual (19 models).nc\"  \n [5] \"CMIP6 - Maximum temperature (TX) Change deg C - Warming 1.5Â°C SSP5-8.5 (rel. to 1850-1900) - Annual (27 models).nc\" \n [6] \"CMIP6 - Maximum temperature (TX) Change deg C - Warming 2Â°C SSP5-8.5 (rel. to 1850-1900) - Annual (27 models).nc\"   \n [7] \"CMIP6 - Maximum temperature (TX) Change deg C - Warming 3Â°C SSP5-8.5 (rel. to 1850-1900) - Annual (27 models).nc\"   \n [8] \"CMIP6 - Maximum temperature (TX) Change deg C - Warming 4Â°C SSP5-8.5 (rel. to 1850-1900) - Annual (16 models).nc\"   \n [9] \"CMIP6 - Mean temperature (T) Change deg C - Warming 1.5Â°C SSP5-8.5 (rel. to 1850-1900) - Annual (34 models).nc\"     \n[10] \"CMIP6 - Mean temperature (T) Change deg C - Warming 2Â°C SSP5-8.5 (rel. to 1850-1900) - Annual (34 models).nc\"       \n[11] \"CMIP6 - Mean temperature (T) Change deg C - Warming 3Â°C SSP5-8.5 (rel. to 1850-1900) - Annual (34 models).nc\"       \n[12] \"CMIP6 - Mean temperature (T) Change deg C - Warming 4Â°C SSP5-8.5 (rel. to 1850-1900) - Annual (20 models).nc\"       \n[13] \"CMIP6 - Total precipitation (PR) Change % - Warming 1.5Â°C SSP5-8.5 (rel. to 1850-1900) - Annual (33 models).nc\"     \n[14] \"CMIP6 - Total precipitation (PR) Change % - Warming 2Â°C SSP5-8.5 (rel. to 1850-1900) - Annual (33 models).nc\"       \n[15] \"CMIP6 - Total precipitation (PR) Change % - Warming 3Â°C SSP5-8.5 (rel. to 1850-1900) - Annual (33 models).nc\"       \n[16] \"CMIP6 - Total precipitation (PR) Change % - Warming 4Â°C SSP5-8.5 (rel. to 1850-1900) - Annual (19 models).nc\"       \n\n# Mean temperature\ntemp_list <- list.files(path= paste0(home, \"/IPCC\"), pattern = \"Mean temperature\", full.names = TRUE)\ntemp_GW <- stack(temp_list)\nnames(temp_GW) <- c(\"GW1.5\", \"GW2.0\", \"GW3.0\", \"GW4.0\") \nplot(temp_GW)\n\n\n\n\n\n#masking data outside country and converting grid to dataframe\n\ntemp_GW_country <- as.data.frame(mask(temp_GW, my_country))\ndim(temp_GW_country)\n\n[1] 64800     4\n\nhead(temp_GW_country)   \n\n  GW1.5 GW2.0 GW3.0 GW4.0\n1    NA    NA    NA    NA\n2    NA    NA    NA    NA\n3    NA    NA    NA    NA\n4    NA    NA    NA    NA\n5    NA    NA    NA    NA\n6    NA    NA    NA    NA\n\ntemp_GW_country <- na.omit(temp_GW_country)\ndim(temp_GW_country)\n\n[1] 699   4\n\n#install.packages(\"reshape2\")\nlibrary(reshape2)\ntemp_GW_country_m <- melt(temp_GW_country)\n\nNo id variables; using all as measure variables\n\n#creating a boxplot of avg temp per global warming level on ggplot2\n\nbp1 <- ggplot(temp_GW_country_m, aes(x=variable, y=value, fill=variable)) +\ngeom_boxplot()+\nxlab(\"Global warming level (Â°C)\")+\nylab(\"Change in average surface temperature (Â°C)\")+\nggtitle(paste(\"Change in average surface temperature per global warming level in \", my_country@data$NAME[1], sep=\"\")) +\ntheme_bw()\n\nbp1 <- bp1 + scale_color_brewer(name= \"GW level\", palette=\"YlOrRd\") # why it does not work? - change from color to fill\nbp1\n\n\n\n\n\n\n7 Repeat the extraction and plot for precipitation and/or other metrics\n\n# Total precipitation\nprec_list <- list.files(path= paste0(home, \"/IPCC\"), pattern = \"Total precipitation\", full.names = TRUE)\nprec_GW <- stack(prec_list)\nnames(prec_GW) <- c(\"GW1.5\", \"GW2.0\", \"GW3.0\", \"GW4.0\") \nplot(prec_GW)\n\n\n\n\n\n#masking data outside country and converting grid to dataframe\n\nprec_GW_country <- as.data.frame(mask(prec_GW, my_country))\nprec_GW_GW_country <- na.omit(prec_GW_country)\nprec_GW_country_m <- melt(prec_GW_country)\n\nNo id variables; using all as measure variables\n\n#creating a boxplot of precipitation per global warming level on ggplot2\n\nbp2 <- ggplot(prec_GW_country_m, aes(x=variable, y=value, fill=variable)) +\ngeom_boxplot()+\nxlab(\"Global warming level (Â°C)\")+\nylab(\"Change in total precipitation (%)\")+\nggtitle(paste(\"Change in total precipitation per global warming level in \", my_country@data$NAME[1], sep=\"\")) +\ntheme_bw() +\nscale_fill_brewer(name= \"GW level\", palette=\"YlOrRd\")\nbp2\n\nWarning: Removed 256404 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\n\n\nWhere to find climate data\nIPCC interactive atlas The authority for climate data is the IPCC. And the interactive atlas has the latest data https://interactive-atlas.ipcc.ch/regional-information\nWorldclim Global climate and weather data. WorldClim is a database of high spatial resolution global weather and climate data. https://www.worldclim.org/\nSILO gridded data for Australia until yesterday: https://longpaddock.qld.gov.au/silo/gridded-data/\nLongPaddock Provided by the Queensland Government, gridded data available for a range of variables in NetCDF and GeoTiff formats. The NetCDF datasets are arranged in annual blocks where each file contains all of the grids for the selected year and variable. https://longpaddock.qld.gov.au\nCMIP5 downscaled climate projections over Queensland High-resolution climate change projections for Queensland using dynamical downscaling of CMIP5 global climate models are available for download in gridded format with spatial resolution of 10 km at Terrestrial Ecosystem Research Network (TERN) https://longpaddock.qld.gov.au/qld-future-climate/data-info/tern/\n\n\nAbout the author\n\n \nRalph is a research scientist with expertise in climate change, ecohydrology, and deforestation impacts. Ralph is particularly interested in how climate and landscape changes affect the environment and impact society. He is a Principal Climate Change Scientist at the Department of Environment and Science (Queensland Government) and a Research Fellow at the School of Biological Sciences (University of Queensland)."
  },
  {
    "objectID": "posts/2022-04-28-cloud-computing-with-open-data-cube-and-python/index.html",
    "href": "posts/2022-04-28-cloud-computing-with-open-data-cube-and-python/index.html",
    "title": "Cloud computing with Open Data Cube and Python",
    "section": "",
    "text": "This workshop broadly covered remote sensing data analysis using the Open Data Cube (ODC), developed by Geoscience Australia. We went over some important Python packages that the ODC is built upon: Numpy, Xarray, and Dask, and explored how they enable fast and scalable computation.\nAll the learning material used in this tutorial is available on the Digital Earth Australia Sandbox as Jupyter Notebooks. An account was required to participate, which can easily be created here.\nAdditional documentation for the DEA Sandbox is available here which includes useful guides, a dataset catalogue and examples.\nIf you missed the demonstration, the recording is available on our cloudstor site, email mitchel.rudge@uq.edu.au to get access.\n\nAbout the presenter\nThe workshop was be presented by Tim Devereux.\n\n\n\n \n\nTim is a PhD candidate with the UQ Remote Sensing Research Centre (RSRC), and has a background in Environmental and Computational Sciences. His research is focused on the development of high fidelity digital representations of Australian forests for next generation simulations. He is also a demonstrator for the SEES advanced remote sensing course at UQ."
  },
  {
    "objectID": "posts/2022-05-26-problem-solving-session/index.html",
    "href": "posts/2022-05-26-problem-solving-session/index.html",
    "title": "Problem Solving Session I",
    "section": "",
    "text": "We did something different for May: a problem solving session!\n\nHere, people emailed in some questions which we went through and discussed in the workshop.\nIt seemed to go pretty well, so we will probably use this format from time to time.\nBelow, we have the two main questions that were discussed, attempted solutions"
  },
  {
    "objectID": "posts/2022-05-26-problem-solving-session/index.html#question-1---rasterizing-field-size-information-per-farm.",
    "href": "posts/2022-05-26-problem-solving-session/index.html#question-1---rasterizing-field-size-information-per-farm.",
    "title": "Problem Solving Session I",
    "section": "Question 1 - Rasterizing field size information per farm.",
    "text": "Question 1 - Rasterizing field size information per farm.\n\nThe question.\nI have a geospatial problem to crop field mapping.I am using household survey data that includes a section on crop fields, their location, their area, use, distance to homestead and other things. An example for one country, Ethiopia, is here.\nFor privacy reasons I cannot get the GPS coordinates of each crop field although this data was collected. The household GPS locations are easier to access.\nI try to think through a process of calculating field size per raster grid cell that intersects with a circle around a household that is defined by the maximum field-homestead distance. I know that all the fields have to be within that circle and I know the mean field size and the distribution of field sizes within that circle. I was thinking to just assume that every grid cell in the circle has the mean field size of that circle with an error range based on the field size distribution. But there are also overlaps between circles and I donâ€™t just want to calculate averages in this case.\nDo you know of a similar geospatial problem that someone has solved already that I could look into to get some ideas? From another field outside agriculture even?\n\n\n\nCreate some dummy data\nIn this problem, we have point data (the households), with attributes related to the crop fields that are associated with that household, such as their area, use and distance to homestead. One of those attributes, maximum distance of field to homestead, was used to generate the buffers (red circles). But because maximum distance doesnâ€™t perfectly capture the distance of fields to homesteads, they overlap. This complicates the process of rasterising the buffers.\nTo explore our options, we will use the Terra R package.\nFirst, we will create some dummy data.\n\nlibrary(terra)\n\nterra 1.7.18\n\nr <- rast(ncols=10, nrows=10, xmin = 1, xmax = 1.1, ymin = 1, ymax = 1.1)\nvalues(r) <- sample(1:ncell(r), ncell(r))\n\nThen create some random points within our dummy raster (r). These represent the household locations.\n\nsamp <- spatSample(r, 25, as.points=TRUE, method = \"random\")\nwidths <- sample(100:1000, length(samp), replace = T)\n\nFinally, we will add buffers to each of the points, randomly sized to represent the variability in maximum distance to field from household.\n\nbuf<-list()\nfor(i in 1:length(samp)) {buf[[i]] <- buffer(samp[i], widths[i])}\nfields <- vect(buf)\n\nAlso, add in other attributes (dmax, dmin and dmed) representing other field attributes like mean field size etc.\n\nfields$ID <- 1:25 #field IDs\nfields$dmax <- expanse(fields) / 1000 #based on area covered by vector. \n\nWarning: [expanse] unknown CRS. Results can be wrong\n\nfields$dmin <- fields$dmax / 4 \nfields$dmed <- fields$dmax / 2 \n\nSo now when we plot everything, we have essentially recreated the problem.\n\nplot(r) #plot the dummy raster\nplot(fields, add = T)\n\n\n\n\nAnd when we look at the attributes of the fields dataset, we have attributes for each field.\n\nfields\n\n class       : SpatVector \n geometry    : polygons \n dimensions  : 25, 5  (geometries, attributes)\n extent      : 0.9961141, 1.096878, 0.9973581, 1.102877  (xmin, xmax, ymin, ymax)\n coord. ref. :  \n names       : lyr.1    ID      dmax      dmin      dmed\n type        : <int> <int>     <num>     <num>     <num>\n values      :     5     1 1.071e-07 2.677e-08 5.354e-08\n                 100     2 6.054e-08 1.514e-08 3.027e-08\n                  23     3 1.221e-07 3.052e-08 6.104e-08\n\n\n\n\nMethod 1. go back to point data, and add rasterise points using the grid.\nThis ensures that polygons are not overlapping - 1 point per grid cell. but it removes the spatial representation of the radius.\n\ncentres <- terra::centroids(fields)\nplot(r)\nplot(centres, add=TRUE)\n\n\n\n\nNow that we have converted the buffers to points, we can use the rasterize function to add the point data to the rasters - one layer per attribute.\n\ndmax_cent <- rasterize(centres, r, \"dmax\", \"mean\") #rasterize the dmax attribute of the points\nnames(dmax_cent) <- \"dmax_cent\" #name the dmax layer\n\ndmin_cent <- rasterize(centres, r, \"dmed\", \"mean\") # rasterize the median field size attribute from the points\nnames(dmin_cent) <- \"dmin_cent\" #name the dmin layer\n\ndmed_cent <- rasterize(centres, r, \"dmin\", \"mean\") #rasterize the min field size from the point layers\nnames(dmed_cent) <- \"dmed_cent\" #name the dmed layer\n\ncent_combined <- c(dmax_cent, dmin_cent, dmed_cent) #combine the rasters into a single spatVector\n\n\npar(mfrow=c(1,3))\n\nplot(dmin_cent, xlim = c(1, 1.1))\nplot(centres, add=T)\n\nplot(dmax_cent)\nplot(centres, add=T)\n\nplot(dmax_cent)\nplot(centres, add=T)\n\n\n\n\nWe can see that each household, represented by the points, relates to a single raster grid cell. This might be enough, but the spatial information embedded in the buffers - where the buffer size is proportional to maximum distance - is lost.\nSo what options are there to preserve this information when rasterizing?\n\n\nMethod 2. add values of buffer to grid cell, and account for the proportion of overlap.\nThere has been a similar issue posted on stackoverflow which gives us some clues.\nOk, going back to our fields and our raster:\n\nplot(r)\nplot(fields, add=T)\n\n\n\n\nOne idea was to scale the field size by the fraction of the grid cell that it covers, such that a 100m max field size, that covered 5% of a grid would become 5m. Unfortunately this doesnâ€™t make a lot of sense, as the actual size of the field hasnt changed.\nSo really what we want to do is just add the field size onto the raster. so even if its a small fraction, the average size would still be 100m.\nBut its not so simple when field buffers overlap: what happens when a 100m field and 50m field overlap within the same grid cell?\nOne approach is to reduce the cell size of the original raster, then individually rasterize all of the field polygons using this fine resolution raster, before merging the musing the mosaic function to make the grid cells much smaller than they currently are.\n\ndis <- terra::disagg(r, 20) # 20x smaller cells. \ndvalue <- lapply(1:nrow(fields), \\(i) rasterize(fields[i,], dis, field = \"dmax\")) #rasterize each of the fields using the fine raster  \ndvalue <- terra::sprc(dvalue) #make a spatraster collection out of the list of rasterised fields \ndvalue <- mosaic(dvalue) #mosaic them all together, which by default will average overlapping cells\nplot(dvalue)\nplot(fields, add=TRUE)\n\n\n\n\nNow, the original question was what is the average field size per grid cell. When we re-aggregate the data\n\npar(mfrow=c(1,2))\n\nplot(dmax_cent)\nplot(fields, add=T)\n\nplot(aggregate(dvalue, 20, mean, na.rm = TRUE))\nplot(fields, add=T)\n\n\n\n\nSo now, each cell should represent the average field size within it. This is not perfect: It might tell you where there are trends toward bigger or smaller fields, but the raster cell is not proportional to field size so be careful with summary statistics."
  },
  {
    "objectID": "posts/2022-05-26-problem-solving-session/index.html#question-2.-take-a-sample-of-a-continuous-raster-using-a-random-sample-of-a-categorical-raster.",
    "href": "posts/2022-05-26-problem-solving-session/index.html#question-2.-take-a-sample-of-a-continuous-raster-using-a-random-sample-of-a-categorical-raster.",
    "title": "Problem Solving Session I",
    "section": "Question 2. Take a sample of a continuous raster using a random sample of a categorical raster.",
    "text": "Question 2. Take a sample of a continuous raster using a random sample of a categorical raster.\n\nThe problem\nHave 2 rasters, one categorical representing classes of coral reef cover, and one continuous representing wave action.\nWanting to take a random sample of the reef cover raster (excluding NAs), then use that sample to return corresponding values of the continuous raster. The two rasters have different resolutions.\n\n\nAttempted solution\nAs always, we will start by trying to create a dummy dataset. Starting with the reef cover raster.\n\nlibrary(terra) #load the terra library, the best for raster analysis in R \n\n#make a coral cover raster\ncoral <- rast(ncol=10, nrow=10, names=\"stratum\")  # a 10x10 raster\nset.seed(1)\nvalues(coral) <- round(runif(ncell(coral), 1, 5)) #values 1-5, setting 5 as NA\ncoral <- terra::classify(coral, cbind(5, NA)) # #make 5 NA, so the dataset has some NA\n\n#make a wave action raster\nwave <- rast(ncol=20, nrow=20) \nset.seed(1)\nvalues(wave) <- runif(ncell(wave), 1, 25)\nwave <- terra::classify(wave, cbind(5, NA))\n\npar(mfrow=c(1,2)) #plot them side-by-side\nplot(coral)\nplot(wave)\n\n\n\n\nNow we can take a random sample of the coral cover raster using the spatSample function.\n\nrand_pts <- spatSample(coral, 10, \"random\", as.points=TRUE, na.rm = TRUE) #this will sample the number from among the strata (not #NA) \nplot(coral)\nplot(rand_pts, 1, add=TRUE, plg=list(x=185, y=1, title=\"points\"))\n\n\n\n\nAnd we can see that each point relates to the stratum integer of the raster:\n\nrand_pts$stratum\n\n [1] 3 3 3 4 1 4 4 3 3 4\n\n\nAs an aside, this doesnâ€™t seem to work when we have a named categorical raster, as opposed to a categorical raster represented by integers. As we will see if we label the categories using the levels function:\n\ncoral_named = coral-1 #values need to start at zero, not one, for the levels function. \n#the way we made the raster, they started at one. \n\nlevels(coral_named) <- c(\"Rubble\", \"Coral/Algae\", \"Sand\", \"Rock\") #now we Can add our category labels in \n\nWarning: [set.cats] setting categories like this is deprecated; use a two-column\ndata.frame instead\n\nplot(coral_named)\n\n\n\n\nWe would obviously prefer our categorical raster to look like this, with names rather then integers representing the categories. But when we randomly sample it with spatSample (using the exact same code as above), we get a whole pile of NAs.\n\nrand_pts_named <- spatSample(coral_named, 10, \"random\", as.points=TRUE, na.rm = TRUE) #this will sample the number from among the strata (not NA) \nrand_pts_named$stratum\n\n [1] Coral/Algae Rock        Rock        Sand        Rock        Coral/Algae\n [7] Rock        Sand        Sand        Rubble     \nLevels: Rubble Coral/Algae Sand Rock\n\n\nNot sure why this is the case and it might be a good one to put on stack overflowâ€¦ but for now, lets just move on knowing the integers represent the cover classes.\nSo getting back to the task - we can use the random sample from the coral layer stored in the rand_pts spatVector using rasterize:\n\ncoral_sample <- rasterize(rand_pts, wave, field = \"stratum\") #rasterize the points using the wave raster as a template\n\nAnd now that we are done sampling, we can name our coral categories.\n\ncoral_sample <- coral_sample -1\nlevels(coral_sample) <- c(\"Rubble\", \"Coral/Algae\", \"Sand\", \"Rock\") #now we can add our category labels in\n\nWarning: [set.cats] setting categories like this is deprecated; use a two-column\ndata.frame instead\n\n\nFinally, we can use the mask function to grab the cells where we have sample values of coral:\n\nwaves_sample <- mask(wave, coral_sample) #get the waves cells where the points were \n\nLets have a look at the two rasters to see if they it all makes sense.\n\npar(mfrow=c(1,2)) #plot them side-by-side\nplot(coral_sample)\nplot(waves_sample)"
  },
  {
    "objectID": "posts/2022-08-16-newsletter/index.html",
    "href": "posts/2022-08-16-newsletter/index.html",
    "title": "Newsletter | Analysing climate data with R + Interactive Maps + AEO Forum + more.",
    "section": "",
    "text": "A huge thanks to Christina for the interactive mapping with RShiny workshop. All the material is available here. There was a lot of interest in the subject of interactive maps, and talk of a follow up session. Christina is very knowledgeable on all thing R-spatial, and would be happy to help if you are stuck trying to make a web map.\n\n\n\nWe have another great workshop is lined up. Ralph Trancoso is going to show us how to delve into climate data - both observations and projections - using R. If you want to include climate data in your research but donâ€™t know where to start, you really wonâ€™t want to miss this one!\n\n\n\nNick Wiggins is taking over from Stephane in organising the UQ R user group sessions. The next one will be on August 24th. Each session is recorded on this collaborative document.\nAs well as the R users group, Nick will be hosting some beginner spatial analysis sessions. Introduction to QGIS will be held on Thursday 25 August 2022, 9.30am - 11.30am Introduction to Raster Analysis Will be held on Thursday 8 September 2022, 9.30am - 11.30am All hosted through the UQ library, book through here.\n\n\n\nThe Advancing Earth Observation Forum will be held next week, 22nd â€“ 26th August at the Brisbane Convention and Exhibition Centre. This will be a great opportunity to connect with and learn from others in the earth observation community. Registrations are still open.\n\n\n\nUnfortunately, the 2022 ResBaz conference has been postponed due to the Covid and flu surge. We will provide updates as they become available.\n\n\n\nmapscaping is a spatial podcast where they discuss a lot of interesting geospatial topics that come up in our sessions, so definitely worth checking out.\n\n\n\nHere are a few job vacancies from across the country that might be of interest. If you know of any vacancies, send them in and they will be included with the next newsletter.\nGraduate Spatial information officer, QLD government, Location flexible.\nGeospatial engineer, Nova Systems, Brisbane\nGIS technician, TerraLab, Victoria\nTeam Leader Conservation Planner / GIS analyst, Centre for Conservation Geography, Byron Bay."
  },
  {
    "objectID": "posts/2022-11-03-build-blog-w-quarto/index.html",
    "href": "posts/2022-11-03-build-blog-w-quarto/index.html",
    "title": "Build a blog with Quarto, Git, and RStudio",
    "section": "",
    "text": "We will be covering some basics of multiple programming skills (Git/GitHub, R, Markdown, etcâ€¦) with the aim of empowering people to contribute to quarto websites such as this one - the Brisbane Spatial Share Community of Practice. The idea is to encourage community members to contribute material directly instead of funneling everything through a website administrator.\nBackground of the Community of Practice with founder, Mitchel Rudge. See the About page for more info.\nSo the group already has a websiteâ€¦ why another blog? Essentially, we found blogdown to be buggier than we wanted. Also, the folder structure was not very intutitive and are unique to each hugo theme. Finally, for the needs of our Spatial Share group the multi-lingual aspects of quarto were an important draw."
  },
  {
    "objectID": "posts/2022-11-03-build-blog-w-quarto/index.html#research-bazaar-queensland-2022",
    "href": "posts/2022-11-03-build-blog-w-quarto/index.html#research-bazaar-queensland-2022",
    "title": "Build a blog with Quarto, Git, and RStudio",
    "section": "Research Bazaar Queensland 2022",
    "text": "Research Bazaar Queensland 2022\nThis session was run as a workshop for ResBaz Queensland 2022. ResBaz is a global festival promoting digital literacy at the centre of modern research.\nWhat we will cover:\n\nQuarto basics\nGit and GitHub basics\nHow to create/edit a post on a quarto website\n\nI have pieced this together using many other resources on the above which are mentioned throughout. This is also coming from a learning-as-we-go approach and by no means expert opinion. Thank you to Mitch and Christina for their help with this tutorial and workshop!\nWhat you will need:\n\nInstallations - Git, R Windows mac, RStudio (Quarto should be installed included with recent >2022.07 versions of RSTudio - otherwise download Quarto separately)\nGitHub account (free) with your login and personal access token (PAT) details handy\nNetlify account (free)"
  },
  {
    "objectID": "posts/2022-11-03-build-blog-w-quarto/index.html#creating-a-blog-with-quarto",
    "href": "posts/2022-11-03-build-blog-w-quarto/index.html#creating-a-blog-with-quarto",
    "title": "Build a blog with Quarto, Git, and RStudio",
    "section": "Creating a blog with quarto",
    "text": "Creating a blog with quarto\n\nWhat is quarto?\nQuarto is a â€œmulti-language, next-generation version of R markdown from RStudio.â€ It is designed to be programming language (compatible with R, python, Julia, and moreâ€¦?) and tool agnostic (RStudio, VSCode, jupyter, Observable). In this tutorial, we are focusing on Quarto and RStudio.\nThe basic model of Quarto publishing is taking a source document and rendering it to a variety of outputs like html, pdfs, and Word. The backend process is illustrated below. The key difference from R Markdown is that it uses pandoc. For those interested in the details, I would recommend the Welcome to Quarto! 2 hr workshop on Youtube led by Tom Mock at RStudio.\n\nFAQ for R Markdown users.\n\n\nMake a quarto blog in RStudio\nRStudio has quarto built-in with recent versions after 2022.07. Go to File > New Project or the R in a blue cube under â€˜Editâ€™ and you will see Quarto options right there!\n\nLetâ€™s click on the Quarto Blog option. In the next window, name you project (e.g., myblog), select where to save the project with the Browse button, and ensure â€˜Create a git repositoryâ€™ is checked. More on git later.\n\nThe default project is populated with some example files and folders. The open index.qmd file is the â€˜home pageâ€™ of the blog that will list all the posts. The .qmd is the file extension for a Quarto file just like .Rmd for R Markdown. Go ahead and change the first title field in the YAML. For instance, change â€˜my blogâ€™ to â€˜My Blogâ€™.\n\n\n\n\n\n\nNote\n\n\n\nYAML stands for â€˜Yet Another Markup Languageâ€™ and is delineated by a triple dash (â€”) at the beginning and end of the YAML section. This is where you define settings for you quarto document/post.\n\n\nNow, letâ€™s look at one of the template posts. In the Files pane click on posts > welcome > index.qmd. Here we can see a template for a â€˜Welcomeâ€™ post.\nA recent addition to RStudio is that you can view the â€˜Sourceâ€™ (top left pane) as either the Source code or Visual editor. These views can be swapped by toggling the buttons at the top right of the pane. The Source code (blue box below) displays all the source code for your quarto file such are your R code (in chunks - none in this example) and Markdown narrative text.\n\n\n\n\n\n\nNote\n\n\n\nA code chunck is delineated by three backticks (button to the left of 1) and {} with the language for the code chunk (R, python etc.). Click the green C+ button to the left of run to add a new R chunck. Or keyboard shortcut Ctrl/Cmd + Alt + I.\n\n\n\nThe Visual editor displays a rendered version of your quarto file - more like what it will look like when the site is published. This is more similar to writing in a text editor like Word. You can also see there some extra formatting buttons in the Visual Editor like bold/italics and super/subscripts. The â€˜Tableâ€™ function is also a welcome edition as formatting tables in Markdown is very finicky and tedious.\nTry inserting a table or super/subscript (Format > Text > Strikethrough/Superscript/Subscript/Smallcaps) in the Visual editor and then toggle to the Source code. Now you can see the associated Markdown code for whatever you just did! Super handy.\nNow, open the _quarto.yml file. Here we can see the project type (a website), some website formatting (the navigation bar), and some other customization fields. Update the title field to match the title we edited earlier. In my case, it was â€˜My Blogâ€™. Feel free to edit other fields such as your GitHub, Twitter, LinkedIn profile links etc. You can also change the theme to one of many built-in themes.\n\n\nDonâ€™t forget to save your files when you make changes. If the file name in the tab is red - that means you have unsaved changes.\n\n\n\n\n\n\n\nNote\n\n\n\nDonâ€™t forget to save your files when you make changes. If the file name in the tab is red - that means you have unsaved changes.\n\n\nThe Visual editor is pretty cool, but itâ€™s not exactly the same as previewing your website before publishing. Click on the Render button at the top and see what happens.\nA preview of your blog should have popped-up in a web browser. You can navigate like you would a website to see all the features. Go to the about page - we can see it is the default page with the Quarto blog project. If youâ€™d like, open the about.qmd page in the project directory and make a change. Add some text, delete a link (like LinkedIn) and then save your changes.\nCongrats - youâ€™ve made a blog!\n\n\n\nCelebrate! Credit: http://www.reactiongifs.com/cheering-minions/\n\n\nIn the top right view pane of RStudio, you can see Render and Background Jobs tabs. If youâ€™d like to get an idea of what is happening in the background, check out these tabs. In the Backgroun Jobs tab, there is a red stop sign in the top right corner to stop previewing your site.\nBut how do I share it with the world?? First, we will need to version control our project with git and store it in a remote repository."
  },
  {
    "objectID": "posts/2022-11-03-build-blog-w-quarto/index.html#git---what-is-it",
    "href": "posts/2022-11-03-build-blog-w-quarto/index.html#git---what-is-it",
    "title": "Build a blog with Quarto, Git, and RStudio",
    "section": "Git - what is it?",
    "text": "Git - what is it?\nA version control software (think track changes) useful for collaborating on and sharing code.\nGit is the software itself that records changes to a set of files locally. There are several hosting platforms that are like online repositories (think Dropbox, Google Drive, etc.) that work with Git: Bitbucket, GitLab, and GitHub to name a few.\nThese platforms not only allow for version control but also to collaborate, organize, and back up projects.\n\nIn this case, we will be using GitHub to access the website files, make some changes (i.e., add a post), and then incorporate those changes back to the website repository on GitHub which will automatically update the website itself. ðŸ™Œ\nThere are lots of fabulous and free resources online that go more into depth on Git:\n\nIf you need to be convinced to use Git for version control see this article and Happy Git and GitHub for the useR to git started both by Git/R guru Jenny Bryan.\nSee Caitie Kuempelâ€™s R Ladies Brisbane presentation on getting started with GitHub in RStudio.\n\n\nGit Terminology\nRepository/repo - where a project is stored in GitHub. Think of it like a folder holding all the relevant documents that you can version control, view history, and add collaborators. The repository or repo holds all the relevant files for the website - most of which we will not touch.\nCommit - is one or more changes to a file or set of files that you are asking GitHub to keep track of.\nPush - sending your committed changes to a remote repository on GitHub. Local changes updated on the GitHub website where other people can access.\nPull - incorporating and merging changes. An edit on the remote repository on GitHub can be pulled to a local repository.\nDiff - difference, or changes made that are visible as insertions/deletions for a commit.\nMain - the default branch you are on. Master has recently updated to main, but they are the same thing. You are more likely to come across master on older resources. Jenny Bryan strongly urges you to create a new branch to work off of which requires using command line. For the purpose of contributing to a quarto website, I will forgo covering this as it is unlikely more than one person will be contributing at the same time.\nOrigin - the remote repo online from which you have cloned your local copy from.\n\n\n\nHow committing goesâ€¦ Credit: xkcd comics\n\n\n\n\nUsethis on our blog project\n\n\n\n\n\n\nHappy Git and GitHub for the useR is the online bible of using git with R by legendary Jenny Bryan. This book covers all the basics in details and provides workflows and troubleshooting Jenny Bryan has a whole chapters on what is covered below. Ch 7 Configure Git, Ch 9 PATs, and Ch 17.3 Create and connect a GitHub repo. Itâ€™s an excellent resource that I would highly encourage you to check out.\n\n\n\nUsethis is a workflow package designed to automate repetitive tasks for package development and project setup. Here, weâ€™ll be using it for the latter.\n\n\n\n\n\n\nNote\n\n\n\nYou might need to install usethis. Check by search in the Packages window in the bottom right pane in RStudio.\ninstall.packages(\"usethis\")\nlibrary(usethis)\nOr you can install the development version: install.packages(\"devtools\") if you donâ€™t have devtools. devtools::install_github(â€œr-lib/usethisâ€)\n\n\n\nConfigure Git\nIf you have never used Git before you will need to configure your account. We can do this in R with usethis using your GitHub username and email. These must be the details associated with your GitHub account. You will only need to do this once.\nusethis::use_git_config(user.name = \"Jane Doe\", user.email = \"jane@example.org\")\nIf you are not sure if you have configured Git, you can check with running usethis::edit_git_config() in the console. This will open your .gitconfig file and you can check the [user] details. If these are not right you can go ahead and change theme in the file and save.\n\n\n\nCreate a personal access token\nWe must also configure a personal access token or PAT with usethis. Type usethis::create_github_token() in the console. You will either need to log into GitHub or confirm your password. usethis will automatically select some scopes - which ones are selected? We can use these defaults - click the big, green Generate token button at the bottom.\nLeave this page open or copy this and keep it a text file/password manager. We will use it again later. You can even use gitcreds::gitcreds_set() to store your PAT now.\n\n\n\n\n\n\nWe can also save our PAT in RStudio with: gitcreds::gitcreds_set()\nThis should result in the following message. Enter password or token: ghp_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\nAdding new credentialsâ€¦\nRemoving credentials from cacheâ€¦\nDone.\n\n\n\n\n\nSetup the remote GitHub repository\nNow letâ€™s setup a remote repo on GitHub using usethis::use_github. This section is straight out of 17.3 Happy git with R - create and connect a github repo with usethis.\nHow did that go? Did you get an error?\nDonâ€™t worry. Weâ€™ve forgotten to do an initial commit a common mistake. Click on the Commit button in the Git pane, select all (Ctrl/Cmd + Shift + A) and click Stage. We are going to stage all the files to push to our remote GitHub repo. This might be a bit slow since it is multiple files so be patient. Then, make a commit message in the top right of the window. Click Commit. This creates a record (or anchor in line with the climbing analogy below) in our project that we can view and go back to if we ever need to.\n\nOnce thatâ€™s complete, letâ€™s usethis::use_github() in the Console again. How did it go this time?\nHopefully, you see something like this: \nNotice that part of what use_github() does is push the master or main branch to GitHub. (Master is legacy, but you may still see it around.)\nNow go to the link there use_github() set the remote too (in the third line with a âœ”ï¸). You will see everything that youâ€™ve commited is now in the online, remote repo! Have a look around. You can navigate, add a README.md file, and even edit files in GitHub.\nLetâ€™s go ahead and edit a file. Go to the â€˜Welcomeâ€™ post, click on the pencil âœï¸ to edit, and make a change. At the bottom you can add a commit message then commit your change.\nCool, but how do we get these changes we made on our remote repo into our local repo on our computer? This is where pull comes in. Back in the RStudio Git pane, you should see a blue down arrow labelled Pull. Click this button. This will update your local repo on your computer with the edit we made in GitHub. Look at your files and see if you can find the change we just made online. Pulling is especially important if you are working on a collaborative project. In general, you want to pull first before pushing to ensure you are working with the most up-to-date version of the project. Even if you are not in a collaborative project, it is a good habit to get into.\nThose are the Git basics! In general, you want to use the following workflow when using git.\n\nMake a change in your files and save. The changes will not show up in the Git pane unless you save the changes.\nStage the files you would like to commit. Can stage multiple files at a time.\nWrite a concise, informative commit message and press the Commit button. If you donâ€™t get any glaringly obvious Error messages, itâ€™s probably all good.\nPull pressing the blue down arrow before pushing with the green up arrow.\nRepeat!"
  },
  {
    "objectID": "posts/2022-11-03-build-blog-w-quarto/index.html#publishing",
    "href": "posts/2022-11-03-build-blog-w-quarto/index.html#publishing",
    "title": "Build a blog with Quarto, Git, and RStudio",
    "section": "Publishing",
    "text": "Publishing\nThere are several options for publishing your quarto blog outlined here. Such as Quarto Pub and Netlify.\n\n\n\n\n\n\nNote\n\n\n\nQuarto Pub is a free publishing service for quarto content. It requires having a login and an access token. This is a relatively straight forward way to get your blog online. There are some limitations to the size and everything published on Quarto Pub is publicly visible. The link above outlines the steps to publish with Quart Pub. This method does not involve using git.\n\n\nFor this workshop, we will focus on Netlify. In your Netlify account, click on the teal Add new site button.\nImport an existing project from a GitHub repository. You will probably need to configure your Netlify on GitHub. Can either configure all repositories or pick a specific repository.\n\nAuthorize Quarto to access Netlify.\n\nNow that weâ€™ve connected our GitHub to Netlify, go to the Site settings. At the bottom â€˜Publish directoryâ€™ section put the _site/ folder where your website is rendered.\n\nIt will take a few minutes to deploy your website. Netlify automatically generates a random url like â€œlighthearted-travesseiro-492jfg3â€ which can be changed in the â€˜Domain settingsâ€™. Or course, you can also use/pay for a custom url to remove the â€˜netlify.appâ€™ at the end of the url.\nNow, make a change in the welcome post, render the site, commit the changes, and push the changes in the .qmd file. Look at your GitHub remote repo to check that the changes are there. Now check your website - did it update as well?\nAs we defined above, unless you also commited the updated contents of the _site/ foldr the website will not have updated. This folder is where all the rendered outputs are that are used to build the site on Netlify. Commit the updated _site/ folder and push. Now check your website again.\n\n\n\nCheers"
  },
  {
    "objectID": "posts/2022-11-03-build-blog-w-quarto/index.html#add-a-map",
    "href": "posts/2022-11-03-build-blog-w-quarto/index.html#add-a-map",
    "title": "Build a blog with Quarto, Git, and RStudio",
    "section": "Add a map",
    "text": "Add a map\nThis is a spatial community of practice - letâ€™s add a map of ResBazQld 2022 to a post using leaflet.\n\n# install.packages(\"leaflet\")\nlibrary(leaflet)\nlibrary(magrittr)\nleaflet() %>% \n  addTiles() %>% # default background map\n  addMarkers(lat = -27.552, lng = 153.0535,\n             popup = \"Location of ResBazQld 2022\")"
  },
  {
    "objectID": "posts/2022-11-03-build-blog-w-quarto/index.html#troubleshooting-tbc",
    "href": "posts/2022-11-03-build-blog-w-quarto/index.html#troubleshooting-tbc",
    "title": "Build a blog with Quarto, Git, and RStudio",
    "section": "Troubleshooting TBC",
    "text": "Troubleshooting TBC"
  },
  {
    "objectID": "posts/2022-11-03-build-blog-w-quarto/index.html#resources",
    "href": "posts/2022-11-03-build-blog-w-quarto/index.html#resources",
    "title": "Build a blog with Quarto, Git, and RStudio",
    "section": "Resources",
    "text": "Resources\nQuarto\n\nBuilding a blog with quarto, Youtube video, website - Isabella Valasquez, Rstudio\nWelcome to Quarto!, Tom Mock, RStudio"
  }
]